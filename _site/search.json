[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "",
    "text": "Ce workshop vous guidera à travers le déploiement complet d’un modèle de Machine Learning en production sur Microsoft Azure. Vous allez construire une API de prédiction de défaillance client (churn) et la déployer sur le cloud avec toutes les bonnes pratiques MLOps.\n\n\n\nÀ la fin de ce workshop, vous serez capable de :\n\nEntraîner et sauvegarder un modèle ML avec MLflow\nCréer une API REST avec FastAPI\nConteneuriser une application avec Docker\nDéployer sur Azure Container Apps\nMettre en place un pipeline CI/CD avec GitHub Actions\nMonitorer votre application en production\nDétecter le data drift\n\n\n\n\nContexte : Une banque souhaite prédire quels clients risquent de partir pour proposer des actions de rétention.\nDataset : 10 features (âge, score crédit, solde, etc.) + 1 target (Exited : 0/1)\nModèle : Random Forest Classifier\nLivrable : API REST déployée sur Azure, accessible publiquement\n\n\n\nFlux de déploiement :\nCode GitHub → GitHub Actions → Docker Build → Azure Container Registry → Azure Container Apps → Internet"
  },
  {
    "objectID": "index.html#sec-introduction",
    "href": "index.html#sec-introduction",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "",
    "text": "Ce workshop vous guidera à travers le déploiement complet d’un modèle de Machine Learning en production sur Microsoft Azure. Vous allez construire une API de prédiction de défaillance client (churn) et la déployer sur le cloud avec toutes les bonnes pratiques MLOps.\n\n\n\nÀ la fin de ce workshop, vous serez capable de :\n\nEntraîner et sauvegarder un modèle ML avec MLflow\nCréer une API REST avec FastAPI\nConteneuriser une application avec Docker\nDéployer sur Azure Container Apps\nMettre en place un pipeline CI/CD avec GitHub Actions\nMonitorer votre application en production\nDétecter le data drift\n\n\n\n\nContexte : Une banque souhaite prédire quels clients risquent de partir pour proposer des actions de rétention.\nDataset : 10 features (âge, score crédit, solde, etc.) + 1 target (Exited : 0/1)\nModèle : Random Forest Classifier\nLivrable : API REST déployée sur Azure, accessible publiquement\n\n\n\nFlux de déploiement :\nCode GitHub → GitHub Actions → Docker Build → Azure Container Registry → Azure Container Apps → Internet"
  },
  {
    "objectID": "index.html#sec-preparation",
    "href": "index.html#sec-preparation",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "2 Préparation de l’Environnement",
    "text": "2 Préparation de l’Environnement\n\n2.1 Logiciels Requis\nObligatoire :\n\nPython 3.9+ : https://www.python.org/downloads/\nVisual Studio Code : https://code.visualstudio.com/\nGit : https://git-scm.com/downloads\nDocker Desktop : https://www.docker.com/products/docker-desktop\nAzure CLI : https://docs.microsoft.com/cli/azure/install-azure-cli\n\nComptes à créer :\n\nCompte GitHub : https://github.com/signup\nAzure for Students (100$) : https://azure.microsoft.com/students\n\n\n\n2.2 Vérification de l’Installation\nOuvrez un terminal et testez :\n# Python\npython --version\n# Doit afficher Python 3.9.x ou superieur\n\n# Git\ngit --version\n\n# Docker\ndocker --version\ndocker ps\n\n# Azure CLI\naz --version\n\n\n2.3 Configuration Initiale\n\n2.3.1 Configuration Git\ngit config --global user.name \"Votre Nom\"\ngit config --global user.email \"votre.email@example.com\"\n\n\n2.3.2 Connexion à Azure\n# Se connecter a Azure\naz login\n\n# Verifier l'abonnement\naz account show\n\n# Si vous avez plusieurs abonnements, selectionner celui de Students\naz account set --subscription \"Azure for Students\""
  },
  {
    "objectID": "index.html#sec-module1",
    "href": "index.html#sec-module1",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "3 Module 1 : Entraînement du Modèle",
    "text": "3 Module 1 : Entraînement du Modèle\n\n3.1 Objectif\nEntraîner un modèle Random Forest pour prédire le churn et le sauvegarder avec MLflow.\n\n\n3.2 Préparation du Projet\n# Creer le dossier du projet\nmkdir bank-churn-mlops\ncd bank-churn-mlops\n\n# Creer un environnement virtuel\npython -m venv venv\n\n# Activer l'environnement\n# Windows :\nvenv\\Scripts\\activate\n# Mac/Linux :\nsource venv/bin/activate\n\n# Creer la structure\nmkdir -p data model app tests\ntouch requirements.txt\n\n\n3.3 Fichier requirements.txt\nCréez le fichier requirements.txt avec le contenu suivant :\n# API Framework\nfastapi==0.104.1\nuvicorn[standard]==0.24.0\npydantic==2.5.0\n\n# Machine Learning\nscikit-learn==1.3.2\npandas==2.1.3\nnumpy==1.26.2\njoblib==1.3.2\n\n# MLflow\nmlflow==2.8.1\n\n# Testing\npytest==7.4.3\npytest-cov==4.1.0\nhttpx==0.25.2\n\n# Utilities\npython-multipart==0.0.6\nrequests==2.31.0\nPuis installez les dépendances :\npip install -r requirements.txt\n\n\n3.4 Téléchargement du Dataset\nCréez un dataset synthétique :\n# generate_data.py\nimport pandas as pd\nimport numpy as np\n\nnp.random.seed(42)\nn_samples = 10000\n\ndata = {\n    'CreditScore': np.random.randint(300, 850, n_samples),\n    'Age': np.random.randint(18, 80, n_samples),\n    'Tenure': np.random.randint(0, 11, n_samples),\n    'Balance': np.random.uniform(0, 200000, n_samples),\n    'NumOfProducts': np.random.randint(1, 5, n_samples),\n    'HasCrCard': np.random.choice([0, 1], n_samples),\n    'IsActiveMember': np.random.choice([0, 1], n_samples),\n    'EstimatedSalary': np.random.uniform(20000, 150000, n_samples),\n    'Geography_Germany': np.random.choice([0, 1], n_samples),\n    'Geography_Spain': np.random.choice([0, 1], n_samples),\n}\n\n# Target : plus de chance de partir si inactif, peu de produits, etc.\nchurn_prob = (\n    (1 - data['IsActiveMember']) * 0.3 +\n    (data['NumOfProducts'] == 1) * 0.2 +\n    (data['Age'] &gt; 60) * 0.15 +\n    (data['Balance'] == 0) * 0.25\n)\ndata['Exited'] = (np.random.random(n_samples) &lt; churn_prob).astype(int)\n\ndf = pd.DataFrame(data)\ndf.to_csv('data/bank_churn.csv', index=False)\nprint(f\"Dataset cree : {len(df)} lignes\")\nprint(f\"Taux de churn : {df['Exited'].mean():.2%}\")\n\n\n3.5 Script d’Entraînement\nCréez le fichier train_model.py :\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, \n    precision_score, \n    recall_score,\n    f1_score, \n    roc_auc_score,\n    confusion_matrix\n)\nimport joblib\nimport mlflow\nimport mlflow.sklearn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configuration MLflow\nmlflow.set_tracking_uri(\"./mlruns\")\nmlflow.set_experiment(\"bank-churn-prediction\")\n\nprint(\"Chargement des donnees...\")\ndf = pd.read_csv(\"data/bank_churn.csv\")\n\nprint(f\"Dataset : {len(df)} lignes, {len(df.columns)} colonnes\")\nprint(f\"Taux de churn : {df['Exited'].mean():.2%}\")\n\n# Separation features/target\nX = df.drop('Exited', axis=1)\ny = df['Exited']\n\n# Split train/test (80/20)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(f\"\\nTrain : {len(X_train)} lignes\")\nprint(f\"Test : {len(X_test)} lignes\")\n\n# Entrainement avec MLflow tracking\nprint(\"\\nEntrainement du modele...\")\nwith mlflow.start_run(run_name=\"random-forest-v1\"):\n    \n    # Parametres du modele\n    params = {\n        'n_estimators': 100,\n        'max_depth': 10,\n        'min_samples_split': 5,\n        'random_state': 42\n    }\n    \n    # Entrainement\n    model = RandomForestClassifier(**params)\n    model.fit(X_train, y_train)\n    \n    # Predictions\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    \n    # Calcul des metriques\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    \n    # Log des parametres et metriques dans MLflow\n    mlflow.log_params(params)\n    mlflow.log_metrics({\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1_score\": f1,\n        \"roc_auc\": auc\n    })\n    \n    # Creation et sauvegarde de la matrice de confusion\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title('Matrice de Confusion')\n    plt.ylabel('Vraie Classe')\n    plt.xlabel('Classe Predite')\n    plt.savefig('confusion_matrix.png')\n    mlflow.log_artifact('confusion_matrix.png')\n    plt.close()\n    \n    # Feature importance\n    feature_importance = pd.DataFrame({\n        'feature': X.columns,\n        'importance': model.feature_importances_\n    }).sort_values('importance', ascending=False)\n    \n    plt.figure(figsize=(10, 6))\n    plt.barh(feature_importance['feature'], feature_importance['importance'])\n    plt.xlabel('Importance')\n    plt.title('Feature Importance')\n    plt.tight_layout()\n    plt.savefig('feature_importance.png')\n    mlflow.log_artifact('feature_importance.png')\n    plt.close()\n    \n    # Enregistrement du modele dans MLflow\n    mlflow.sklearn.log_model(\n        model,\n        \"model\",\n        registered_model_name=\"bank-churn-classifier\"\n    )\n    \n    # Sauvegarde locale du modele\n    joblib.dump(model, \"model/churn_model.pkl\")\n    \n    # Tags\n    mlflow.set_tags({\n        \"environment\": \"development\",\n        \"model_type\": \"RandomForest\",\n        \"task\": \"binary_classification\"\n    })\n    \n    # Affichage des resultats\n    print(\"\\n\" + \"=\"*50)\n    print(\"RESULTATS DE L'ENTRAINEMENT\")\n    print(\"=\"*50)\n    print(f\"Accuracy  : {accuracy:.4f}\")\n    print(f\"Precision : {precision:.4f}\")\n    print(f\"Recall    : {recall:.4f}\")\n    print(f\"F1 Score  : {f1:.4f}\")\n    print(f\"ROC AUC   : {auc:.4f}\")\n    print(\"=\"*50)\n    \n    print(f\"\\nModele sauvegarde dans : model/churn_model.pkl\")\n    print(f\"MLflow UI : mlflow ui --port 5000\")\n\n\n3.6 Exécution\n# Lancer l'entrainement\npython train_model.py\n\n# Voir les resultats dans MLflow UI\nmlflow ui --port 5000\n# Ouvrir http://localhost:5000 dans votre navigateur\n\n\n3.7 Checkpoint\n\n\n\n\n\n\nNoteValidation Module 1\n\n\n\nAvant de passer au module suivant, vérifiez que :\n\n\nLe modèle est entraîné avec une accuracy &gt; 0.75\nLe fichier model/churn_model.pkl existe\nMLflow UI affiche votre expérience\nVous comprenez les métriques obtenues"
  },
  {
    "objectID": "index.html#sec-module2",
    "href": "index.html#sec-module2",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "4 Module 2 : Création de l’API avec FastAPI",
    "text": "4 Module 2 : Création de l’API avec FastAPI\n\n4.1 Objectif\nCréer une API REST qui expose le modèle via des endpoints HTTP.\n\n\n4.2 Structure du Code API\nbank-churn-mlops/\n|-- app/\n|   |-- __init__.py\n|   |-- main.py\n|   |-- models.py\n|   +-- utils.py\n|-- model/\n|   +-- churn_model.pkl\n|-- tests/\n|   +-- test_api.py\n|-- requirements.txt\n+-- README.md\n\n\n4.3 Fichier app/models.py\nDéfinition des schémas de données avec Pydantic :\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass CustomerFeatures(BaseModel):\n    \"\"\"Schema pour les features d'un client\"\"\"\n    CreditScore: int = Field(..., ge=300, le=850, description=\"Score de credit\")\n    Age: int = Field(..., ge=18, le=100, description=\"Age du client\")\n    Tenure: int = Field(..., ge=0, le=10, description=\"Anciennete en annees\")\n    Balance: float = Field(..., ge=0, description=\"Solde du compte\")\n    NumOfProducts: int = Field(..., ge=1, le=4, description=\"Nombre de produits\")\n    HasCrCard: int = Field(..., ge=0, le=1, description=\"Possession carte credit\")\n    IsActiveMember: int = Field(..., ge=0, le=1, description=\"Membre actif\")\n    EstimatedSalary: float = Field(..., ge=0, description=\"Salaire estime\")\n    Geography_Germany: int = Field(..., ge=0, le=1, description=\"Client allemand\")\n    Geography_Spain: int = Field(..., ge=0, le=1, description=\"Client espagnol\")\n    \n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"CreditScore\": 650,\n                \"Age\": 35,\n                \"Tenure\": 5,\n                \"Balance\": 50000,\n                \"NumOfProducts\": 2,\n                \"HasCrCard\": 1,\n                \"IsActiveMember\": 1,\n                \"EstimatedSalary\": 75000,\n                \"Geography_Germany\": 0,\n                \"Geography_Spain\": 1\n            }\n        }\n\nclass PredictionResponse(BaseModel):\n    \"\"\"Schema pour la reponse de prediction\"\"\"\n    churn_probability: float = Field(..., description=\"Probabilite de churn (0-1)\")\n    prediction: int = Field(..., description=\"Prediction binaire (0=reste, 1=part)\")\n    risk_level: str = Field(..., description=\"Niveau de risque (Low/Medium/High)\")\n\nclass HealthResponse(BaseModel):\n    \"\"\"Schema pour le health check\"\"\"\n    status: str\n    model_loaded: bool\n\n\n4.4 Fichier app/main.py\nL’API principale :\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nimport joblib\nimport numpy as np\nfrom typing import List\nimport logging\nimport os\n\nfrom app.models import CustomerFeatures, PredictionResponse, HealthResponse\n\n# Configuration du logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Initialisation FastAPI\napp = FastAPI(\n    title=\"Bank Churn Prediction API\",\n    description=\"API de prediction de defaillance client\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\"\n)\n\n# CORS pour permettre les requetes depuis un navigateur\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Chargement du modele au demarrage\nMODEL_PATH = os.getenv(\"MODEL_PATH\", \"model/churn_model.pkl\")\nmodel = None\n\n@app.on_event(\"startup\")\nasync def load_model():\n    \"\"\"Charge le modele au demarrage de l'API\"\"\"\n    global model\n    try:\n        model = joblib.load(MODEL_PATH)\n        logger.info(f\"Modele charge avec succes depuis {MODEL_PATH}\")\n    except Exception as e:\n        logger.error(f\"Erreur lors du chargement du modele : {e}\")\n        model = None\n\n@app.get(\"/\", tags=[\"General\"])\ndef root():\n    \"\"\"Endpoint racine\"\"\"\n    return {\n        \"message\": \"Bank Churn Prediction API\",\n        \"version\": \"1.0.0\",\n        \"status\": \"running\",\n        \"docs\": \"/docs\"\n    }\n\n@app.get(\"/health\", response_model=HealthResponse, tags=[\"General\"])\ndef health_check():\n    \"\"\"Verification de l'etat de l'API\"\"\"\n    if model is None:\n        raise HTTPException(\n            status_code=503, \n            detail=\"Modele non charge\"\n        )\n    return {\n        \"status\": \"healthy\",\n        \"model_loaded\": True\n    }\n\n@app.post(\"/predict\", response_model=PredictionResponse, tags=[\"Prediction\"])\ndef predict(features: CustomerFeatures):\n    \"\"\"\n    Predit si un client va partir (churn)\n    \n    Retourne :\n    - churn_probability : probabilite de churn (0 a 1)\n    - prediction : 0 (reste) ou 1 (part)\n    - risk_level : Low, Medium ou High\n    \"\"\"\n    if model is None:\n        raise HTTPException(\n            status_code=503, \n            detail=\"Modele non disponible\"\n        )\n    \n    try:\n        # Preparation des features\n        input_data = np.array([[\n            features.CreditScore,\n            features.Age,\n            features.Tenure,\n            features.Balance,\n            features.NumOfProducts,\n            features.HasCrCard,\n            features.IsActiveMember,\n            features.EstimatedSalary,\n            features.Geography_Germany,\n            features.Geography_Spain\n        ]])\n        \n        # Prediction\n        proba = model.predict_proba(input_data)[0, 1]\n        prediction = int(proba &gt; 0.5)\n        \n        # Classification du risque\n        if proba &lt; 0.3:\n            risk = \"Low\"\n        elif proba &lt; 0.7:\n            risk = \"Medium\"\n        else:\n            risk = \"High\"\n        \n        logger.info(\n            f\"Prediction effectuee : proba={proba:.4f}, \"\n            f\"prediction={prediction}, risk={risk}\"\n        )\n        \n        return {\n            \"churn_probability\": round(float(proba), 4),\n            \"prediction\": prediction,\n            \"risk_level\": risk\n        }\n    \n    except Exception as e:\n        logger.error(f\"Erreur lors de la prediction : {e}\")\n        raise HTTPException(\n            status_code=500, \n            detail=f\"Erreur de prediction : {str(e)}\"\n        )\n\n@app.post(\"/predict/batch\", tags=[\"Prediction\"])\ndef predict_batch(features_list: List[CustomerFeatures]):\n    \"\"\"\n    Predictions en batch pour plusieurs clients\n    \"\"\"\n    if model is None:\n        raise HTTPException(status_code=503, detail=\"Modele non disponible\")\n    \n    try:\n        predictions = []\n        \n        for features in features_list:\n            input_data = np.array([[\n                features.CreditScore, features.Age, features.Tenure,\n                features.Balance, features.NumOfProducts, features.HasCrCard,\n                features.IsActiveMember, features.EstimatedSalary,\n                features.Geography_Germany, features.Geography_Spain\n            ]])\n            \n            proba = model.predict_proba(input_data)[0, 1]\n            prediction = int(proba &gt; 0.5)\n            \n            predictions.append({\n                \"churn_probability\": round(float(proba), 4),\n                \"prediction\": prediction\n            })\n        \n        logger.info(f\"Batch prediction : {len(predictions)} clients traites\")\n        \n        return {\"predictions\": predictions, \"count\": len(predictions)}\n    \n    except Exception as e:\n        logger.error(f\"Erreur batch prediction : {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n\n\n4.5 Test Local de l’API\n# Demarrer l'API\nuvicorn app.main:app --reload --port 8000\n\n# Dans un autre terminal, tester :\n\n# 1. Health check\ncurl http://localhost:8000/health\n\n# 2. Prediction simple\ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n  }'\n\n\n4.6 Jupyter Lab\n#dans jupyter lab\nimport requests\nimport json\n\n# URL de ton API FastAPI\nurl = \"http://localhost:8000/predict\"\n\n# Données à envoyer\ndata = {\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n}\n\n# Envoyer la requête POST\nresponse = requests.post(url, json=data)\n\n# Afficher la réponse\nprint(f\"Status Code: {response.status_code}\")\nprint(f\"Response: {response.json()}\")\n\n\n4.7 Documentation Interactive\nOuvrez votre navigateur et allez sur :\n\nSwagger UI : http://localhost:8000/docs\nReDoc : http://localhost:8000/redoc\n\n\n\n4.8 Checkpoint\n\n\n\n\n\n\nNoteValidation Module 2\n\n\n\nAvant de passer au module suivant, vérifiez que :\n\n\nLe modèle est entraîné avec une accuracy &gt; 0.75\nLe fichier model/churn_model.pkl existe\n\nMLflow UI affiche votre expérience\nVous comprenez les métriques obtenues"
  },
  {
    "objectID": "index.html#sec-module3",
    "href": "index.html#sec-module3",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "5 Module 3 : Conteneurisation avec Docker",
    "text": "5 Module 3 : Conteneurisation avec Docker\n\n5.1 Objectif\nEmpaqueter l’API dans un conteneur Docker pour la rendre portable et faciliter le déploiement sur Azure.\n\n\n5.2 Création du Dockerfile\nCréez le fichier Dockerfile à la racine du projet :\n# Utilise une image Python officielle\nFROM python:3.9-slim\n\n# Definir le repertoire de travail\nWORKDIR /app\n\n# Copier les fichiers de dependances\nCOPY requirements.txt .\n\n# Installer les dependances\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copier le code de l'application\nCOPY app/ ./app/\nCOPY model/ ./model/\n\n# Exposer le port\nEXPOSE 8000\n\n# Commande pour demarrer l'application\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n\n\n5.3 Création du .dockerignore\nCréez le fichier .dockerignore :\n__pycache__\n*.pyc\n*.pyo\n*.pyd\n.Python\nenv/\nvenv/\n.venv\n*.egg-info/\n.pytest_cache/\n.git\n.gitignore\nREADME.md\n.env\nmlruns/\n*.log\n.DS_Store\n.vscode/\ntests/\n\n\n5.4 Build de l’Image Docker\n# Build de l'image (cela peut prendre quelques minutes)\ndocker build -t bank-churn-api:v1 .\n\n# Verifier que l'image est creee\ndocker images bank-churn-api:v1\n\n# Voir la taille de l'image\ndocker images --format \"table {{.Repository}}\\t{{.Tag}}\\t{{.Size}}\" | grep bank-churn\n\n\n5.5 Test du Conteneur en Local\n# Lancer le conteneur\ndocker run -d -p 8000:8000 --name churn-api bank-churn-api:v1\n\n# Verifier que le conteneur tourne\ndocker ps\n\n# Voir les logs\ndocker logs churn-api\n\n# Tester l'API\ncurl http://localhost:8000/health\n\n# Prediction de test\ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 700,\n    \"Age\": 40,\n    \"Tenure\": 7,\n    \"Balance\": 80000,\n    \"NumOfProducts\": 3,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 0,\n    \"EstimatedSalary\": 90000,\n    \"Geography_Germany\": 1,\n    \"Geography_Spain\": 0\n  }'\n\n# Arreter et supprimer le conteneur\ndocker stop churn-api\ndocker rm churn-api\n\n\n5.6 Commandes Docker Utiles\n# Voir tous les conteneurs (meme arretes)\ndocker ps -a\n\n# Entrer dans un conteneur en cours d'execution\ndocker exec -it churn-api /bin/bash\n\n# Voir l'utilisation des ressources\ndocker stats churn-api\n\n# Nettoyer les images inutilisees\ndocker image prune\n\n# Supprimer toutes les images\ndocker rmi $(docker images -q)\n\n\n5.7 Questions de Compréhension\n\nPourquoi utiliser un .dockerignore ?\nQuelle est la différence entre CMD et RUN dans un Dockerfile ?\nPourquoi exposer le port 8000 ?\nComment vérifier que votre conteneur fonctionne correctement ?\n\n\n\n5.8 Checkpoint\n\n\n\n\n\n\nNoteValidation Module 3\n\n\n\nAvant de passer au module suivant, vérifiez que :\n\n\nL’image Docker est buildée avec succès\nLe conteneur démarre sans erreur\nL’API répond correctement depuis le conteneur\nLa taille de l’image est raisonnable (&lt; 1GB)"
  },
  {
    "objectID": "index.html#sec-module4",
    "href": "index.html#sec-module4",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "6 Module 4 : Déploiement sur Azure",
    "text": "6 Module 4 : Déploiement sur Azure\n\n6.1 Objectif\nDéployer l’API sur Azure Container Apps et la rendre accessible publiquement.\n\n\n6.2 Étape 1 : Création du Groupe de Ressources\n# Variables (MODIFIEZ avec vos valeurs)\nRESOURCE_GROUP=\"rg-mlops-workshop\"\nLOCATION=\"westeurope\"\nACR_NAME=\"acrmlops$(whoami)$(date +%s)\"  # Doit etre unique globalement\nCONTAINER_APP_NAME=\"app-churn-api\"\n\n# Creation du groupe de ressources\naz group create \\\n  --name $RESOURCE_GROUP \\\n  --location $LOCATION\n\necho \"Groupe de ressources cree : $RESOURCE_GROUP\"\n\n\n6.3 Étape 2 : Azure Container Registry (ACR)\n# Creation du registry (SKU Basic pour economiser)\naz acr create \\\n  --resource-group $RESOURCE_GROUP \\\n  --name $ACR_NAME \\\n  --sku Basic \\\n  --admin-enabled true\n\necho \"Container Registry cree : $ACR_NAME\"\n\n# Se connecter au registry\naz acr login --name $ACR_NAME\n\n# Verifier la connexion\naz acr show --name $ACR_NAME --query loginServer --output tsv\n\n\n6.4 Étape 3 : Push de l’Image vers ACR\n# Recuperer l'URL du registry\nACR_LOGIN_SERVER=$(az acr show --name $ACR_NAME --query loginServer --output tsv)\n\n# Tagger l'image pour ACR\ndocker tag bank-churn-api:v1 $ACR_LOGIN_SERVER/bank-churn-api:v1\ndocker tag bank-churn-api:v1 $ACR_LOGIN_SERVER/bank-churn-api:latest\n\n# Pousser l'image vers ACR\ndocker push $ACR_LOGIN_SERVER/bank-churn-api:v1\ndocker push $ACR_LOGIN_SERVER/bank-churn-api:latest\n\n# Verifier que l'image est bien dans ACR\naz acr repository list --name $ACR_NAME --output table\naz acr repository show-tags --name $ACR_NAME --repository bank-churn-api --output table\n\n\n6.5 Étape 4 : Création de l’Environnement Container Apps\n# Variables\nCONTAINERAPPS_ENV=\"env-mlops-workshop\"\n\n# Creation de l'environnement\naz containerapp env create \\\n  --name $CONTAINERAPPS_ENV \\\n  --resource-group $RESOURCE_GROUP \\\n  --location $LOCATION\n\necho \"Environnement Container Apps cree : $CONTAINERAPPS_ENV\"\n\n\n6.6 Étape 5 : Déploiement de l’Application\n# Recuperer les credentials ACR\nACR_USERNAME=$(az acr credential show --name $ACR_NAME --query username -o tsv)\nACR_PASSWORD=$(az acr credential show --name $ACR_NAME --query passwords[0].value -o tsv)\n\n# Deployer l'application\naz containerapp create \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --environment $CONTAINERAPPS_ENV \\\n  --image $ACR_LOGIN_SERVER/bank-churn-api:v1 \\\n  --registry-server $ACR_LOGIN_SERVER \\\n  --registry-username $ACR_USERNAME \\\n  --registry-password $ACR_PASSWORD \\\n  --target-port 8000 \\\n  --ingress external \\\n  --min-replicas 1 \\\n  --max-replicas 3 \\\n  --cpu 0.5 \\\n  --memory 1Gi\n\necho \"Application deployee !\"\n\n\n6.7 Étape 6 : Récupérer l’URL Publique\n# Recuperer l'URL de l'application\nAPP_URL=$(az containerapp show \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --query properties.configuration.ingress.fqdn -o tsv)\n\necho \"==========================================\"\necho \"API deployee avec succes !\"\necho \"URL : https://$APP_URL\"\necho \"Health check : https://$APP_URL/health\"\necho \"Documentation : https://$APP_URL/docs\"\necho \"==========================================\"\n\n# Tester l'API deployee\ncurl https://$APP_URL/health\n\n\n6.8 Étape 7 : Test de l’API en Production\n# Test de prediction\ncurl -X POST \"https://$APP_URL/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n  }'\n\n\n6.9 Surveillance des Coûts\n\n\n\n\n\n\nWarningIMPORTANT - Gestion du Budget\n\n\n\nPour éviter de dépasser le budget de 100$ :\n# Voir les couts estimes\naz consumption usage list \\\n  --start-date 2024-11-01 \\\n  --end-date 2024-11-30 \\\n  --output table\n\n# Mettre l'application en veille (min-replicas=0)\naz containerapp update \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --min-replicas 0 \\\n  --max-replicas 3\nCoûts estimés pour ce workshop : 8-12$ pour 10 heures d’utilisation.\n\n\n\n\n6.10 Exercice Pratique\n\n\n\n\n\n\nTipEXERCICE 2\n\n\n\nPartagez votre URL d’API avec un camarade et testez son API :\n\nFaites 10 prédictions sur son API\nComparez les résultats avec votre modèle\nObservez les logs dans Azure Portal\n\n\n\n\n\n6.11 Checkpoint\n\n\n\n\n\n\nNoteValidation Module 4\n\n\n\nAvant de passer au module suivant, vérifiez que :\n\n\nL’application est accessible via HTTPS\nLe health check fonctionne\nLes prédictions fonctionnent\nVous avez noté l’URL publique de votre API"
  },
  {
    "objectID": "index.html#sec-module5",
    "href": "index.html#sec-module5",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "7 Module 5 : CI/CD avec GitHub Actions",
    "text": "7 Module 5 : CI/CD avec GitHub Actions\n\n7.1 Objectif\nAutomatiser le déploiement : chaque commit sur la branche main déclenche un build et un redéploiement.\n\n\n7.2 Étape 1 : Initialisation du Repository Git\n# Initialiser git (si pas deja fait)\ngit init\n\n# Creer un .gitignore\ncat &gt; .gitignore &lt;&lt; EOF\n__pycache__/\n*.pyc\nvenv/\n.env\nmlruns/\n*.log\n.DS_Store\n.vscode/\nconfusion_matrix.png\nfeature_importance.png\nEOF\n\n# Premier commit\ngit add .\ngit commit -m \"Initial commit: Bank Churn API\"\n\n\n7.3 Étape 2 : Créer un Repository GitHub\n\nAllez sur https://github.com/new\nNom du repository : bank-churn-mlops\nVisibility : Public ou Private\nNe pas initialiser avec README (déjà fait localement)\nCliquez sur “Create repository”\n\n# Lier votre repo local a GitHub (REMPLACEZ username)\ngit remote add origin https://github.com/username/bank-churn-mlops.git\ngit branch -M main\ngit push -u origin main\n\n\n7.4 Étape 3 : Configuration des Secrets GitHub\n\n7.4.1 Créer un Service Principal Azure\n# Recuperer votre Subscription ID\nSUBSCRIPTION_ID=$(az account show --query id -o tsv)\n\n# Creer un Service Principal\naz ad sp create-for-rbac \\\n  --name \"github-actions-mlops\" \\\n  --role contributor \\\n  --scopes /subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP \\\n  --sdk-auth\nCopiez tout le JSON retourné.\n\n\n7.4.2 Ajouter les Secrets dans GitHub\n\nAllez dans votre repository GitHub\nSettings &gt; Secrets and variables &gt; Actions\nCliquez sur “New repository secret”\nAjoutez les secrets suivants :\n\n\n\n\n\n\n\n\nNom\nValeur\n\n\n\n\nAZURE_CREDENTIALS\nLe JSON du Service Principal\n\n\nACR_USERNAME\nRésultat de : az acr credential show --name $ACR_NAME --query username -o tsv\n\n\nACR_PASSWORD\nRésultat de : az acr credential show --name $ACR_NAME --query passwords[0].value -o tsv\n\n\n\n\n\n\n7.5 Étape 4 : Création du Workflow GitHub Actions\nCréez le fichier .github/workflows/ci-cd.yml :\nname: CI/CD Pipeline\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n  workflow_dispatch:\n\nenv:\n  AZURE_RESOURCE_GROUP: rg-mlops-workshop\n  ACR_NAME: votre-acr-name  # MODIFIEZ ICI\n  CONTAINER_APP_NAME: app-churn-api\n  IMAGE_NAME: bank-churn-api\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n      \n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.9'\n      \n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements.txt\n          pip install pytest pytest-cov\n      \n      - name: Run tests\n        run: |\n          pytest tests/ -v --cov=app --cov-report=term\n      \n  build-and-deploy:\n    needs: test\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'\n    \n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n      \n      - name: Azure Login\n        uses: azure/login@v1\n        with:\n          creds: ${{ secrets.AZURE_CREDENTIALS }}\n      \n      - name: Login to ACR\n        uses: azure/docker-login@v1\n        with:\n          login-server: ${{ env.ACR_NAME }}.azurecr.io\n          username: ${{ secrets.ACR_USERNAME }}\n          password: ${{ secrets.ACR_PASSWORD }}\n      \n      - name: Build and push Docker image\n        run: |\n          docker build -t ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }} .\n          docker build -t ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest .\n          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}\n          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest\n      \n      - name: Deploy to Azure Container Apps\n        uses: azure/CLI@v1\n        with:\n          inlineScript: |\n            az containerapp update \\\n              --name ${{ env.CONTAINER_APP_NAME }} \\\n              --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n              --image ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}\n      \n      - name: Verify deployment\n        run: |\n          APP_URL=$(az containerapp show \\\n            --name ${{ env.CONTAINER_APP_NAME }} \\\n            --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n            --query properties.configuration.ingress.fqdn -o tsv)\n          \n          echo \"Application deployed at: https://$APP_URL\"\n          \n          sleep 30\n          curl -f https://$APP_URL/health || exit 1\n          \n          echo \"Deployment successful!\"\n\n\n7.6 Étape 5 : Déclencher le Pipeline\n# Ajouter le workflow\ngit add .github/workflows/ci-cd.yml\ngit add tests/test_api.py\ngit commit -m \"Add CI/CD pipeline and tests\"\ngit push origin main\n\n# Le pipeline se declenche automatiquement !\nAllez sur GitHub &gt; Actions pour voir le pipeline en cours d’exécution.\n\n\n7.7 Exercice Pratique\n\n\n\n\n\n\nTipEXERCICE 3\n\n\n\n\nAjoutez un nouveau test dans test_api.py\nFaites un commit et push\nObservez le pipeline s’exécuter\nVérifiez que le déploiement s’est bien fait\n\n\n\n\n\n7.8 Checkpoint\n\n\n\n\n\n\nNoteValidation Module 5\n\n\n\nAvant de passer au module suivant, vérifiez que :\n\n\nLe repository GitHub est créé\nLes secrets sont configurés\nLe workflow CI/CD s’exécute sans erreur\nL’application se redéploie\n\n\nautomatiquement"
  },
  {
    "objectID": "index.html#sec-module6",
    "href": "index.html#sec-module6",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "8 Module 6 : Monitoring et Maintenance",
    "text": "8 Module 6 : Monitoring et Maintenance\n\n8.1 Objectif\nMettre en place le monitoring de l’application et détecter les problèmes en production.\n\n\n8.2 Configuration Application Insights\n# Creation d'Application Insights\naz monitor app-insights component create \\\n  --app bank-churn-insights \\\n  --location $LOCATION \\\n  --resource-group $RESOURCE_GROUP \\\n  --application-type web\n\n# Recuperer la connection string\nAPPINSIGHTS_CONN=$(az monitor app-insights component show \\\n  --app bank-churn-insights \\\n  --resource-group $RESOURCE_GROUP \\\n  --query connectionString -o tsv)\n\necho \"Connection String : $APPINSIGHTS_CONN\"\n\n# Ajouter la variable d'environnement a Container Apps\naz containerapp update \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --set-env-vars \"APPLICATIONINSIGHTS_CONNECTION_STRING=$APPINSIGHTS_CONN\"\n\n\n8.3 Intégration du Monitoring dans le Code\nAjoutez dans requirements.txt :\nopencensus-ext-azure==1.1.9\nopencensus-ext-requests==0.12.1\nModifiez app/main.py pour ajouter le monitoring :\nimport os\nfrom opencensus.ext.azure.log_exporter import AzureLogHandler\nimport logging\n\n# Configuration du logging avec Application Insights\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n\nAPPINSIGHTS_CONN = os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\")\nif APPINSIGHTS_CONN:\n    logger.addHandler(AzureLogHandler(connection_string=APPINSIGHTS_CONN))\n    logger.info(\"Application Insights connecte\")\n\n\n8.4 Détection de Data Drift\nCréez le fichier drift_detection.py :\nimport pandas as pd\nfrom scipy.stats import ks_2samp\nimport json\n\ndef detect_drift(reference_file, production_file, threshold=0.05):\n    \"\"\"\n    Detecte le drift entre donnees de reference et production\n    \"\"\"\n    ref_data = pd.read_csv(reference_file)\n    prod_data = pd.read_csv(production_file)\n    \n    drift_results = {}\n    \n    for column in ref_data.columns:\n        if column in prod_data.columns and column != 'Exited':\n            # Test de Kolmogorov-Smirnov\n            statistic, p_value = ks_2samp(\n                ref_data[column].dropna(),\n                prod_data[column].dropna()\n            )\n            \n            drift_detected = p_value &lt; threshold\n            \n            drift_results[column] = {\n                'p_value': float(p_value),\n                'statistic': float(statistic),\n                'drift_detected': drift_detected\n            }\n    \n    # Rapport\n    drifted_features = [f for f, r in drift_results.items() if r['drift_detected']]\n    \n    print(\"=\"*50)\n    print(\"DATA DRIFT DETECTION REPORT\")\n    print(\"=\"*50)\n    print(f\"Threshold: {threshold}\")\n    print(f\"Features analyzed: {len(drift_results)}\")\n    print(f\"Features with drift: {len(drifted_features)}\")\n    print(\"\\nDrifted features:\")\n    for feature in drifted_features:\n        print(f\"  - {feature}: p-value = {drift_results[feature]['p_value']:.4f}\")\n    print(\"=\"*50)\n    \n    return drift_results\n\nif __name__ == \"__main__\":\n    results = detect_drift(\n        \"data/bank_churn.csv\",\n        \"data/production_data.csv\"\n    )\n    \n    # Sauvegarder les resultats\n    with open(\"drift_report.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n    \n    print(\"\\nRapport sauvegarde dans drift_report.json\")\n\n\n8.5 Checkpoint\n\n\n\n\n\n\nNoteValidation Module 6\n\n\n\nAvant de passer au module suivant, vérifiez que :\n\n\nApplication Insights est configuré\nLes logs apparaissent dans Azure Portal\nVous pouvez visualiser les métriques\nLe script de détection de drift fonctionne"
  },
  {
    "objectID": "index.html#sec-module7",
    "href": "index.html#sec-module7",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "9 Module 7 : Optimisations et Bonnes Pratiques",
    "text": "9 Module 7 : Optimisations et Bonnes Pratiques\n\n9.1 Objectif\nAméliorer les performances, la sécurité et la maintenabilité de l’application.\n\n\n9.2 Ajout d’un Cache pour les Prédictions\nModifiez app/main.py :\nfrom functools import lru_cache\nimport hashlib\nimport json\n\ndef hash_features(features_dict: dict) -&gt; str:\n    \"\"\"Cree un hash unique pour les features\"\"\"\n    return hashlib.md5(\n        json.dumps(features_dict, sort_keys=True).encode()\n    ).hexdigest()\n\n# Cache pour les predictions (1000 dernieres)\n@lru_cache(maxsize=1000)\ndef predict_cached(features_hash: str, features_json: str):\n    features_dict = json.loads(features_json)\n    input_data = np.array([[\n        features_dict[\"CreditScore\"],\n        features_dict[\"Age\"],\n        # ... autres features\n    ]])\n    \n    proba = model.predict_proba(input_data)[0, 1]\n    prediction = int(proba &gt; 0.5)\n    \n    if proba &lt; 0.3:\n        risk = \"Low\"\n    elif proba &lt; 0.7:\n        risk = \"Medium\"\n    else:\n        risk = \"High\"\n    \n    return {\n        \"churn_probability\": round(float(proba), 4),\n        \"prediction\": prediction,\n        \"risk_level\": risk\n    }\n\n@app.post(\"/predict\", response_model=PredictionResponse)\ndef predict(features: CustomerFeatures):\n    features_dict = features.dict()\n    features_hash = hash_features(features_dict)\n    features_json = json.dumps(features_dict)\n    \n    # Utilise le cache si disponible\n    result = predict_cached(features_hash, features_json)\n    \n    logger.info(f\"Prediction - Hash: {features_hash[:8]}\")\n    return result\n\n\n9.3 Checklist de Production\n\n\n\n\n\n\nTipChecklist Avant Production\n\n\n\n\nTests unitaires avec coverage &gt; 80%\nTests d’integration\nLoad testing effectue\nMonitoring configure\nAlertes definies\nLogs centralises\nDocumentation API complete\nHTTPS active\nHealth checks fonctionnels\nAuto-scaling teste\nVariables d’environnement securisees\nBudget Azure surveille\n\n\n\n\n\n9.4 Checkpoint Final\n\n\n\n\n\n\nNoteValidation Module 7\n\n\n\n\n\nCache de predictions implemente\nDocumentation complete\nTous les tests passent\nChecklist de production verifiee"
  },
  {
    "objectID": "index.html#sec-nettoyage",
    "href": "index.html#sec-nettoyage",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "10 Nettoyage des Ressources Azure",
    "text": "10 Nettoyage des Ressources Azure\n\n10.1 IMPORTANT - Suppression pour Éviter les Coûts\n\n\n\n\n\n\nWarningATTENTION - À FAIRE À LA FIN DU WORKSHOP\n\n\n\nPour éviter de consommer votre budget de 100$, supprimez toutes les ressources :\n# Suppression du groupe de ressources (supprime tout)\naz group delete --name $RESOURCE_GROUP --yes --no-wait\n\n# Verification\naz group list --output table\nCette commande supprime : - Azure Container Registry - Azure Container Apps - Application Insights - Tous les logs et données\nTemps de suppression : 5-10 minutes\n\n\n\n\n10.2 Script de Nettoyage Automatique\nCréez cleanup.sh :\n#!/bin/bash\n\nRESOURCE_GROUP=\"rg-mlops-workshop\"\n\necho \"==========================================\"\necho \"Nettoyage des ressources Azure\"\necho \"==========================================\"\n\nread -p \"Voulez-vous vraiment supprimer toutes les ressources ? (yes/no): \" confirm\n\nif [ \"$confirm\" != \"yes\" ]; then\n    echo \"Operation annulee.\"\n    exit 0\nfi\n\necho \"\\nRessources a supprimer:\"\naz resource list --resource-group $RESOURCE_GROUP --output table\n\necho \"\\nSuppression en cours...\"\naz group delete --name $RESOURCE_GROUP --yes --no-wait\n\necho \"\\nSuppression lancee (prend 5-10 minutes)\"\necho \"Verifiez sur : https://portal.azure.com\"\n# Rendre executable et lancer\nchmod +x cleanup.sh\n./cleanup.sh"
  },
  {
    "objectID": "index.html#sec-recapitulatif",
    "href": "index.html#sec-recapitulatif",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "11 Récapitulatif du Workshop",
    "text": "11 Récapitulatif du Workshop\n\n11.1 Ce que Vous Avez Accompli\nFélicitations ! Vous avez déployé un système MLOps complet :\nArchitecture Finale :\nML Training → FastAPI → Docker → Azure Container Registry → Azure Container Apps\n↑ GitHub Actions CI/CD\n↑ Application Insights Monitoring\n\n\n11.2 Compétences Acquises\n\nMachine Learning\n\nEntraînement d’un modèle Random Forest\nÉvaluation avec métriques appropriées\nTracking avec MLflow\n\nDéveloppement d’API\n\nCréation d’API REST avec FastAPI\nValidation des données avec Pydantic\nDocumentation automatique\n\nConteneurisation\n\nDockerfiles optimisés\nBonnes pratiques de sécurité\nGestion des images\n\nCloud Azure\n\nAzure Container Registry\nAzure Container Apps\nApplication Insights\n\nDevOps/MLOps\n\nPipelines CI/CD avec GitHub Actions\nTests automatisés\nDéploiement continu\n\nMonitoring et Maintenance\n\nLogs centralisés\nMétriques de performance\nDétection de data drift\n\n\n\n\n11.3 Points Clés à Retenir\n\n\n\n\n\n\nImportantLecons Importantes\n\n\n\n\nMLOps = DevOps + ML : Automatisation du cycle de vie complet\nConteneurisation : Portabilité et reproductibilité\nTests : Essentiels pour la fiabilité\nMonitoring : Indispensable en production\nDocumentation : Facilite la collaboration\nSécurité : À considérer dès le début\nCoûts : Toujours surveiller l’utilisation cloud"
  },
  {
    "objectID": "index.html#sec-faq",
    "href": "index.html#sec-faq",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "12 FAQ - Foire Aux Questions",
    "text": "12 FAQ - Foire Aux Questions\n\n12.1 Questions Techniques\nQ1 : Mon API est lente, comment l’optimiser ?\nR : Plusieurs options : - Activer le cache des prédictions - Utiliser des prédictions batch - Optimiser le modèle (quantization, pruning) - Augmenter les ressources CPU/RAM\nQ2 : Comment gérer plusieurs versions de modèles ?\nR : Utilisez MLflow Model Registry et créez des endpoints différents (v1, v2).\nQ3 : Comment implémenter un rollback ?\nR : Conservez les anciennes images Docker avec tags et utilisez :\naz containerapp update \\\n  --name $APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --image $ACR_NAME.azurecr.io/bank-churn-api:v1  # Version precedente\nQ4 : Mon budget Azure est presque épuisé, que faire ?\nR : - Mettre min-replicas à 0 - Utiliser des SKU Basic - Supprimer les ressources inutilisées - Activer les budgets alerts\n\n\n12.2 Questions de Compréhension\nQ5 : Quelle est la différence entre Docker et Kubernetes ?\nR : Docker conteneurise les applications, Kubernetes les orchestre (scaling, load balancing, self-healing).\nQ6 : Pourquoi utiliser FastAPI plutôt que Flask ?\nR : FastAPI est plus rapide, avec validation automatique, documentation auto-générée, et support async natif.\nQ7 : Qu’est-ce que le data drift ?\nR : Changement dans la distribution des données d’entrée par rapport aux données d’entraînement, pouvant dégrader les performances du modèle."
  },
  {
    "objectID": "index.html#sec-conclusion",
    "href": "index.html#sec-conclusion",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "13 Conclusion",
    "text": "13 Conclusion\n\n13.1 Félicitations !\nVous avez terminé ce workshop intensif de MLOps avec Azure. Vous avez construit un système complet de déploiement de modèle de Machine Learning en production, avec toutes les bonnes pratiques de l’industrie.\n\n\n13.2 Prochaines Étapes\n\nPratiquez : Refaites le workshop avec un dataset différent\nPartagez : Mettez votre projet sur GitHub\nAméliorez : Implémentez les fonctionnalités avancées\nCertifiez-vous : Préparez les certifications Azure\n\n\nBon Apprentissage et Bon Déploiement !\nCe guide vous a accompagné dans votre premier projet MLOps.\nContinuez à explorer, à apprendre et à innover.\n\nVersion 1.0 - Novembre 2025\nWorkshop MLOps avec Azure ## Test de déploiement - jeu. 20 nov. 2025 03:26:42"
  }
]