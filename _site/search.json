[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "",
    "text": "Ce workshop vous guidera √† travers le d√©ploiement complet d‚Äôun mod√®le de Machine Learning en production sur Microsoft Azure. Vous allez construire une API de pr√©diction de d√©faillance client (churn) et la d√©ployer sur le cloud avec toutes les bonnes pratiques MLOps.\n\n\n\n√Ä la fin de ce workshop, vous serez capable de :\n\nEntra√Æner et sauvegarder un mod√®le ML avec MLflow\nCr√©er une API REST avec FastAPI\nConteneuriser une application avec Docker\nD√©ployer sur Azure Container Apps\nMettre en place un pipeline CI/CD avec GitHub Actions\nMonitorer votre application en production\nD√©tecter le data drift\n\n\n\n\nContexte : Une banque souhaite pr√©dire quels clients risquent de partir pour proposer des actions de r√©tention.\nDataset : 10 features (√¢ge, score cr√©dit, solde, etc.) + 1 target (Exited : 0/1)\nMod√®le : Random Forest Classifier\nLivrable : API REST d√©ploy√©e sur Azure, accessible publiquement\n\n\n\nFlux de d√©ploiement :\nCode GitHub ‚Üí GitHub Actions ‚Üí Docker Build ‚Üí Azure Container Registry ‚Üí Azure Container Apps ‚Üí Internet"
  },
  {
    "objectID": "index.html#sec-introduction",
    "href": "index.html#sec-introduction",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "",
    "text": "Ce workshop vous guidera √† travers le d√©ploiement complet d‚Äôun mod√®le de Machine Learning en production sur Microsoft Azure. Vous allez construire une API de pr√©diction de d√©faillance client (churn) et la d√©ployer sur le cloud avec toutes les bonnes pratiques MLOps.\n\n\n\n√Ä la fin de ce workshop, vous serez capable de :\n\nEntra√Æner et sauvegarder un mod√®le ML avec MLflow\nCr√©er une API REST avec FastAPI\nConteneuriser une application avec Docker\nD√©ployer sur Azure Container Apps\nMettre en place un pipeline CI/CD avec GitHub Actions\nMonitorer votre application en production\nD√©tecter le data drift\n\n\n\n\nContexte : Une banque souhaite pr√©dire quels clients risquent de partir pour proposer des actions de r√©tention.\nDataset : 10 features (√¢ge, score cr√©dit, solde, etc.) + 1 target (Exited : 0/1)\nMod√®le : Random Forest Classifier\nLivrable : API REST d√©ploy√©e sur Azure, accessible publiquement\n\n\n\nFlux de d√©ploiement :\nCode GitHub ‚Üí GitHub Actions ‚Üí Docker Build ‚Üí Azure Container Registry ‚Üí Azure Container Apps ‚Üí Internet"
  },
  {
    "objectID": "index.html#sec-preparation",
    "href": "index.html#sec-preparation",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "2 Pr√©paration de l‚ÄôEnvironnement",
    "text": "2 Pr√©paration de l‚ÄôEnvironnement\n\n2.1 Logiciels Requis\nObligatoire :\n\nPython 3.9+ : https://www.python.org/downloads/\nVisual Studio Code : https://code.visualstudio.com/\nGit : https://git-scm.com/downloads\nDocker Desktop : https://www.docker.com/products/docker-desktop\nAzure CLI : https://docs.microsoft.com/cli/azure/install-azure-cli\n\nComptes √† cr√©er :\n\nCompte GitHub : https://github.com/signup\nAzure for Students (100$) : https://azure.microsoft.com/students\n\n\n\n2.2 V√©rification de l‚ÄôInstallation\nOuvrez un terminal et testez :\n# Python\npython --version\n# Doit afficher Python 3.9.x ou superieur\n\n# Git\ngit --version\n\n# Docker\ndocker --version\ndocker ps\n\n# Azure CLI\naz --version\n\n\n2.3 Configuration Initiale\n\n2.3.1 Configuration Git\ngit config --global user.name \"Votre Nom\"\ngit config --global user.email \"votre.email@example.com\"\n\n\n2.3.2 Connexion √† Azure\n# Se connecter a Azure\naz login\n\n# Verifier l'abonnement\naz account show\n\n# Si vous avez plusieurs abonnements, selectionner celui de Students\naz account set --subscription \"Azure for Students\""
  },
  {
    "objectID": "index.html#sec-module1",
    "href": "index.html#sec-module1",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "3 Module 1 : Entra√Ænement du Mod√®le",
    "text": "3 Module 1 : Entra√Ænement du Mod√®le\n\n3.1 Objectif\nEntra√Æner un mod√®le Random Forest pour pr√©dire le churn et le sauvegarder avec MLflow.\n\n\n3.2 Pr√©paration du Projet\n# Creer le dossier du projet\nmkdir bank-churn-mlops\ncd bank-churn-mlops\n\n# Creer un environnement virtuel\npython -m venv venv\n\n# Activer l'environnement\n# Windows :\nvenv\\Scripts\\activate\n# Mac/Linux :\nsource venv/bin/activate\n\n# Creer la structure\nmkdir -p data model app tests\ntouch requirements.txt\n\n\n3.3 Fichier requirements.txt\nCr√©ez le fichier requirements.txt avec le contenu suivant :\n# API Framework\nfastapi==0.104.1\nuvicorn[standard]==0.24.0\npydantic==2.5.0\n\n# Machine Learning\nscikit-learn==1.3.2\npandas==2.1.3\nnumpy==1.26.2\njoblib==1.3.2\n\n# MLflow\nmlflow==2.8.1\n\n# Testing\npytest==7.4.3\npytest-cov==4.1.0\nhttpx==0.25.2\n\n# Utilities\npython-multipart==0.0.6\nrequests==2.31.0\nPuis installez les d√©pendances :\npip install -r requirements.txt\n\n\n3.4 T√©l√©chargement du Dataset\nCr√©ez un dataset synth√©tique :\n# generate_data.py\nimport pandas as pd\nimport numpy as np\n\nnp.random.seed(42)\nn_samples = 10000\n\ndata = {\n    'CreditScore': np.random.randint(300, 850, n_samples),\n    'Age': np.random.randint(18, 80, n_samples),\n    'Tenure': np.random.randint(0, 11, n_samples),\n    'Balance': np.random.uniform(0, 200000, n_samples),\n    'NumOfProducts': np.random.randint(1, 5, n_samples),\n    'HasCrCard': np.random.choice([0, 1], n_samples),\n    'IsActiveMember': np.random.choice([0, 1], n_samples),\n    'EstimatedSalary': np.random.uniform(20000, 150000, n_samples),\n    'Geography_Germany': np.random.choice([0, 1], n_samples),\n    'Geography_Spain': np.random.choice([0, 1], n_samples),\n}\n\n# Target : plus de chance de partir si inactif, peu de produits, etc.\nchurn_prob = (\n    (1 - data['IsActiveMember']) * 0.3 +\n    (data['NumOfProducts'] == 1) * 0.2 +\n    (data['Age'] &gt; 60) * 0.15 +\n    (data['Balance'] == 0) * 0.25\n)\ndata['Exited'] = (np.random.random(n_samples) &lt; churn_prob).astype(int)\n\ndf = pd.DataFrame(data)\ndf.to_csv('data/bank_churn.csv', index=False)\nprint(f\"Dataset cree : {len(df)} lignes\")\nprint(f\"Taux de churn : {df['Exited'].mean():.2%}\")\n\n\n3.5 Script d‚ÄôEntra√Ænement\nCr√©ez le fichier train_model.py :\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, \n    precision_score, \n    recall_score,\n    f1_score, \n    roc_auc_score,\n    confusion_matrix\n)\nimport joblib\nimport mlflow\nimport mlflow.sklearn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configuration MLflow\nmlflow.set_tracking_uri(\"./mlruns\")\nmlflow.set_experiment(\"bank-churn-prediction\")\n\nprint(\"Chargement des donnees...\")\ndf = pd.read_csv(\"data/bank_churn.csv\")\n\nprint(f\"Dataset : {len(df)} lignes, {len(df.columns)} colonnes\")\nprint(f\"Taux de churn : {df['Exited'].mean():.2%}\")\n\n# Separation features/target\nX = df.drop('Exited', axis=1)\ny = df['Exited']\n\n# Split train/test (80/20)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(f\"\\nTrain : {len(X_train)} lignes\")\nprint(f\"Test : {len(X_test)} lignes\")\n\n# Entrainement avec MLflow tracking\nprint(\"\\nEntrainement du modele...\")\nwith mlflow.start_run(run_name=\"random-forest-v1\"):\n    \n    # Parametres du modele\n    params = {\n        'n_estimators': 100,\n        'max_depth': 10,\n        'min_samples_split': 5,\n        'random_state': 42\n    }\n    \n    # Entrainement\n    model = RandomForestClassifier(**params)\n    model.fit(X_train, y_train)\n    \n    # Predictions\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    \n    # Calcul des metriques\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    \n    # Log des parametres et metriques dans MLflow\n    mlflow.log_params(params)\n    mlflow.log_metrics({\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1_score\": f1,\n        \"roc_auc\": auc\n    })\n    \n    # Creation et sauvegarde de la matrice de confusion\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title('Matrice de Confusion')\n    plt.ylabel('Vraie Classe')\n    plt.xlabel('Classe Predite')\n    plt.savefig('confusion_matrix.png')\n    mlflow.log_artifact('confusion_matrix.png')\n    plt.close()\n    \n    # Feature importance\n    feature_importance = pd.DataFrame({\n        'feature': X.columns,\n        'importance': model.feature_importances_\n    }).sort_values('importance', ascending=False)\n    \n    plt.figure(figsize=(10, 6))\n    plt.barh(feature_importance['feature'], feature_importance['importance'])\n    plt.xlabel('Importance')\n    plt.title('Feature Importance')\n    plt.tight_layout()\n    plt.savefig('feature_importance.png')\n    mlflow.log_artifact('feature_importance.png')\n    plt.close()\n    \n    # Enregistrement du modele dans MLflow\n    mlflow.sklearn.log_model(\n        model,\n        \"model\",\n        registered_model_name=\"bank-churn-classifier\"\n    )\n    \n    # Sauvegarde locale du modele\n    joblib.dump(model, \"model/churn_model.pkl\")\n    \n    # Tags\n    mlflow.set_tags({\n        \"environment\": \"development\",\n        \"model_type\": \"RandomForest\",\n        \"task\": \"binary_classification\"\n    })\n    \n    # Affichage des resultats\n    print(\"\\n\" + \"=\"*50)\n    print(\"RESULTATS DE L'ENTRAINEMENT\")\n    print(\"=\"*50)\n    print(f\"Accuracy  : {accuracy:.4f}\")\n    print(f\"Precision : {precision:.4f}\")\n    print(f\"Recall    : {recall:.4f}\")\n    print(f\"F1 Score  : {f1:.4f}\")\n    print(f\"ROC AUC   : {auc:.4f}\")\n    print(\"=\"*50)\n    \n    print(f\"\\nModele sauvegarde dans : model/churn_model.pkl\")\n    print(f\"MLflow UI : mlflow ui --port 5000\")\n\n\n3.6 Ex√©cution\n# Lancer l'entrainement\npython train_model.py\n\n# Voir les resultats dans MLflow UI\nmlflow ui --port 5000\n# Ouvrir http://localhost:5000 dans votre navigateur\n\n\n3.7 Checkpoint\n\n\n\n\n\n\nNoteValidation Module 1\n\n\n\nAvant de passer au module suivant, v√©rifiez que :\n\n\nLe mod√®le est entra√Æn√© avec une accuracy &gt; 0.75\nLe fichier model/churn_model.pkl existe\nMLflow UI affiche votre exp√©rience\nVous comprenez les m√©triques obtenues"
  },
  {
    "objectID": "index.html#sec-module2",
    "href": "index.html#sec-module2",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "4 Module 2 : Cr√©ation de l‚ÄôAPI avec FastAPI",
    "text": "4 Module 2 : Cr√©ation de l‚ÄôAPI avec FastAPI\n\n4.1 Objectif\nCr√©er une API REST qui expose le mod√®le via des endpoints HTTP.\n\n\n4.2 Structure du Code API\nbank-churn-mlops/\n|-- app/\n|   |-- __init__.py\n|   |-- main.py\n|   |-- models.py\n|   +-- utils.py\n|-- model/\n|   +-- churn_model.pkl\n|-- tests/\n|   +-- test_api.py\n|-- requirements.txt\n+-- README.md\n\n\n4.3 Fichier app/models.py\nD√©finition des sch√©mas de donn√©es avec Pydantic :\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass CustomerFeatures(BaseModel):\n    \"\"\"Schema pour les features d'un client\"\"\"\n    CreditScore: int = Field(..., ge=300, le=850, description=\"Score de credit\")\n    Age: int = Field(..., ge=18, le=100, description=\"Age du client\")\n    Tenure: int = Field(..., ge=0, le=10, description=\"Anciennete en annees\")\n    Balance: float = Field(..., ge=0, description=\"Solde du compte\")\n    NumOfProducts: int = Field(..., ge=1, le=4, description=\"Nombre de produits\")\n    HasCrCard: int = Field(..., ge=0, le=1, description=\"Possession carte credit\")\n    IsActiveMember: int = Field(..., ge=0, le=1, description=\"Membre actif\")\n    EstimatedSalary: float = Field(..., ge=0, description=\"Salaire estime\")\n    Geography_Germany: int = Field(..., ge=0, le=1, description=\"Client allemand\")\n    Geography_Spain: int = Field(..., ge=0, le=1, description=\"Client espagnol\")\n    \n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"CreditScore\": 650,\n                \"Age\": 35,\n                \"Tenure\": 5,\n                \"Balance\": 50000,\n                \"NumOfProducts\": 2,\n                \"HasCrCard\": 1,\n                \"IsActiveMember\": 1,\n                \"EstimatedSalary\": 75000,\n                \"Geography_Germany\": 0,\n                \"Geography_Spain\": 1\n            }\n        }\n\nclass PredictionResponse(BaseModel):\n    \"\"\"Schema pour la reponse de prediction\"\"\"\n    churn_probability: float = Field(..., description=\"Probabilite de churn (0-1)\")\n    prediction: int = Field(..., description=\"Prediction binaire (0=reste, 1=part)\")\n    risk_level: str = Field(..., description=\"Niveau de risque (Low/Medium/High)\")\n\nclass HealthResponse(BaseModel):\n    \"\"\"Schema pour le health check\"\"\"\n    status: str\n    model_loaded: bool\n\n\n4.4 Fichier app/main.py\nL‚ÄôAPI principale :\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nimport joblib\nimport numpy as np\nfrom typing import List\nimport logging\nimport os\n\nfrom app.models import CustomerFeatures, PredictionResponse, HealthResponse\n\n# Configuration du logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Initialisation FastAPI\napp = FastAPI(\n    title=\"Bank Churn Prediction API\",\n    description=\"API de prediction de defaillance client\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\"\n)\n\n# CORS pour permettre les requetes depuis un navigateur\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Chargement du modele au demarrage\nMODEL_PATH = os.getenv(\"MODEL_PATH\", \"model/churn_model.pkl\")\nmodel = None\n\n@app.on_event(\"startup\")\nasync def load_model():\n    \"\"\"Charge le modele au demarrage de l'API\"\"\"\n    global model\n    try:\n        model = joblib.load(MODEL_PATH)\n        logger.info(f\"Modele charge avec succes depuis {MODEL_PATH}\")\n    except Exception as e:\n        logger.error(f\"Erreur lors du chargement du modele : {e}\")\n        model = None\n\n@app.get(\"/\", tags=[\"General\"])\ndef root():\n    \"\"\"Endpoint racine\"\"\"\n    return {\n        \"message\": \"Bank Churn Prediction API\",\n        \"version\": \"1.0.0\",\n        \"status\": \"running\",\n        \"docs\": \"/docs\"\n    }\n\n@app.get(\"/health\", response_model=HealthResponse, tags=[\"General\"])\ndef health_check():\n    \"\"\"Verification de l'etat de l'API\"\"\"\n    if model is None:\n        raise HTTPException(\n            status_code=503, \n            detail=\"Modele non charge\"\n        )\n    return {\n        \"status\": \"healthy\",\n        \"model_loaded\": True\n    }\n\n@app.post(\"/predict\", response_model=PredictionResponse, tags=[\"Prediction\"])\ndef predict(features: CustomerFeatures):\n    \"\"\"\n    Predit si un client va partir (churn)\n    \n    Retourne :\n    - churn_probability : probabilite de churn (0 a 1)\n    - prediction : 0 (reste) ou 1 (part)\n    - risk_level : Low, Medium ou High\n    \"\"\"\n    if model is None:\n        raise HTTPException(\n            status_code=503, \n            detail=\"Modele non disponible\"\n        )\n    \n    try:\n        # Preparation des features\n        input_data = np.array([[\n            features.CreditScore,\n            features.Age,\n            features.Tenure,\n            features.Balance,\n            features.NumOfProducts,\n            features.HasCrCard,\n            features.IsActiveMember,\n            features.EstimatedSalary,\n            features.Geography_Germany,\n            features.Geography_Spain\n        ]])\n        \n        # Prediction\n        proba = model.predict_proba(input_data)[0, 1]\n        prediction = int(proba &gt; 0.5)\n        \n        # Classification du risque\n        if proba &lt; 0.3:\n            risk = \"Low\"\n        elif proba &lt; 0.7:\n            risk = \"Medium\"\n        else:\n            risk = \"High\"\n        \n        logger.info(\n            f\"Prediction effectuee : proba={proba:.4f}, \"\n            f\"prediction={prediction}, risk={risk}\"\n        )\n        \n        return {\n            \"churn_probability\": round(float(proba), 4),\n            \"prediction\": prediction,\n            \"risk_level\": risk\n        }\n    \n    except Exception as e:\n        logger.error(f\"Erreur lors de la prediction : {e}\")\n        raise HTTPException(\n            status_code=500, \n            detail=f\"Erreur de prediction : {str(e)}\"\n        )\n\n@app.post(\"/predict/batch\", tags=[\"Prediction\"])\ndef predict_batch(features_list: List[CustomerFeatures]):\n    \"\"\"\n    Predictions en batch pour plusieurs clients\n    \"\"\"\n    if model is None:\n        raise HTTPException(status_code=503, detail=\"Modele non disponible\")\n    \n    try:\n        predictions = []\n        \n        for features in features_list:\n            input_data = np.array([[\n                features.CreditScore, features.Age, features.Tenure,\n                features.Balance, features.NumOfProducts, features.HasCrCard,\n                features.IsActiveMember, features.EstimatedSalary,\n                features.Geography_Germany, features.Geography_Spain\n            ]])\n            \n            proba = model.predict_proba(input_data)[0, 1]\n            prediction = int(proba &gt; 0.5)\n            \n            predictions.append({\n                \"churn_probability\": round(float(proba), 4),\n                \"prediction\": prediction\n            })\n        \n        logger.info(f\"Batch prediction : {len(predictions)} clients traites\")\n        \n        return {\"predictions\": predictions, \"count\": len(predictions)}\n    \n    except Exception as e:\n        logger.error(f\"Erreur batch prediction : {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n\n\n4.5 Test Local de l‚ÄôAPI\n# Demarrer l'API\nuvicorn app.main:app --reload --port 8000\n\n# Dans un autre terminal, tester :\n\n# 1. Health check\ncurl http://localhost:8000/health\n\n# 2. Prediction simple\ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n  }'\n\n\n4.6 Jupyter Lab\n#dans jupyter lab\nimport requests\nimport json\n\n# URL de ton API FastAPI\nurl = \"http://localhost:8000/predict\"\n\n# Donn√©es √† envoyer\ndata = {\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n}\n\n# Envoyer la requ√™te POST\nresponse = requests.post(url, json=data)\n\n# Afficher la r√©ponse\nprint(f\"Status Code: {response.status_code}\")\nprint(f\"Response: {response.json()}\")\n\n\n4.7 Documentation Interactive\nOuvrez votre navigateur et allez sur :\n\nSwagger UI : http://localhost:8000/docs\nReDoc : http://localhost:8000/redoc\n\n\n\n4.8 Checkpoint\n\n\n\n\n\n\nNoteValidation Module 2\n\n\n\nAvant de passer au module suivant, v√©rifiez que :\n\n\nLe mod√®le est entra√Æn√© avec une accuracy &gt; 0.75\nLe fichier model/churn_model.pkl existe\n\nMLflow UI affiche votre exp√©rience\nVous comprenez les m√©triques obtenues"
  },
  {
    "objectID": "index.html#sec-module3",
    "href": "index.html#sec-module3",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "5 Module 3 : Conteneurisation avec Docker",
    "text": "5 Module 3 : Conteneurisation avec Docker\n\n5.1 Objectif\nEmpaqueter l‚ÄôAPI dans un conteneur Docker pour la rendre portable et faciliter le d√©ploiement sur Azure.\n\n\n5.2 Cr√©ation du Dockerfile\nCr√©ez le fichier Dockerfile √† la racine du projet :\n# Utilise une image Python officielle\nFROM python:3.9-slim\n\n# Definir le repertoire de travail\nWORKDIR /app\n\n# Copier les fichiers de dependances\nCOPY requirements.txt .\n\n# Installer les dependances\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copier le code de l'application\nCOPY app/ ./app/\nCOPY model/ ./model/\n\n# Exposer le port\nEXPOSE 8000\n\n# Commande pour demarrer l'application\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n\n\n5.3 Cr√©ation du .dockerignore\nCr√©ez le fichier .dockerignore :\n__pycache__\n*.pyc\n*.pyo\n*.pyd\n.Python\nenv/\nvenv/\n.venv\n*.egg-info/\n.pytest_cache/\n.git\n.gitignore\nREADME.md\n.env\nmlruns/\n*.log\n.DS_Store\n.vscode/\ntests/\n\n\n5.4 Build de l‚ÄôImage Docker\n# Build de l'image (cela peut prendre quelques minutes)\ndocker build -t bank-churn-api:v1 .\n\n# Verifier que l'image est creee\ndocker images bank-churn-api:v1\n\n# Voir la taille de l'image\ndocker images --format \"table {{.Repository}}\\t{{.Tag}}\\t{{.Size}}\" | grep bank-churn\n\n\n5.5 Test du Conteneur en Local\n# Lancer le conteneur\ndocker run -d -p 8000:8000 --name churn-api bank-churn-api:v1\n\n# Verifier que le conteneur tourne\ndocker ps\n\n# Voir les logs\ndocker logs churn-api\n\n# Tester l'API\ncurl http://localhost:8000/health\n\n# Prediction de test\ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 700,\n    \"Age\": 40,\n    \"Tenure\": 7,\n    \"Balance\": 80000,\n    \"NumOfProducts\": 3,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 0,\n    \"EstimatedSalary\": 90000,\n    \"Geography_Germany\": 1,\n    \"Geography_Spain\": 0\n  }'\n\n# Arreter et supprimer le conteneur\ndocker stop churn-api\ndocker rm churn-api\n\n\n5.6 Commandes Docker Utiles\n# Voir tous les conteneurs (meme arretes)\ndocker ps -a\n\n# Entrer dans un conteneur en cours d'execution\ndocker exec -it churn-api /bin/bash\n\n# Voir l'utilisation des ressources\ndocker stats churn-api\n\n# Nettoyer les images inutilisees\ndocker image prune\n\n# Supprimer toutes les images\ndocker rmi $(docker images -q)\n\n\n5.7 Questions de Compr√©hension\n\nPourquoi utiliser un .dockerignore ?\nQuelle est la diff√©rence entre CMD et RUN dans un Dockerfile ?\nPourquoi exposer le port 8000 ?\nComment v√©rifier que votre conteneur fonctionne correctement ?\n\n\n\n5.8 Checkpoint\n\n\n\n\n\n\nNoteValidation Module 3\n\n\n\nAvant de passer au module suivant, v√©rifiez que :\n\n\nL‚Äôimage Docker est build√©e avec succ√®s\nLe conteneur d√©marre sans erreur\nL‚ÄôAPI r√©pond correctement depuis le conteneur\nLa taille de l‚Äôimage est raisonnable (&lt; 1GB)"
  },
  {
    "objectID": "index.html#sec-module4",
    "href": "index.html#sec-module4",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "6 Module 4 : D√©ploiement sur Azure",
    "text": "6 Module 4 : D√©ploiement sur Azure\n\n6.1 Objectif\nD√©ployer l‚ÄôAPI sur Azure Container Apps et la rendre accessible publiquement.\n\n\n6.2 Pr√©requis\n\nDocker Desktop en cours d‚Äôex√©cution (mode WSL2 recommand√©)\nConfigurer Docker \nAzure CLI install√© et connect√© (az login)\nImage locale churn-api:v1 d√©j√† construite\ninstaller l‚Äôextension containerapp\n\n az extension add --name containerapp\n\n\n6.3 Etape 0 : V√©rifier les r√©gions disponibles\n#!/bin/bash\n# M√©thodesimple \n\n# Liste toutes les r√©gions recommand√©es\necho \"R√©gions disponibles chez toi :\"\naz account list-locations \\\n  --query \"[?metadata.regionCategory=='Recommended'].name\" \\\n  -o tsv | head -5\n\n# Prendre la premi√®re\nREGION=$(az account list-locations \\\n  --query \"[?metadata.regionCategory=='Recommended'].name\" \\\n  -o tsv | head -1)\n\necho \"‚úÖ proposition de la r√©gion : $REGION\"\nOn Peut aussi √©x√©cuter\n# Juste cette ligne dans ton terminal :\nLOCATION=$(az account list-locations --query \"[0].name\" -o tsv) && echo \"Use: $REGION\"\n\n\n6.4 Script Complet :\n#!/usr/bin/env bash\nset -euo pipefail\n#################################\n# VARIABLES D√âFINITIVES\n#################################\nRESOURCE_GROUP=\"rg-mlops\"  \nLOCATION=\"westeurope\"   # Forc√© West Europe (garanti)\nFALLBACK_LOCATION=\"northeurope\"     # Fallback garanti\nACR_NAME=\"mlops$(whoami | tr '[:upper:]' '[:lower:]' | tr -cd '[:alnum:]')\"  # 100% minuscules\nCONTAINER_APP_NAME=\"bank-churn\" \nCONTAINERAPPS_ENV=\"env-mlops-workshop\"\nIMAGE_NAME=\"bank-churn-api\"\nIMAGE_TAG=\"v1\"\nTARGET_PORT=8000\n\n#################################\n# 0) Contexte Azure + V√©rification Extensions\n#################################\necho \"V√©rification du contexte Azure...\"\naz account show --query \"{name:name, cloudName:cloudName}\" -o json &gt;/dev/null\n\necho \"V√©rification/installation des extensions Azure CLI...\"\n\n# V√©rifier et installer containerapp si n√©cessaire\nif ! az extension show --name containerapp &gt;/dev/null 2&gt;&1; then\n    echo \"üì¶ Installation de l'extension containerapp...\"\n    az extension add --name containerapp --upgrade -y --only-show-errors\n    echo \"‚úÖ Extension containerapp install√©e\"\nelse\n    echo \"‚úÖ Extension containerapp d√©j√† install√©e\"\n    # Mise √† jour silencieuse\n    az extension update --name containerapp -y --only-show-errors 2&gt;/dev/null || true\nfi\n\n# Liste des extensions install√©es pour v√©rification\necho \"Extensions install√©es :\"\naz extension list --query \"[].{Name:name, Version:version}\" -o table\n\n#################################\n# 1) Providers n√©cessaires\n#################################\necho \"Register providers...\"\naz provider register --namespace Microsoft.ContainerRegistry --wait\naz provider register --namespace Microsoft.App --wait\naz provider register --namespace Microsoft.Web --wait\naz provider register --namespace Microsoft.OperationalInsights --wait\n\n#################################\n# 2) Resource Group\n#################################\necho \"Cr√©ation/validation du groupe de ressources...\"\naz group create -n \"$RESOURCE_GROUP\" -l \"$LOCATION\" &gt;/dev/null || true\necho \"‚úÖ RG OK: $RESOURCE_GROUP\"\n\n#################################\n# 3) Cr√©ation ACR (avec v√©rification)\n#################################\necho \"Cr√©ation du Container Registry (ACR) en $LOCATION...\"\n\n# V√©rification pr√©alable\nif [[ ! \"$ACR_NAME\" =~ ^[a-z0-9]{5,50}$ ]]; then\n    echo \"‚ùå ERREUR: Nom ACR invalide: $ACR_NAME\"\n    echo \"   Doit contenir 5-50 caract√®res alphanum√©riques en minuscules\"\n    exit 1\nfi\n\necho \"Nom ACR valid√©: $ACR_NAME (${#ACR_NAME} caract√®res)\"\n\nset +e\naz acr create \\\n  --resource-group \"$RESOURCE_GROUP\" \\\n  --name \"$ACR_NAME\" \\\n  --sku Basic \\\n  --admin-enabled true \\\n  --location \"$LOCATION\" &gt;/dev/null 2&gt;&1\nACR_RC=$?\nset -e\n\nif [ $ACR_RC -ne 0 ]; then\n  echo \"‚ö†Ô∏è ACR bloqu√© en $LOCATION. Fallback =&gt; $FALLBACK_LOCATION\"\n  LOCATION=\"$FALLBACK_LOCATION\"\n  az acr create \\\n    --resource-group \"$RESOURCE_GROUP\" \\\n    --name \"$ACR_NAME\" \\\n    --sku Basic \\\n    --admin-enabled true \\\n    --location \"$LOCATION\" &gt;/dev/null\nfi\n\n# Attendre la cr√©ation compl√®te\nsleep 5\necho \"‚úÖ ACR cr√©√© : $ACR_NAME (region=$LOCATION)\"\n\n#################################\n# 4) Login ACR + Push image\n#################################\necho \"Connexion au registry...\"\naz acr login --name \"$ACR_NAME\" &gt;/dev/null\n\nACR_LOGIN_SERVER=$(az acr show --name \"$ACR_NAME\" --query loginServer -o tsv | tr -d '\\r')\necho \"ACR_LOGIN_SERVER=$ACR_LOGIN_SERVER\"\n\n# R√©cup√©ration des credentials AU BON ENDROIT\nACR_USER=$(az acr credential show -n \"$ACR_NAME\" --query username -o tsv | tr -d '\\r')\nACR_PASS=$(az acr credential show -n \"$ACR_NAME\" --query \"passwords[0].value\" -o tsv | tr -d '\\r')\nIMAGE=\"$ACR_LOGIN_SERVER/$IMAGE_NAME:$IMAGE_TAG\"\n\necho \"Build + Tag + Push...\"\ndocker build -t \"$IMAGE_NAME:$IMAGE_TAG\" .\ndocker tag \"$IMAGE_NAME:$IMAGE_TAG\" \"$ACR_LOGIN_SERVER/$IMAGE_NAME:$IMAGE_TAG\"\ndocker tag \"$IMAGE_NAME:$IMAGE_TAG\" \"$ACR_LOGIN_SERVER/$IMAGE_NAME:latest\"\ndocker push \"$ACR_LOGIN_SERVER/$IMAGE_NAME:$IMAGE_TAG\"\ndocker push \"$ACR_LOGIN_SERVER/$IMAGE_NAME:latest\"\necho \"‚úÖ Image push√©e dans ACR\"\n\n#################################\n# 5) Log Analytics (corrig√©)\n#################################\nLAW_NAME=\"law-mlops-$(whoami)-$RANDOM\"\necho \"Cr√©ation Log Analytics: $LAW_NAME\"\naz monitor log-analytics workspace create -g \"$RESOURCE_GROUP\" -n \"$LAW_NAME\" -l \"$LOCATION\" &gt;/dev/null\nsleep 10  # Attente n√©cessaire\n\n# Commande corrig√©e avec param√®tres explicites\nLAW_ID=$(az monitor log-analytics workspace show \\\n    --resource-group \"$RESOURCE_GROUP\" \\\n    --workspace-name \"$LAW_NAME\" \\\n    --query customerId -o tsv | tr -d '\\r')\n\nLAW_KEY=$(az monitor log-analytics workspace get-shared-keys \\\n    --resource-group \"$RESOURCE_GROUP\" \\\n    --workspace-name \"$LAW_NAME\" \\\n    --query primarySharedKey -o tsv | tr -d '\\r')\necho \"‚úÖ Log Analytics OK\"\n\n#################################\n# 6) Container Apps Environment\n#################################\necho \"Cr√©ation/validation Container Apps Environment: $CONTAINERAPPS_ENV\"\nif ! az containerapp env show -n \"$CONTAINERAPPS_ENV\" -g \"$RESOURCE_GROUP\" &gt;/dev/null 2&gt;&1; then\n  az containerapp env create \\\n    -n \"$CONTAINERAPPS_ENV\" \\\n    -g \"$RESOURCE_GROUP\" \\\n    -l \"$LOCATION\" \\\n    --logs-workspace-id \"$LAW_ID\" \\\n    --logs-workspace-key \"$LAW_KEY\" &gt;/dev/null\nfi\necho \"‚úÖ Environment OK\"\n\n#################################\n# 7) D√©ploiement Container App\n#################################\necho \"D√©ploiement Container App: $CONTAINER_APP_NAME\"\nif az containerapp show -n \"$CONTAINER_APP_NAME\" -g \"$RESOURCE_GROUP\" &gt;/dev/null 2&gt;&1; then\n  az containerapp update \\\n    -n \"$CONTAINER_APP_NAME\" \\\n    -g \"$RESOURCE_GROUP\" \\\n    --image \"$IMAGE\" \\\n    --registry-server \"$ACR_LOGIN_SERVER\" \\\n    --registry-username \"$ACR_USER\" \\\n    --registry-password \"$ACR_PASS\" &gt;/dev/null\nelse\n  az containerapp create \\\n    -n \"$CONTAINER_APP_NAME\" \\\n    -g \"$RESOURCE_GROUP\" \\\n    --environment \"$CONTAINERAPPS_ENV\" \\\n    --image \"$IMAGE\" \\\n    --ingress external \\\n    --target-port \"$TARGET_PORT\" \\\n    --registry-server \"$ACR_LOGIN_SERVER\" \\\n    --registry-username \"$ACR_USER\" \\\n    --registry-password \"$ACR_PASS\" \\\n    --min-replicas 1 \\\n    --max-replicas 1 &gt;/dev/null\nfi\necho \"‚úÖ Container App OK\"\n\n#################################\n# 8) URL API\n#################################\nAPP_URL=$(az containerapp show -n \"$CONTAINER_APP_NAME\" -g \"$RESOURCE_GROUP\" --query properties.configuration.ingress.fqdn -o tsv | tr -d '\\r')\n\necho \"\"\necho \"==========================================\"\necho \"‚úÖ D√âPLOIEMENT R√âUSSI\"\necho \"==========================================\"\necho \"ACR      : $ACR_NAME\"\necho \"Region   : $LOCATION\"\necho \"Resource Group: $RESOURCE_GROUP\"\necho \"\"\necho \"URLs de l'application :\"\necho \"  API      : https://$APP_URL\"\necho \"  Health   : https://$APP_URL/health\"\necho \"  Docs     : https://$APP_URL/docs\"\necho \"\"\necho \"Pour supprimer toutes les ressources :\"\necho \"  az group delete --name $RESOURCE_GROUP --yes --no-wait\"\necho \"==========================================\"\n\n\n6.5 Test de l‚ÄôAPI en Production\nRESOURCE_GROUP=\"rg-mlops\"  # votre Ressource group\n\nCONTAINER_APP_NAME=\"bank-churn\" # le nom de votre container app\n\nAPP_URL=$(az containerapp show \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --query properties.configuration.ingress.fqdn -o tsv | tr -d '\\r\\n' | xargs)\n\n# 2. V√©rifier l'URL proprement\necho \"URL nettoy√©e: '$APP_URL'\"\necho \"Longueur: ${#APP_URL}\"\n\n# 3. Test avec l'URL compl√®te\nFULL_URL=\"https://${APP_URL}/predict\"\necho \"URL compl√®te: $FULL_URL\"\n\n# 4. Test de pr√©diction\ncurl -X POST \"$FULL_URL\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n  }'\n\necho \"\"\n\n\n6.6 üîß R√©solution des probl√®mes\n\n\n\n\n\n\n\nProbl√®me\nSolution\n\n\n\n\nErreur DNS / cloudName: null\nEx√©cuter az logout && az login\n\n\nCaract√®re \\r dans les variables\nToujours utiliser tr -d '\\r' apr√®s az acr show\n\n\nErreur ‚ÄúContainerAppInvalidSecretName‚Äù\nUtiliser l‚Äôapproche YAML avec secret nomm√© acrpassword\n\n\nDocker non accessible\nD√©marrer Docker Desktop et ouvrir un nouveau terminal\n\n\nErreurs de permissions\nV√©rifier az account show et az login\n\n\nL‚Äôapplication est ‚ÄúFailed‚Äù\nV√©rifier les logs : az containerapp logs show --name $CONTAINER_APP_NAME --resource-group $RESOURCE_GROUP --tail 50\n\n\nImage fonctionne localement mais pas sur Azure\nV√©rifier les credentials ACR et l‚Äôidentit√© manag√©e\n\n\n\n\n\n6.7 üìã Commandes de diagnostic utiles\n# Voir les logs en temps r√©el\naz containerapp logs show \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --tail 100 \\\n  --follow\n\n# V√©rifier l'√©tat d√©taill√©\naz containerapp revision list \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --output table\n\n# R√©cup√©ration automatique et test Docker\nRESOURCE_GROUP=\"rg-mlops1\"\nACR_NAME=$(az acr list --resource-group $RESOURCE_GROUP --query \"[0].name\" -o tsv | tr -d '\\r\\n' | xargs)\nACR_LOGIN_SERVER=$(az acr show --name $ACR_NAME --query loginServer --output tsv | tr -d '\\r\\n' | xargs)\n\necho \"ACR trouv√©: $ACR_LOGIN_SERVER\"\necho \"Lancement de l'image...\"\n\ndocker run -p 8000:8000 ${ACR_LOGIN_SERVER}/bank-churn-api:v1\n\n\n# tester l'api \ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n  }'\n\n\n6.8 üìä Alternative : D√©ploiement via le Portail Azure\n\n6.8.1 Objectif\nReproduire EXACTEMENT le script Bash fourni en utilisant UNIQUEMENT l‚Äôinterface graphique Azure Portal.\n\n\n6.8.2 Pr√©requis\n\nCompte Azure avec abonnement actif\nAcc√®s √† portal.azure.com\nDockerfile et code de l‚Äôapplication bank-churn-api pr√™ts localement\n\n\n\n\n6.8.3 √âTAPE 0: Connexion Azure\n\nConnectez-vous √† portal.azure.com\nV√©rifiez votre abonnement :\n\nEn haut √† droite ‚Üí Cliquez sur votre profil\n‚ÄúChanger de r√©pertoire‚Äù si besoin\nL‚Äôabonnement actif s‚Äôaffiche dans le panneau lat√©ral gauche\n\n\n\n\n\n6.8.4 √âTAPE 1: V√©rifier/Cr√©er les Fournisseurs (Providers)\n‚ö†Ô∏è Cette √©tape n‚Äôest pas faisable dans le portail Les providers s‚Äôenregistrent automatiquement lors de la premi√®re utilisation du service. Alternative : Utilisez Azure Cloud Shell (Bash) pour cette partie uniquement :\n# Dans Azure Cloud Shell (ic√¥ne &gt;_ en haut du portail)\naz provider register --namespace Microsoft.ContainerRegistry --wait\naz provider register --namespace Microsoft.App --wait\naz provider register --namespace Microsoft.Web --wait\naz provider register --namespace Microsoft.OperationalInsights --wait\n\n\n\n6.8.5 √âTAPE 2: Groupe de Ressources\n\nRecherchez ‚ÄúGroupes de ressources‚Äù dans la barre de recherche\nCliquez sur ‚Äú+ Cr√©er‚Äù\nRemplissez :\n\nAbonnement : Votre abonnement\nGroupe de ressources : rg-MLopsyy\nR√©gion : France Central\n\nCliquez sur ‚ÄúV√©rifier + cr√©er‚Äù puis ‚ÄúCr√©er‚Äù\nAttendez le d√©ploiement (‚âà30 secondes)\n\n\n\n\n6.8.6 √âTAPE 3: Container Registry (ACR)\n\n6.8.6.1 3.1 Cr√©ation ACR\n\nRecherchez ‚ÄúRegistres de conteneurs‚Äù\nCliquez sur ‚Äú+ Cr√©er‚Äù\nOnglet ‚ÄúG√©n√©ral‚Äù :\n\nGroupe de ressources : rg-MLopsyy\nNom du registre : acrmlops[VOTRE_USERNAME][TIMESTAMP] Ex: acrmlopsjean1648826400 (le nom doit √™tre unique dans Azure et contenir de 5 √† 50 caract√®res alphanum√©riques ).\nEmplacement : France Central\nSKU : De base\n\nOnglet ‚ÄúAuthentification‚Äù :\n\n‚úÖ Utilisateur administrateur ‚Üí ACTIV√â (utile pour les tests, mais privil√©giez une identit√© Microsoft Entra pour les sc√©narios de production )\n\nCliquez sur ‚ÄúV√©rifier + cr√©er‚Äù puis ‚ÄúCr√©er‚Äù\n\n\n\n6.8.6.2 3.2 Fallback si France Central bloqu√©\nSi erreur de strat√©gie : 1. Recommencez l‚Äô√©tape 3.1 2. Changez l‚Äôemplacement : West Europe 3. Notez la nouvelle r√©gion pour les √©tapes suivantes\n\n\n\n\n6.8.7 √âTAPE 4: Build et Push de l‚ÄôImage\n\n6.8.7.1 4.1 Pr√©parer localement\n# Sur VOTRE machine locale (pas dans le portail)\ncd /chemin/vers/votre/projet\n\n# Build l'image\ndocker build -t bank-churn-api:v1 .\n\n# Tag avec ACR\ndocker tag bank-churn-api:v1 acrmlopsjean1648826400.azurecr.io/bank-churn-api:v1\ndocker tag bank-churn-api:v1 acrmlopsjean1648826400.azurecr.io/bank-churn-api:latest\n\n\n6.8.7.2 4.2 Push vers ACR\n\n6.8.7.2.1 Option A: Via Azure CLI local\n# Login ACR avec votre identit√© individuelle \naz acr login --name acrmlopsjean1648826400\n\n# Push images\ndocker push acrmlopsjean1648826400.azurecr.io/bank-churn-api:v1\ndocker push acrmlopsjean1648826400.azurecr.io/bank-churn-api:latest\n\n\n6.8.7.2.2 Option B: Via Portail Azure (ACR Tasks)\n\nAllez dans votre ACR cr√©√©\nMenu gauche ‚Üí ‚ÄúServices‚Äù ‚Üí ‚ÄúT√¢ches‚Äù\nCliquez sur ‚Äú+ T√¢che‚Äù\nConfigurez :\n\nType de t√¢che : T√¢che rapide\nPlatform : Linux\nEmplacement : M√™me que l‚ÄôACR\nSource du code : ‚ÄúContext local‚Äù\nUploader votre code ZIP ou Dockerfile\n\nEx√©cutez la t√¢che\n\n\n\n\n\n\n6.8.8 √âTAPE 5: Log Analytics Workspace\n\nRecherchez ‚ÄúEspaces de travail Log Analytics‚Äù\nCliquez sur ‚Äú+ Cr√©er‚Äù\nRemplissez :\n\nGroupe de ressources : rg-MLopsyy\nNom : law-mlops-[VOTRE_USERNAME]-[RANDOM] Ex: law-mlops-jean-12345\nR√©gion : M√™me que l‚ÄôACR (France Central ou West Europe)\n\nCliquez sur ‚ÄúV√©rifier + cr√©er‚Äù puis ‚ÄúCr√©er‚Äù\nNotez :\n\nID de l‚Äôespace de travail (customerId)\nCl√© primaire (primarySharedKey)\n\n\n\n\n\n6.8.9 √âTAPE 6: Container Apps Environment\n\nRecherchez ‚ÄúEnvironnements Container Apps‚Äù\nCliquez sur ‚Äú+ Cr√©er‚Äù\nOnglet ‚ÄúG√©n√©ral‚Äù :\n\nNom de l‚Äôenvironnement : env-mlops-workshop\nGroupe de ressources : rg-MLopsyy\nZone : M√™me r√©gion que l‚ÄôACR\nType d‚Äôenvironnement : Consumption only (pour ce workshop)\n\nOnglet ‚ÄúSurveillance‚Äù :\n\n‚úÖ Activer la surveillance Log Analytics\nEspace de travail Log Analytics : S√©lectionnez celui cr√©√© √† l‚Äô√©tape 5\n\nCliquez sur ‚ÄúV√©rifier + cr√©er‚Äù puis ‚ÄúCr√©er‚Äù\n\n\n\n\n6.8.10 √âTAPE 7: Container App (Application)\n\n6.8.10.1 7.1 Cr√©ation\n\nRecherchez ‚ÄúContainer Apps‚Äù\nCliquez sur ‚Äú+ Cr√©er‚Äù &gt; ‚ÄúContainer App‚Äù\nOnglet ‚ÄúG√©n√©ral‚Äù :\n\nAbonnement : Votre abonnement\nGroupe de ressources : rg-MLopsyy\nNom de l‚Äôapplication conteneur : bank-churn-api (entre 2 et 32 caract√®res, lettres minuscules, chiffres et tirets )\nR√©gion : S√©lectionnez une r√©gion pr√®s de vous\nEnvironnement Container Apps : S√©lectionnez env-mlops-workshop (cr√©√© pr√©c√©demment)\n\n\n\n\n6.8.10.2 7.2 Onglet ‚ÄúApplication‚Äù\n\nSection ‚ÄúImage‚Äù :\n\nSource de l‚Äôimage : ‚ÄúAzure Container Registry‚Äù\nRegistre : S√©lectionnez votre ACR\nImage : bank-churn-api\n√âtiquette : v1\nType d‚Äôauthentification du registre : ‚ÄúInformations d‚Äôidentification de l‚Äôadministrateur‚Äù (utilisez les cl√©s d‚Äôacc√®s de l‚ÄôACR pour ce workshop )\nNom d‚Äôutilisateur/Password : R√©cup√©rez-les dans ACR ‚Üí ‚ÄúCl√©s d‚Äôacc√®s‚Äù\n\n\n\n\n6.8.10.3 7.3 Onglet ‚ÄúIngress‚Äù\n\nTrafic entrant : ‚úÖ Activ√©\nVisibilit√© du trafic entrant : Accepting traffic from anywhere (pour un acc√®s externe )\nType d‚Äôentr√©e : HTTP\nPort cible : 8000 (doit correspondre au port √©cout√© par votre conteneur )\nConnexions non s√©curis√©es : D√©cochez (laissez false par d√©faut pour forcer HTTPS )\n\n\n\n6.8.10.4 7.4 Onglet ‚ÄúMise √† l‚Äô√©chelle‚Äù\nPour ce workshop et pour optimiser les co√ªts : 1. Mode de mise √† l‚Äô√©chelle : ‚ÄúAucune mise √† l‚Äô√©chelle automatique‚Äù 2. Nombre minimal de r√©plicas : 1 3. Nombre maximal de r√©plicas : 1\n\n\n\n\n\n\nNoteBonne pratique en production\n\n\n\nPour une meilleure fiabilit√© en production, il est recommand√© de configurer au moins 3 r√©plicas et d‚Äôactiver la mise √† l‚Äô√©chelle automatique bas√©e sur les m√©triques HTTP ou CPU pour g√©rer les pics de charge .\n\n\n\n\n6.8.10.5 7.5 Finalisation\n\nCliquez sur ‚ÄúV√©rifier + cr√©er‚Äù puis ‚ÄúCr√©er‚Äù\nAttendez le d√©ploiement (‚âà2-3 minutes)\n\n\n\n\n\n6.8.11 √âTAPE 8: R√©cup√©rer l‚ÄôURL\n\nAllez sur votre Container App bank-churn-api\nMenu gauche ‚Üí ‚ÄúVue d‚Äôensemble‚Äù\nCherchez ‚ÄúURL de l‚Äôapplication‚Äù (le FQDN g√©n√©r√© automatiquement )\nCopiez l‚ÄôURL (format : https://bank-churn-api.xxxxxxxx.region.azurecontainerapps.io)\n\n\n\n\n6.8.12 √âTAPE 9: Tests\n\nOuvrez un navigateur\nTestez :\n\nHealth : https://[VOTRE-URL]/health\nDocumentation : https://[VOTRE-URL]/docs\nSwagger UI : https://[VOTRE-URL]/redoc\n\n\n\n\n\n6.8.13 V√©rification Finale\nComparez avec le script Bash :\n\n\n\n\n\n\n\n\n√âl√©ment\nScript Bash\nInterface Graphique\n\n\n\n\nResource Group\nrg-MLopsyy (France Central)\n‚úÖ Identique\n\n\nACR\nNom unique avec timestamp\n‚úÖ Identique (5-50 caract√®res alphanum√©riques )\n\n\nFallback location\nWest Europe si blocage\n‚úÖ G√©r√© manuellement\n\n\nLog Analytics\nCr√©√© avec nom al√©atoire\n‚úÖ Identique\n\n\nEnvironment\nenv-mlops-workshop\n‚úÖ Identique\n\n\nContainer App\nbank-churn-api port 8000\n‚úÖ Identique (2-32 caract√®res )\n\n\nImage\nbank-churn-api:v1\n‚úÖ Identique\n\n\nIngress\nExterne, HTTP, port 8000\n‚úÖ Identique\n\n\nR√©plicas\nmin=1, max=1\n‚úÖ Identique\n\n\n\n\n\n\n6.8.14 Points d‚ÄôAttention\n\nTimestamp dans ACR : Dans le portail, g√©n√©rez-le manuellement (ex: date +%s dans Cloud Shell)\nAuthentification ACR : Pour les sc√©narios de production, envisagez d‚Äôutiliser une identit√© manag√©e au lieu des identifiants administrateur pour une s√©curit√© et une gestion am√©lior√©es .\nVariables d‚Äôenvironnement : Si votre app en a besoin, ajoutez-les dans l‚Äôonglet ‚ÄúParam√®tres‚Äù du Container App.\nLogs : Les logs sont automatiquement envoy√©s √† Log Analytics configur√© dans l‚Äôenvironnement.\nS√©curit√© r√©seau : Pour restreindre l‚Äôacc√®s, vous pouvez configurer ult√©rieurement des restrictions d‚Äôadresse IP sur l‚Äôingress de votre application conteneur .\n\n\n\n\n6.8.15 R√©sum√© des URLs\n\nPortail Azure : https://portal.azure.com\nVotre API : https://bank-churn-api.[...].azurecontainerapps.io\nHealth check : /health\nDocumentation : /docs (Swagger)\nACR : acrmlopsjean1648826400.azurecr.io\n\n\nDur√©e totale : ‚âà15-20 minutes via l‚Äôinterface graphique Co√ªt estim√© : ~5-10‚Ç¨/mois (ACR Basic + Container App en fonctionnement)\nRemarque : Il est important de conserver la section existante ‚ÄúSurveillance des Co√ªts {#sec-module4-couts}‚Äù qui suit imm√©diatement cette partie dans votre fichier.\n\n\n\n6.9 Exercice Pratique\n\n\n\n\n\n\nTipEXERCICE 2\n\n\n\nPartagez votre URL d‚ÄôAPI avec un camarade et testez son API :\n\nFaites 10 pr√©dictions sur son API\nComparez les r√©sultats avec votre mod√®le\nObservez les logs dans Azure Portal :\n\nAllez dans votre Container App\nMenu ‚ÄúLog stream‚Äù ou ‚ÄúMonitoring‚Äù ‚Üí ‚ÄúLogs‚Äù\nObservez les requ√™tes en temps r√©el\n\n\n\n\n\n\n6.10 üéØ Points cl√©s des corrections apport√©es\n\nNettoyage du \\r : Ajout de tr -d '\\r' √† la r√©cup√©ration du login server\nApproche YAML : Contournement du bug de g√©n√©ration de nom de secret\nSecret nomm√© : Utilisation d‚Äôun nom valide acrpassword au lieu du nom auto-g√©n√©r√©\nVariables d‚Äôenvironnement : Ajout de PYTHONUNBUFFERED=1 pour les logs\nTests robustes : Attente de 30 secondes avant les v√©rifications\nCommandes de diagnostic : Ajout de commandes pour troubleshooting\nAlternative GUI : Instructions pour le d√©ploiement via le portail Azure\n\nPour ex√©cuter le module, sauvegardez-le dans un fichier module4-deploiement.sh et ex√©cutez :\nchmod +x module4-deploiement.sh\n./module4-deploiement.sh\n\n\n6.11 Checkpoint\n\n\n\n\n\n\nNoteValidation Module 4\n\n\n\nAvant de passer au module suivant, v√©rifiez que :\n\n\nL‚Äôapplication est accessible via HTTPS\nLe health check fonctionne\nLes pr√©dictions fonctionnent\nVous avez not√© l‚ÄôURL publique de votre API"
  },
  {
    "objectID": "index.html#sec-module5",
    "href": "index.html#sec-module5",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "7 Module 5 : CI/CD avec GitHub Actions",
    "text": "7 Module 5 : CI/CD avec GitHub Actions\n\n7.1 Objectif\nAutomatiser le d√©ploiement : chaque commit sur la branche main d√©clenche un build et un red√©ploiement.\n\n\n7.2 √âtape 1 : Initialisation du Repository Git\n# Initialiser git (si pas deja fait)\ngit init\n\n# Creer un .gitignore\ncat &gt; .gitignore &lt;&lt; EOF\n__pycache__/\n*.pyc\nvenv/\n.env\nmlruns/\n*.log\n.DS_Store\n.vscode/\nconfusion_matrix.png\nfeature_importance.png\nEOF\n\n# Premier commit\ngit add .\ngit commit -m \"Initial commit: Bank Churn API\"\n\n\n7.3 √âtape 2 : Cr√©er un Repository GitHub\n\nAllez sur https://github.com/new\nNom du repository : bank-churn-mlops\nVisibility : Public ou Private\nNe pas initialiser avec README (d√©j√† fait localement)\nCliquez sur ‚ÄúCreate repository‚Äù\n\n# Lier votre repo local a GitHub (REMPLACEZ username)\ngit remote add origin https://github.com/username/bank-churn-mlops.git\ngit branch -M main\ngit push -u origin main\n\n\n7.4 √âtape 3 : Configuration des Secrets GitHub\n\n7.4.1 Cr√©er un Service Principal Azure\n# Recuperer votre Subscription ID\nSUBSCRIPTION_ID=$(az account show --query id -o tsv)\n\n# Creer un Service Principal\naz ad sp create-for-rbac \\\n  --name \"github-actions-mlops\" \\\n  --role contributor \\\n  --scopes /subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP \\\n  --sdk-auth\nCopiez tout le JSON retourn√©.\n\n\n7.4.2 Ajouter les Secrets dans GitHub\n\nAllez dans votre repository GitHub\nSettings &gt; Secrets and variables &gt; Actions\nCliquez sur ‚ÄúNew repository secret‚Äù\nAjoutez les secrets suivants :\n\n\n\n\n\n\n\n\nNom\nValeur\n\n\n\n\nAZURE_CREDENTIALS\nLe JSON du Service Principal\n\n\nACR_USERNAME\nR√©sultat de : az acr credential show --name $ACR_NAME --query username -o tsv\n\n\nACR_PASSWORD\nR√©sultat de : az acr credential show --name $ACR_NAME --query passwords[0].value -o tsv\n\n\n\n\n\n\n7.5 √âtape 4 : Cr√©ation du Workflow GitHub Actions\nCr√©ez le fichier .github/workflows/ci-cd.yml :\nname: CI/CD Pipeline\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n  workflow_dispatch:\n\nenv:\n  AZURE_RESOURCE_GROUP: rg-mlops\n  ACR_NAME: votre-acr-name  # MODIFIEZ ICI\n  CONTAINER_APP_NAME: app-churn-api\n  IMAGE_NAME: bank-churn-api\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n      \n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.9'\n      \n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements.txt\n          pip install pytest pytest-cov\n      \n      - name: Run tests\n        run: |\n          pytest tests/ -v --cov=app --cov-report=term\n      \n  build-and-deploy:\n    needs: test\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'\n    \n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n      \n      - name: Azure Login\n        uses: azure/login@v1\n        with:\n          creds: ${{ secrets.AZURE_CREDENTIALS }}\n      \n      - name: Login to ACR\n        uses: azure/docker-login@v1\n        with:\n          login-server: ${{ env.ACR_NAME }}.azurecr.io\n          username: ${{ secrets.ACR_USERNAME }}\n          password: ${{ secrets.ACR_PASSWORD }}\n      \n      - name: Build and push Docker image\n        run: |\n          docker build -t ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }} .\n          docker build -t ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest .\n          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}\n          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest\n      \n      - name: Deploy to Azure Container Apps\n        uses: azure/CLI@v1\n        with:\n          inlineScript: |\n            az containerapp update \\\n              --name ${{ env.CONTAINER_APP_NAME }} \\\n              --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n              --image ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}\n      \n      - name: Verify deployment\n        run: |\n          APP_URL=$(az containerapp show \\\n            --name ${{ env.CONTAINER_APP_NAME }} \\\n            --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n            --query properties.configuration.ingress.fqdn -o tsv)\n          \n          echo \"Application deployed at: https://$APP_URL\"\n          \n          sleep 30\n          curl -f https://$APP_URL/health || exit 1\n          \n          echo \"Deployment successful!\"\n\n\n7.6 √âtape 5 : D√©clencher le Pipeline\n# Ajouter le workflow\ngit add .github/workflows/ci-cd.yml\ngit add tests/test_api.py\ngit commit -m \"Add CI/CD pipeline and tests\"\ngit push origin main\n\n# Le pipeline se declenche automatiquement !\nAllez sur GitHub &gt; Actions pour voir le pipeline en cours d‚Äôex√©cution.\n\n\n7.7 Exercice Pratique\n\n\n\n\n\n\nTipEXERCICE 3\n\n\n\n\nAjoutez un nouveau test dans test_api.py\nFaites un commit et push\nObservez le pipeline s‚Äôex√©cuter\nV√©rifiez que le d√©ploiement s‚Äôest bien fait\n\n\n\n\n\n7.8 Checkpoint\n\n\n\n\n\n\nNoteValidation Module 5\n\n\n\nAvant de passer au module suivant, v√©rifiez que :\n\n\nLe repository GitHub est cr√©√©\nLes secrets sont configur√©s\nLe workflow CI/CD s‚Äôex√©cute sans erreur\nL‚Äôapplication se red√©ploie\n\n\nautomatiquement"
  },
  {
    "objectID": "index.html#sec-module6",
    "href": "index.html#sec-module6",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "8 Module 6 : Monitoring et Maintenance",
    "text": "8 Module 6 : Monitoring et Maintenance\n\n8.1 Objectif\nMettre en place le monitoring de l‚Äôapplication et d√©tecter les probl√®mes en production.\n\n\n8.2 Configuration Application Insights\n# Creation d'Application Insights\naz monitor app-insights component create \\\n  --app bank-churn-insights \\\n  --location $LOCATION \\\n  --resource-group $RESOURCE_GROUP \\\n  --application-type web\n\n# Recuperer la connection string\nAPPINSIGHTS_CONN=$(az monitor app-insights component show \\\n  --app bank-churn-insights \\\n  --resource-group $RESOURCE_GROUP \\\n  --query connectionString -o tsv)\n\necho \"Connection String : $APPINSIGHTS_CONN\"\n\n# Ajouter la variable d'environnement a Container Apps\naz containerapp update \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --set-env-vars \"APPLICATIONINSIGHTS_CONNECTION_STRING=$APPINSIGHTS_CONN\"\n\n\n8.3 Int√©gration du Monitoring dans le Code\nAjoutez dans requirements.txt :\nopencensus-ext-azure==1.1.9\nopencensus-ext-requests==0.12.1\nModifiez app/main.py pour ajouter le monitoring :\nimport os\nfrom opencensus.ext.azure.log_exporter import AzureLogHandler\nimport logging\n\n# Configuration du logging avec Application Insights\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n\nAPPINSIGHTS_CONN = os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\")\nif APPINSIGHTS_CONN:\n    logger.addHandler(AzureLogHandler(connection_string=APPINSIGHTS_CONN))\n    logger.info(\"Application Insights connecte\")\n\n\n8.4 D√©tection de Data Drift\nCr√©ez le fichier drift_detection.py :\nimport pandas as pd\nfrom scipy.stats import ks_2samp\nimport json\n\ndef detect_drift(reference_file, production_file, threshold=0.05):\n    \"\"\"\n    Detecte le drift entre donnees de reference et production\n    \"\"\"\n    ref_data = pd.read_csv(reference_file)\n    prod_data = pd.read_csv(production_file)\n    \n    drift_results = {}\n    \n    for column in ref_data.columns:\n        if column in prod_data.columns and column != 'Exited':\n            # Test de Kolmogorov-Smirnov\n            statistic, p_value = ks_2samp(\n                ref_data[column].dropna(),\n                prod_data[column].dropna()\n            )\n            \n            drift_detected = p_value &lt; threshold\n            \n            drift_results[column] = {\n                'p_value': float(p_value),\n                'statistic': float(statistic),\n                'drift_detected': drift_detected\n            }\n    \n    # Rapport\n    drifted_features = [f for f, r in drift_results.items() if r['drift_detected']]\n    \n    print(\"=\"*50)\n    print(\"DATA DRIFT DETECTION REPORT\")\n    print(\"=\"*50)\n    print(f\"Threshold: {threshold}\")\n    print(f\"Features analyzed: {len(drift_results)}\")\n    print(f\"Features with drift: {len(drifted_features)}\")\n    print(\"\\nDrifted features:\")\n    for feature in drifted_features:\n        print(f\"  - {feature}: p-value = {drift_results[feature]['p_value']:.4f}\")\n    print(\"=\"*50)\n    \n    return drift_results\n\nif __name__ == \"__main__\":\n    results = detect_drift(\n        \"data/bank_churn.csv\",\n        \"data/production_data.csv\"\n    )\n    \n    # Sauvegarder les resultats\n    with open(\"drift_report.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n    \n    print(\"\\nRapport sauvegarde dans drift_report.json\")\n\n\n8.5 Checkpoint\n\n\n\n\n\n\nNoteValidation Module 6\n\n\n\nAvant de passer au module suivant, v√©rifiez que :\n\n\nApplication Insights est configur√©\nLes logs apparaissent dans Azure Portal\nVous pouvez visualiser les m√©triques\nLe script de d√©tection de drift fonctionne"
  },
  {
    "objectID": "index.html#sec-module7",
    "href": "index.html#sec-module7",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "9 Module 7 : Optimisations et Bonnes Pratiques",
    "text": "9 Module 7 : Optimisations et Bonnes Pratiques\n\n9.1 Objectif\nAm√©liorer les performances, la s√©curit√© et la maintenabilit√© de l‚Äôapplication.\n\n\n9.2 Ajout d‚Äôun Cache pour les Pr√©dictions\nModifiez app/main.py :\nfrom functools import lru_cache\nimport hashlib\nimport json\n\ndef hash_features(features_dict: dict) -&gt; str:\n    \"\"\"Cree un hash unique pour les features\"\"\"\n    return hashlib.md5(\n        json.dumps(features_dict, sort_keys=True).encode()\n    ).hexdigest()\n\n# Cache pour les predictions (1000 dernieres)\n@lru_cache(maxsize=1000)\ndef predict_cached(features_hash: str, features_json: str):\n    features_dict = json.loads(features_json)\n    input_data = np.array([[\n        features_dict[\"CreditScore\"],\n        features_dict[\"Age\"],\n        # ... autres features\n    ]])\n    \n    proba = model.predict_proba(input_data)[0, 1]\n    prediction = int(proba &gt; 0.5)\n    \n    if proba &lt; 0.3:\n        risk = \"Low\"\n    elif proba &lt; 0.7:\n        risk = \"Medium\"\n    else:\n        risk = \"High\"\n    \n    return {\n        \"churn_probability\": round(float(proba), 4),\n        \"prediction\": prediction,\n        \"risk_level\": risk\n    }\n\n@app.post(\"/predict\", response_model=PredictionResponse)\ndef predict(features: CustomerFeatures):\n    features_dict = features.dict()\n    features_hash = hash_features(features_dict)\n    features_json = json.dumps(features_dict)\n    \n    # Utilise le cache si disponible\n    result = predict_cached(features_hash, features_json)\n    \n    logger.info(f\"Prediction - Hash: {features_hash[:8]}\")\n    return result\n\n\n9.3 Checklist de Production\n\n\n\n\n\n\nTipChecklist Avant Production\n\n\n\n\nTests unitaires avec coverage &gt; 80%\nTests d‚Äôintegration\nLoad testing effectue\nMonitoring configure\nAlertes definies\nLogs centralises\nDocumentation API complete\nHTTPS active\nHealth checks fonctionnels\nAuto-scaling teste\nVariables d‚Äôenvironnement securisees\nBudget Azure surveille\n\n\n\n\n\n9.4 Checkpoint Final\n\n\n\n\n\n\nNoteValidation Module 7\n\n\n\n\n\nCache de predictions implemente\nDocumentation complete\nTous les tests passent\nChecklist de production verifiee"
  },
  {
    "objectID": "index.html#sec-nettoyage",
    "href": "index.html#sec-nettoyage",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "10 Nettoyage des Ressources Azure",
    "text": "10 Nettoyage des Ressources Azure\n\n10.1 IMPORTANT - Suppression pour √âviter les Co√ªts\n\n\n\n\n\n\nWarningATTENTION - √Ä FAIRE √Ä LA FIN DU WORKSHOP\n\n\n\nPour √©viter de consommer votre budget de 100$, supprimez toutes les ressources :\n# Suppression du groupe de ressources (supprime tout)\naz group delete --name $RESOURCE_GROUP --yes --no-wait\n\n# Verification\naz group list --output table\nCette commande supprime : - Azure Container Registry - Azure Container Apps - Application Insights - Tous les logs et donn√©es\nTemps de suppression : 5-10 minutes\n\n\n\n\n10.2 Script de Nettoyage Automatique\nCr√©ez cleanup.sh :\n#!/bin/bash\n\nRESOURCE_GROUP=\"rg-mlops\"\n\necho \"==========================================\"\necho \"Nettoyage des ressources Azure\"\necho \"==========================================\"\n\nread -p \"Voulez-vous vraiment supprimer toutes les ressources ? (yes/no): \" confirm\n\nif [ \"$confirm\" != \"yes\" ]; then\n    echo \"Operation annulee.\"\n    exit 0\nfi\n\necho \"\\nRessources a supprimer:\"\naz resource list --resource-group $RESOURCE_GROUP --output table\n\necho \"\\nSuppression en cours...\"\naz group delete --name $RESOURCE_GROUP --yes --no-wait\n\necho \"\\nSuppression lancee (prend 5-10 minutes)\"\necho \"Verifiez sur : https://portal.azure.com\"\n# Rendre executable et lancer\nchmod +x cleanup.sh\n./cleanup.sh"
  },
  {
    "objectID": "index.html#sec-recapitulatif",
    "href": "index.html#sec-recapitulatif",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "11 R√©capitulatif du Workshop",
    "text": "11 R√©capitulatif du Workshop\n\n11.1 Ce que Vous Avez Accompli\nF√©licitations ! Vous avez d√©ploy√© un syst√®me MLOps complet :\nArchitecture Finale :\nML Training ‚Üí FastAPI ‚Üí Docker ‚Üí Azure Container Registry ‚Üí Azure Container Apps\n‚Üë GitHub Actions CI/CD\n‚Üë Application Insights Monitoring\n\n\n11.2 Comp√©tences Acquises\n\nMachine Learning\n\nEntra√Ænement d‚Äôun mod√®le Random Forest\n√âvaluation avec m√©triques appropri√©es\nTracking avec MLflow\n\nD√©veloppement d‚ÄôAPI\n\nCr√©ation d‚ÄôAPI REST avec FastAPI\nValidation des donn√©es avec Pydantic\nDocumentation automatique\n\nConteneurisation\n\nDockerfiles optimis√©s\nBonnes pratiques de s√©curit√©\nGestion des images\n\nCloud Azure\n\nAzure Container Registry\nAzure Container Apps\nApplication Insights\n\nDevOps/MLOps\n\nPipelines CI/CD avec GitHub Actions\nTests automatis√©s\nD√©ploiement continu\n\nMonitoring et Maintenance\n\nLogs centralis√©s\nM√©triques de performance\nD√©tection de data drift\n\n\n\n\n11.3 Points Cl√©s √† Retenir\n\n\n\n\n\n\nImportantLecons Importantes\n\n\n\n\nMLOps = DevOps + ML : Automatisation du cycle de vie complet\nConteneurisation : Portabilit√© et reproductibilit√©\nTests : Essentiels pour la fiabilit√©\nMonitoring : Indispensable en production\nDocumentation : Facilite la collaboration\nS√©curit√© : √Ä consid√©rer d√®s le d√©but\nCo√ªts : Toujours surveiller l‚Äôutilisation cloud"
  },
  {
    "objectID": "index.html#sec-faq",
    "href": "index.html#sec-faq",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "12 FAQ - Foire Aux Questions",
    "text": "12 FAQ - Foire Aux Questions\n\n12.1 Questions Techniques\nQ1 : Mon API est lente, comment l‚Äôoptimiser ?\nR : Plusieurs options : - Activer le cache des pr√©dictions - Utiliser des pr√©dictions batch - Optimiser le mod√®le (quantization, pruning) - Augmenter les ressources CPU/RAM\nQ2 : Comment g√©rer plusieurs versions de mod√®les ?\nR : Utilisez MLflow Model Registry et cr√©ez des endpoints diff√©rents (v1, v2).\nQ3 : Comment impl√©menter un rollback ?\nR : Conservez les anciennes images Docker avec tags et utilisez :\naz containerapp update \\\n  --name $APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --image $ACR_NAME.azurecr.io/bank-churn-api:v1  # Version precedente\nQ4 : Mon budget Azure est presque √©puis√©, que faire ?\nR : - Mettre min-replicas √† 0 - Utiliser des SKU Basic - Supprimer les ressources inutilis√©es - Activer les budgets alerts\n\n\n12.2 Questions de Compr√©hension\nQ5 : Quelle est la diff√©rence entre Docker et Kubernetes ?\nR : Docker conteneurise les applications, Kubernetes les orchestre (scaling, load balancing, self-healing).\nQ6 : Pourquoi utiliser FastAPI plut√¥t que Flask ?\nR : FastAPI est plus rapide, avec validation automatique, documentation auto-g√©n√©r√©e, et support async natif.\nQ7 : Qu‚Äôest-ce que le data drift ?\nR : Changement dans la distribution des donn√©es d‚Äôentr√©e par rapport aux donn√©es d‚Äôentra√Ænement, pouvant d√©grader les performances du mod√®le."
  },
  {
    "objectID": "index.html#sec-conclusion",
    "href": "index.html#sec-conclusion",
    "title": "Workshop MLOps avec Azure - Guide Pratique",
    "section": "13 Conclusion",
    "text": "13 Conclusion\n\n13.1 F√©licitations !\nVous avez termin√© ce workshop intensif de MLOps avec Azure. Vous avez construit un syst√®me complet de d√©ploiement de mod√®le de Machine Learning en production, avec toutes les bonnes pratiques de l‚Äôindustrie.\n\n\n13.2 Prochaines √âtapes\n\nPratiquez : Refaites le workshop avec un dataset diff√©rent\nPartagez : Mettez votre projet sur GitHub\nAm√©liorez : Impl√©mentez les fonctionnalit√©s avanc√©es\nCertifiez-vous : Pr√©parez les certifications Azure\n\n\nBon Apprentissage et Bon D√©ploiement !\nCe guide vous a accompagn√© dans votre premier projet MLOps.\nContinuez √† explorer, √† apprendre et √† innover.\n\nVersion 1.0 - Novembre 2025\nWorkshop MLOps avec Azure ## Test de d√©ploiement - jeu. 20 nov. 2025 03:26:42"
  }
]