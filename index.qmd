---
title: "Workshop MLOps avec Azure - Guide Pratique"
format: 
  html:
    toc: true
    toc-depth: 3
    toc-location: left
    number-sections: true
    code-fold: true
    code-overflow: wrap
editor: visual
---

## Introduction {#sec-introduction}

### Bienvenue !

Ce workshop vous guidera √† travers le d√©ploiement complet d'un mod√®le de Machine Learning en production sur Microsoft Azure. Vous allez construire une API de pr√©diction de d√©faillance client (churn) et la d√©ployer sur le cloud avec toutes les bonnes pratiques MLOps.

### Objectifs d'Apprentissage {#sec-objectifs}

√Ä la fin de ce workshop, vous serez capable de :

-   Entra√Æner et sauvegarder un mod√®le ML avec MLflow
-   Cr√©er une API REST avec FastAPI
-   Conteneuriser une application avec Docker
-   D√©ployer sur Azure Container Apps
-   Mettre en place un pipeline CI/CD avec GitHub Actions
-   Monitorer votre application en production
-   D√©tecter le data drift

### Le Projet : Bank Churn Prediction {#sec-projet}

**Contexte :** Une banque souhaite pr√©dire quels clients risquent de partir pour proposer des actions de r√©tention.

**Dataset :** 10 features (√¢ge, score cr√©dit, solde, etc.) + 1 target (Exited : 0/1)

**Mod√®le :** Random Forest Classifier

**Livrable :** API REST d√©ploy√©e sur Azure, accessible publiquement

### Architecture Finale {#sec-architecture}

**Flux de d√©ploiement :**

`Code GitHub` ‚Üí `GitHub Actions` ‚Üí `Docker Build` ‚Üí `Azure Container Registry` ‚Üí `Azure Container Apps` ‚Üí `Internet`

## Pr√©paration de l'Environnement {#sec-preparation}

### Logiciels Requis {#sec-logiciels}

**Obligatoire :**

-   Python 3.9+ : https://www.python.org/downloads/
-   Visual Studio Code : https://code.visualstudio.com/
-   Git : https://git-scm.com/downloads
-   Docker Desktop : https://www.docker.com/products/docker-desktop
-   Azure CLI : https://docs.microsoft.com/cli/azure/install-azure-cli

**Comptes √† cr√©er :**

-   Compte GitHub : https://github.com/signup
-   Azure for Students (100\$) : https://azure.microsoft.com/students

### V√©rification de l'Installation {#sec-verification}

Ouvrez un terminal et testez :

``` bash
# Python
python --version
# Doit afficher Python 3.9.x ou superieur

# Git
git --version

# Docker
docker --version
docker ps

# Azure CLI
az --version
```

### Configuration Initiale {#sec-configuration}

#### Configuration Git {#sec-config-git}

``` bash
git config --global user.name "Votre Nom"
git config --global user.email "votre.email@example.com"
```

#### Connexion √† Azure {#sec-config-azure}

``` bash
# Se connecter a Azure
az login

# Verifier l'abonnement
az account show

# Si vous avez plusieurs abonnements, selectionner celui de Students
az account set --subscription "Azure for Students"
```

## Module 1 : Entra√Ænement du Mod√®le {#sec-module1}

### Objectif {#sec-module1-objectif}

Entra√Æner un mod√®le Random Forest pour pr√©dire le churn et le sauvegarder avec MLflow.

### Pr√©paration du Projet {#sec-module1-preparation}

``` bash
# Creer le dossier du projet
mkdir bank-churn-mlops
cd bank-churn-mlops

# Creer un environnement virtuel
python -m venv venv

# Activer l'environnement
# Windows :
venv\Scripts\activate
# Mac/Linux :
source venv/bin/activate

# Creer la structure
mkdir -p data model app tests
touch requirements.txt
```

### Fichier requirements.txt {#sec-module1-requirements}

Cr√©ez le fichier `requirements.txt` avec le contenu suivant :

```         
# API Framework
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0

# Machine Learning
scikit-learn==1.3.2
pandas==2.1.3
numpy==1.26.2
joblib==1.3.2

# MLflow
mlflow==2.8.1

# Testing
pytest==7.4.3
pytest-cov==4.1.0
httpx==0.25.2

# Utilities
python-multipart==0.0.6
requests==2.31.0
```

Puis installez les d√©pendances :

``` bash
pip install -r requirements.txt
```

### T√©l√©chargement du Dataset {#sec-module1-dataset}

Cr√©ez un dataset synth√©tique :

``` python
# generate_data.py
import pandas as pd
import numpy as np

np.random.seed(42)
n_samples = 10000

data = {
    'CreditScore': np.random.randint(300, 850, n_samples),
    'Age': np.random.randint(18, 80, n_samples),
    'Tenure': np.random.randint(0, 11, n_samples),
    'Balance': np.random.uniform(0, 200000, n_samples),
    'NumOfProducts': np.random.randint(1, 5, n_samples),
    'HasCrCard': np.random.choice([0, 1], n_samples),
    'IsActiveMember': np.random.choice([0, 1], n_samples),
    'EstimatedSalary': np.random.uniform(20000, 150000, n_samples),
    'Geography_Germany': np.random.choice([0, 1], n_samples),
    'Geography_Spain': np.random.choice([0, 1], n_samples),
}

# Target : plus de chance de partir si inactif, peu de produits, etc.
churn_prob = (
    (1 - data['IsActiveMember']) * 0.3 +
    (data['NumOfProducts'] == 1) * 0.2 +
    (data['Age'] > 60) * 0.15 +
    (data['Balance'] == 0) * 0.25
)
data['Exited'] = (np.random.random(n_samples) < churn_prob).astype(int)

df = pd.DataFrame(data)
df.to_csv('data/bank_churn.csv', index=False)
print(f"Dataset cree : {len(df)} lignes")
print(f"Taux de churn : {df['Exited'].mean():.2%}")
```

### Script d'Entra√Ænement {#sec-module1-training}

Cr√©ez le fichier `train_model.py` :

``` python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, 
    precision_score, 
    recall_score,
    f1_score, 
    roc_auc_score,
    confusion_matrix
)
import joblib
import mlflow
import mlflow.sklearn
import matplotlib.pyplot as plt
import seaborn as sns

# Configuration MLflow
mlflow.set_tracking_uri("./mlruns")
mlflow.set_experiment("bank-churn-prediction")

print("Chargement des donnees...")
df = pd.read_csv("data/bank_churn.csv")

print(f"Dataset : {len(df)} lignes, {len(df.columns)} colonnes")
print(f"Taux de churn : {df['Exited'].mean():.2%}")

# Separation features/target
X = df.drop('Exited', axis=1)
y = df['Exited']

# Split train/test (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nTrain : {len(X_train)} lignes")
print(f"Test : {len(X_test)} lignes")

# Entrainement avec MLflow tracking
print("\nEntrainement du modele...")
with mlflow.start_run(run_name="random-forest-v1"):
    
    # Parametres du modele
    params = {
        'n_estimators': 100,
        'max_depth': 10,
        'min_samples_split': 5,
        'random_state': 42
    }
    
    # Entrainement
    model = RandomForestClassifier(**params)
    model.fit(X_train, y_train)
    
    # Predictions
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]
    
    # Calcul des metriques
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_proba)
    
    # Log des parametres et metriques dans MLflow
    mlflow.log_params(params)
    mlflow.log_metrics({
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1_score": f1,
        "roc_auc": auc
    })
    
    # Creation et sauvegarde de la matrice de confusion
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title('Matrice de Confusion')
    plt.ylabel('Vraie Classe')
    plt.xlabel('Classe Predite')
    plt.savefig('confusion_matrix.png')
    mlflow.log_artifact('confusion_matrix.png')
    plt.close()
    
    # Feature importance
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    plt.figure(figsize=(10, 6))
    plt.barh(feature_importance['feature'], feature_importance['importance'])
    plt.xlabel('Importance')
    plt.title('Feature Importance')
    plt.tight_layout()
    plt.savefig('feature_importance.png')
    mlflow.log_artifact('feature_importance.png')
    plt.close()
    
    # Enregistrement du modele dans MLflow
    mlflow.sklearn.log_model(
        model,
        "model",
        registered_model_name="bank-churn-classifier"
    )
    
    # Sauvegarde locale du modele
    joblib.dump(model, "model/churn_model.pkl")
    
    # Tags
    mlflow.set_tags({
        "environment": "development",
        "model_type": "RandomForest",
        "task": "binary_classification"
    })
    
    # Affichage des resultats
    print("\n" + "="*50)
    print("RESULTATS DE L'ENTRAINEMENT")
    print("="*50)
    print(f"Accuracy  : {accuracy:.4f}")
    print(f"Precision : {precision:.4f}")
    print(f"Recall    : {recall:.4f}")
    print(f"F1 Score  : {f1:.4f}")
    print(f"ROC AUC   : {auc:.4f}")
    print("="*50)
    
    print(f"\nModele sauvegarde dans : model/churn_model.pkl")
    print(f"MLflow UI : mlflow ui --port 5000")
```

### Ex√©cution {#sec-module1-execution}

``` bash
# Lancer l'entrainement
python train_model.py

# Voir les resultats dans MLflow UI
mlflow ui --port 5000
# Ouvrir http://localhost:5000 dans votre navigateur
```

### Checkpoint {#sec-module1-checkpoint}

:::: callout-note
## Validation Module 1

Avant de passer au module suivant, v√©rifiez que :

::: {style="margin-left: 20px;"}
-   [ ] Le mod√®le est entra√Æn√© avec une accuracy \> 0.75
-   [ ] Le fichier `model/churn_model.pkl` existe
-   [ ] MLflow UI affiche votre exp√©rience
-   [ ] Vous comprenez les m√©triques obtenues
:::
::::

## Module 2 : Cr√©ation de l'API avec FastAPI {#sec-module2}

### Objectif {#sec-module2-objectif}

Cr√©er une API REST qui expose le mod√®le via des endpoints HTTP.

### Structure du Code API {#sec-module2-structure}

```         
bank-churn-mlops/
|-- app/
|   |-- __init__.py
|   |-- main.py
|   |-- models.py
|   +-- utils.py
|-- model/
|   +-- churn_model.pkl
|-- tests/
|   +-- test_api.py
|-- requirements.txt
+-- README.md
```

### Fichier app/models.py {#sec-module2-models}

D√©finition des sch√©mas de donn√©es avec Pydantic :

``` python
from pydantic import BaseModel, Field
from typing import List

class CustomerFeatures(BaseModel):
    """Schema pour les features d'un client"""
    CreditScore: int = Field(..., ge=300, le=850, description="Score de credit")
    Age: int = Field(..., ge=18, le=100, description="Age du client")
    Tenure: int = Field(..., ge=0, le=10, description="Anciennete en annees")
    Balance: float = Field(..., ge=0, description="Solde du compte")
    NumOfProducts: int = Field(..., ge=1, le=4, description="Nombre de produits")
    HasCrCard: int = Field(..., ge=0, le=1, description="Possession carte credit")
    IsActiveMember: int = Field(..., ge=0, le=1, description="Membre actif")
    EstimatedSalary: float = Field(..., ge=0, description="Salaire estime")
    Geography_Germany: int = Field(..., ge=0, le=1, description="Client allemand")
    Geography_Spain: int = Field(..., ge=0, le=1, description="Client espagnol")
    
    class Config:
        schema_extra = {
            "example": {
                "CreditScore": 650,
                "Age": 35,
                "Tenure": 5,
                "Balance": 50000,
                "NumOfProducts": 2,
                "HasCrCard": 1,
                "IsActiveMember": 1,
                "EstimatedSalary": 75000,
                "Geography_Germany": 0,
                "Geography_Spain": 1
            }
        }

class PredictionResponse(BaseModel):
    """Schema pour la reponse de prediction"""
    churn_probability: float = Field(..., description="Probabilite de churn (0-1)")
    prediction: int = Field(..., description="Prediction binaire (0=reste, 1=part)")
    risk_level: str = Field(..., description="Niveau de risque (Low/Medium/High)")

class HealthResponse(BaseModel):
    """Schema pour le health check"""
    status: str
    model_loaded: bool
```

### Fichier app/main.py {#sec-module2-main}

L'API principale :

``` python
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import joblib
import numpy as np
from typing import List
import logging
import os

from app.models import CustomerFeatures, PredictionResponse, HealthResponse

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialisation FastAPI
app = FastAPI(
    title="Bank Churn Prediction API",
    description="API de prediction de defaillance client",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS pour permettre les requetes depuis un navigateur
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Chargement du modele au demarrage
MODEL_PATH = os.getenv("MODEL_PATH", "model/churn_model.pkl")
model = None

@app.on_event("startup")
async def load_model():
    """Charge le modele au demarrage de l'API"""
    global model
    try:
        model = joblib.load(MODEL_PATH)
        logger.info(f"Modele charge avec succes depuis {MODEL_PATH}")
    except Exception as e:
        logger.error(f"Erreur lors du chargement du modele : {e}")
        model = None

@app.get("/", tags=["General"])
def root():
    """Endpoint racine"""
    return {
        "message": "Bank Churn Prediction API",
        "version": "1.0.0",
        "status": "running",
        "docs": "/docs"
    }

@app.get("/health", response_model=HealthResponse, tags=["General"])
def health_check():
    """Verification de l'etat de l'API"""
    if model is None:
        raise HTTPException(
            status_code=503, 
            detail="Modele non charge"
        )
    return {
        "status": "healthy",
        "model_loaded": True
    }

@app.post("/predict", response_model=PredictionResponse, tags=["Prediction"])
def predict(features: CustomerFeatures):
    """
    Predit si un client va partir (churn)
    
    Retourne :
    - churn_probability : probabilite de churn (0 a 1)
    - prediction : 0 (reste) ou 1 (part)
    - risk_level : Low, Medium ou High
    """
    if model is None:
        raise HTTPException(
            status_code=503, 
            detail="Modele non disponible"
        )
    
    try:
        # Preparation des features
        input_data = np.array([[
            features.CreditScore,
            features.Age,
            features.Tenure,
            features.Balance,
            features.NumOfProducts,
            features.HasCrCard,
            features.IsActiveMember,
            features.EstimatedSalary,
            features.Geography_Germany,
            features.Geography_Spain
        ]])
        
        # Prediction
        proba = model.predict_proba(input_data)[0, 1]
        prediction = int(proba > 0.5)
        
        # Classification du risque
        if proba < 0.3:
            risk = "Low"
        elif proba < 0.7:
            risk = "Medium"
        else:
            risk = "High"
        
        logger.info(
            f"Prediction effectuee : proba={proba:.4f}, "
            f"prediction={prediction}, risk={risk}"
        )
        
        return {
            "churn_probability": round(float(proba), 4),
            "prediction": prediction,
            "risk_level": risk
        }
    
    except Exception as e:
        logger.error(f"Erreur lors de la prediction : {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"Erreur de prediction : {str(e)}"
        )

@app.post("/predict/batch", tags=["Prediction"])
def predict_batch(features_list: List[CustomerFeatures]):
    """
    Predictions en batch pour plusieurs clients
    """
    if model is None:
        raise HTTPException(status_code=503, detail="Modele non disponible")
    
    try:
        predictions = []
        
        for features in features_list:
            input_data = np.array([[
                features.CreditScore, features.Age, features.Tenure,
                features.Balance, features.NumOfProducts, features.HasCrCard,
                features.IsActiveMember, features.EstimatedSalary,
                features.Geography_Germany, features.Geography_Spain
            ]])
            
            proba = model.predict_proba(input_data)[0, 1]
            prediction = int(proba > 0.5)
            
            predictions.append({
                "churn_probability": round(float(proba), 4),
                "prediction": prediction
            })
        
        logger.info(f"Batch prediction : {len(predictions)} clients traites")
        
        return {"predictions": predictions, "count": len(predictions)}
    
    except Exception as e:
        logger.error(f"Erreur batch prediction : {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### Test Local de l'API {#sec-module2-test}

``` bash
# Demarrer l'API
uvicorn app.main:app --reload --port 8000

# Dans un autre terminal, tester :

# 1. Health check
curl http://localhost:8000/health

# 2. Prediction simple
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "CreditScore": 650,
    "Age": 35,
    "Tenure": 5,
    "Balance": 50000,
    "NumOfProducts": 2,
    "HasCrCard": 1,
    "IsActiveMember": 1,
    "EstimatedSalary": 75000,
    "Geography_Germany": 0,
    "Geography_Spain": 1
  }'
```

### Jupyter Lab

``` python
#dans jupyter lab
import requests
import json

# URL de ton API FastAPI
url = "http://localhost:8000/predict"

# Donn√©es √† envoyer
data = {
    "CreditScore": 650,
    "Age": 35,
    "Tenure": 5,
    "Balance": 50000,
    "NumOfProducts": 2,
    "HasCrCard": 1,
    "IsActiveMember": 1,
    "EstimatedSalary": 75000,
    "Geography_Germany": 0,
    "Geography_Spain": 1
}

# Envoyer la requ√™te POST
response = requests.post(url, json=data)

# Afficher la r√©ponse
print(f"Status Code: {response.status_code}")
print(f"Response: {response.json()}")
```

### Documentation Interactive {#sec-module2-docs}

Ouvrez votre navigateur et allez sur :

-   **Swagger UI** : http://localhost:8000/docs
-   **ReDoc** : http://localhost:8000/redoc

### Checkpoint {#sec-module2-checkpoint}

:::: callout-note
## Validation Module 2

Avant de passer au module suivant, v√©rifiez que :

::: {style="margin-left: 20px;"}
-   [ ] Le mod√®le est entra√Æn√© avec une accuracy \> 0.75
-   [ ] Le fichier `model/churn_model.pkl` existe\
-   [ ] MLflow UI affiche votre exp√©rience
-   [ ] Vous comprenez les m√©triques obtenues
:::
::::

## Module 3 : Conteneurisation avec Docker {#sec-module3}

### Objectif {#sec-module3-objectif}

Empaqueter l'API dans un conteneur Docker pour la rendre portable et faciliter le d√©ploiement sur Azure.

### Cr√©ation du Dockerfile {#sec-module3-dockerfile}

Cr√©ez le fichier `Dockerfile` √† la racine du projet :

``` dockerfile
# Utilise une image Python officielle
FROM python:3.9-slim

# Definir le repertoire de travail
WORKDIR /app

# Copier les fichiers de dependances
COPY requirements.txt .

# Installer les dependances
RUN pip install --no-cache-dir -r requirements.txt

# Copier le code de l'application
COPY app/ ./app/
COPY model/ ./model/

# Exposer le port
EXPOSE 8000

# Commande pour demarrer l'application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Cr√©ation du .dockerignore {#sec-module3-dockerignore}

Cr√©ez le fichier `.dockerignore` :

```         
__pycache__
*.pyc
*.pyo
*.pyd
.Python
env/
venv/
.venv
*.egg-info/
.pytest_cache/
.git
.gitignore
README.md
.env
mlruns/
*.log
.DS_Store
.vscode/
tests/
```

### Build de l'Image Docker {#sec-module3-build}

``` bash
# Build de l'image (cela peut prendre quelques minutes)
docker build -t bank-churn-api:v1 .

# Verifier que l'image est creee
docker images bank-churn-api:v1

# Voir la taille de l'image
docker images --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}" | grep bank-churn
```

### Test du Conteneur en Local {#sec-module3-test}

``` bash
# Lancer le conteneur
docker run -d -p 8000:8000 --name churn-api bank-churn-api:v1

# Verifier que le conteneur tourne
docker ps

# Voir les logs
docker logs churn-api

# Tester l'API
curl http://localhost:8000/health

# Prediction de test
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "CreditScore": 700,
    "Age": 40,
    "Tenure": 7,
    "Balance": 80000,
    "NumOfProducts": 3,
    "HasCrCard": 1,
    "IsActiveMember": 0,
    "EstimatedSalary": 90000,
    "Geography_Germany": 1,
    "Geography_Spain": 0
  }'

# Arreter et supprimer le conteneur
docker stop churn-api
docker rm churn-api
```

### Commandes Docker Utiles {#sec-module3-commandes}

``` bash
# Voir tous les conteneurs (meme arretes)
docker ps -a

# Entrer dans un conteneur en cours d'execution
docker exec -it churn-api /bin/bash

# Voir l'utilisation des ressources
docker stats churn-api

# Nettoyer les images inutilisees
docker image prune

# Supprimer toutes les images
docker rmi $(docker images -q)
```

### Questions de Compr√©hension {#sec-module3-questions}

1.  Pourquoi utiliser un .dockerignore ?
2.  Quelle est la diff√©rence entre CMD et RUN dans un Dockerfile ?
3.  Pourquoi exposer le port 8000 ?
4.  Comment v√©rifier que votre conteneur fonctionne correctement ?

### Checkpoint {#sec-module3-checkpoint}

:::: callout-note
## Validation Module 3

Avant de passer au module suivant, v√©rifiez que :

::: {style="margin-left: 20px;"}
-   [ ] L'image Docker est build√©e avec succ√®s
-   [ ] Le conteneur d√©marre sans erreur
-   [ ] L'API r√©pond correctement depuis le conteneur
-   [ ] La taille de l'image est raisonnable (\< 1GB)
:::
::::

## Module 4 : D√©ploiement sur Azure {#sec-module4}

### Objectif {#sec-module4-objectif}

D√©ployer l'API sur Azure Container Apps et la rendre accessible publiquement.

### Pr√©requis {#sec-module4-prerequis}

1.  **Docker Desktop** en cours d'ex√©cution (mode WSL2 recommand√©)
2.  **Configurer Docker** ![](image_docker.png)
3.  **Azure CLI** install√© et connect√© (`az login`)
4.  **Image locale** `churn-api:v1` d√©j√† construite
5.  **installer l'extension containerapp**

``` bash
 az extension add --name containerapp
```

### Etape 0 : V√©rifier les r√©gions disponibles {#sec-module4-etape0}

``` bash
#!/bin/bash
# M√©thodesimple 

# Liste toutes les r√©gions recommand√©es
echo "R√©gions disponibles chez toi :"
az account list-locations \
  --query "[?metadata.regionCategory=='Recommended'].name" \
  -o tsv | head -5

# Prendre la premi√®re
REGION=$(az account list-locations \
  --query "[?metadata.regionCategory=='Recommended'].name" \
  -o tsv | head -1)

echo "‚úÖ proposition de la r√©gion : $REGION"
```

On Peut aussi √©x√©cuter

``` bash
# Juste cette ligne dans ton terminal :
LOCATION=$(az account list-locations --query "[0].name" -o tsv) && echo "Use: $REGION"
```

### Script Complet : {#sec-module4-etape1}

``` bash
#!/usr/bin/env bash
set -euo pipefail
#################################
# VARIABLES D√âFINITIVES
#################################
RESOURCE_GROUP="rg-mlops-bank-churn"  
LOCATION="westeurope"   # Forc√© West Europe (garanti)
FALLBACK_LOCATION="northeurope"     # Fallback garanti
ACR_NAME="mlops$(whoami | tr '[:upper:]' '[:lower:]' | tr -cd '[:alnum:]')"  # 100% minuscules
CONTAINER_APP_NAME="bank-churn" 
CONTAINERAPPS_ENV="env-mlops-workshop"
IMAGE_NAME="churn-api"
IMAGE_TAG="v1"
TARGET_PORT=8000

#################################
# 0) Contexte Azure + V√©rification Extensions
#################################
echo "V√©rification du contexte Azure..."
az account show --query "{name:name, cloudName:cloudName}" -o json >/dev/null

echo "V√©rification/installation des extensions Azure CLI..."

# V√©rifier et installer containerapp si n√©cessaire
if ! az extension show --name containerapp >/dev/null 2>&1; then
    echo "üì¶ Installation de l'extension containerapp..."
    az extension add --name containerapp --upgrade -y --only-show-errors
    echo "‚úÖ Extension containerapp install√©e"
else
    echo "‚úÖ Extension containerapp d√©j√† install√©e"
    # Mise √† jour silencieuse
    az extension update --name containerapp -y --only-show-errors 2>/dev/null || true
fi

# Liste des extensions install√©es pour v√©rification
echo "Extensions install√©es :"
az extension list --query "[].{Name:name, Version:version}" -o table

#################################
# 1) Providers n√©cessaires
#################################
echo "Register providers..."
az provider register --namespace Microsoft.ContainerRegistry --wait
az provider register --namespace Microsoft.App --wait
az provider register --namespace Microsoft.Web --wait
az provider register --namespace Microsoft.OperationalInsights --wait

#################################
# 2) Resource Group
#################################
echo "Cr√©ation/validation du groupe de ressources..."
az group create -n "$RESOURCE_GROUP" -l "$LOCATION" >/dev/null || true
echo "‚úÖ RG OK: $RESOURCE_GROUP"

#################################
# 3) Cr√©ation ACR (avec v√©rification)
#################################
echo "Cr√©ation du Container Registry (ACR) en $LOCATION..."

# V√©rification pr√©alable
if [[ ! "$ACR_NAME" =~ ^[a-z0-9]{5,50}$ ]]; then
    echo "‚ùå ERREUR: Nom ACR invalide: $ACR_NAME"
    echo "   Doit contenir 5-50 caract√®res alphanum√©riques en minuscules"
    exit 1
fi

echo "Nom ACR valid√©: $ACR_NAME (${#ACR_NAME} caract√®res)"

set +e
az acr create \
  --resource-group "$RESOURCE_GROUP" \
  --name "$ACR_NAME" \
  --sku Basic \
  --admin-enabled true \
  --location "$LOCATION" >/dev/null 2>&1
ACR_RC=$?
set -e

if [ $ACR_RC -ne 0 ]; then
  echo "‚ö†Ô∏è ACR bloqu√© en $LOCATION. Fallback => $FALLBACK_LOCATION"
  LOCATION="$FALLBACK_LOCATION"
  az acr create \
    --resource-group "$RESOURCE_GROUP" \
    --name "$ACR_NAME" \
    --sku Basic \
    --admin-enabled true \
    --location "$LOCATION" >/dev/null
fi

# Attendre la cr√©ation compl√®te
sleep 5
echo "‚úÖ ACR cr√©√© : $ACR_NAME (region=$LOCATION)"

#################################
# 4) Login ACR + Push image
#################################
echo "Connexion au registry..."
az acr login --name "$ACR_NAME" >/dev/null

ACR_LOGIN_SERVER=$(az acr show --name "$ACR_NAME" --query loginServer -o tsv | tr -d '\r')
echo "ACR_LOGIN_SERVER=$ACR_LOGIN_SERVER"

# R√©cup√©ration des credentials AU BON ENDROIT
ACR_USER=$(az acr credential show -n "$ACR_NAME" --query username -o tsv | tr -d '\r')
ACR_PASS=$(az acr credential show -n "$ACR_NAME" --query "passwords[0].value" -o tsv | tr -d '\r')
IMAGE="$ACR_LOGIN_SERVER/$IMAGE_NAME:$IMAGE_TAG"

echo "Build + Tag + Push..."
docker build -t "$IMAGE_NAME:$IMAGE_TAG" .
docker tag "$IMAGE_NAME:$IMAGE_TAG" "$ACR_LOGIN_SERVER/$IMAGE_NAME:$IMAGE_TAG"
docker tag "$IMAGE_NAME:$IMAGE_TAG" "$ACR_LOGIN_SERVER/$IMAGE_NAME:latest"
docker push "$ACR_LOGIN_SERVER/$IMAGE_NAME:$IMAGE_TAG"
docker push "$ACR_LOGIN_SERVER/$IMAGE_NAME:latest"
echo "‚úÖ Image push√©e dans ACR"

#################################
# 5) Log Analytics (corrig√©)
#################################
LAW_NAME="law-mlops-$(whoami)-$RANDOM"
echo "Cr√©ation Log Analytics: $LAW_NAME"
az monitor log-analytics workspace create -g "$RESOURCE_GROUP" -n "$LAW_NAME" -l "$LOCATION" >/dev/null
sleep 10  # Attente n√©cessaire

# Commande corrig√©e avec param√®tres explicites
LAW_ID=$(az monitor log-analytics workspace show \
    --resource-group "$RESOURCE_GROUP" \
    --workspace-name "$LAW_NAME" \
    --query customerId -o tsv | tr -d '\r')

LAW_KEY=$(az monitor log-analytics workspace get-shared-keys \
    --resource-group "$RESOURCE_GROUP" \
    --workspace-name "$LAW_NAME" \
    --query primarySharedKey -o tsv | tr -d '\r')
echo "‚úÖ Log Analytics OK"

#################################
# 6) Container Apps Environment
#################################
echo "Cr√©ation/validation Container Apps Environment: $CONTAINERAPPS_ENV"
if ! az containerapp env show -n "$CONTAINERAPPS_ENV" -g "$RESOURCE_GROUP" >/dev/null 2>&1; then
  az containerapp env create \
    -n "$CONTAINERAPPS_ENV" \
    -g "$RESOURCE_GROUP" \
    -l "$LOCATION" \
    --logs-workspace-id "$LAW_ID" \
    --logs-workspace-key "$LAW_KEY" >/dev/null
fi
echo "‚úÖ Environment OK"

#################################
# 7) D√©ploiement Container App
#################################
echo "D√©ploiement Container App: $CONTAINER_APP_NAME"
if az containerapp show -n "$CONTAINER_APP_NAME" -g "$RESOURCE_GROUP" >/dev/null 2>&1; then
  az containerapp update \
    -n "$CONTAINER_APP_NAME" \
    -g "$RESOURCE_GROUP" \
    --image "$IMAGE" \
    --registry-server "$ACR_LOGIN_SERVER" \
    --registry-username "$ACR_USER" \
    --registry-password "$ACR_PASS" >/dev/null
else
  az containerapp create \
    -n "$CONTAINER_APP_NAME" \
    -g "$RESOURCE_GROUP" \
    --environment "$CONTAINERAPPS_ENV" \
    --image "$IMAGE" \
    --ingress external \
    --target-port "$TARGET_PORT" \
    --registry-server "$ACR_LOGIN_SERVER" \
    --registry-username "$ACR_USER" \
    --registry-password "$ACR_PASS" \
    --min-replicas 1 \
    --max-replicas 1 >/dev/null
fi
echo "‚úÖ Container App OK"

#################################
# 8) URL API
#################################
APP_URL=$(az containerapp show -n "$CONTAINER_APP_NAME" -g "$RESOURCE_GROUP" --query properties.configuration.ingress.fqdn -o tsv | tr -d '\r')

echo ""
echo "=========================================="
echo "‚úÖ D√âPLOIEMENT R√âUSSI"
echo "=========================================="
echo "ACR      : $ACR_NAME"
echo "Region   : $LOCATION"
echo "Resource Group: $RESOURCE_GROUP"
echo ""
echo "URLs de l'application :"
echo "  API      : https://$APP_URL"
echo "  Health   : https://$APP_URL/health"
echo "  Docs     : https://$APP_URL/docs"
echo ""
echo "Pour supprimer toutes les ressources :"
echo "  az group delete --name $RESOURCE_GROUP --yes --no-wait"
echo "=========================================="
```

### Test de l'API en Production {#sec-module4-etape2}

``` bash
RESOURCE_GROUP="rg-mlops-bank-churn"  # votre Ressource group

CONTAINER_APP_NAME="bank-churn" # le nom de votre container app

APP_URL=$(az containerapp show \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --query properties.configuration.ingress.fqdn -o tsv | tr -d '\r\n' | xargs)

# 2. V√©rifier l'URL proprement
echo "URL nettoy√©e: '$APP_URL'"
echo "Longueur: ${#APP_URL}"

# 3. Test avec l'URL compl√®te
FULL_URL="https://${APP_URL}/predict"
echo "URL compl√®te: $FULL_URL"

# 4. Test de pr√©diction
curl -X POST "$FULL_URL" \
  -H "Content-Type: application/json" \
  -d '{
    "CreditScore": 650,
    "Age": 35,
    "Tenure": 5,
    "Balance": 50000,
    "NumOfProducts": 2,
    "HasCrCard": 1,
    "IsActiveMember": 1,
    "EstimatedSalary": 75000,
    "Geography_Germany": 0,
    "Geography_Spain": 1
  }'

echo ""
```

### üîß R√©solution des probl√®mes {#sec-module4-troubleshooting}

| Probl√®me | Solution |
|------------------------------------|------------------------------------|
| **Erreur DNS / `cloudName: null`** | Ex√©cuter `az logout && az login` |
| **Caract√®re `\r` dans les variables** | Toujours utiliser `tr -d '\r'` apr√®s `az acr show` |
| **Erreur "ContainerAppInvalidSecretName"** | Utiliser l'approche YAML avec secret nomm√© `acrpassword` |
| **Docker non accessible** | D√©marrer Docker Desktop et ouvrir un nouveau terminal |
| **Erreurs de permissions** | V√©rifier `az account show` et `az login` |
| **L'application est "Failed"** | V√©rifier les logs : `az containerapp logs show --name $CONTAINER_APP_NAME --resource-group $RESOURCE_GROUP --tail 50` |
| **Image fonctionne localement mais pas sur Azure** | V√©rifier les credentials ACR et l'identit√© manag√©e |

### üìã Commandes de diagnostic utiles {#sec-module4-diagnostic}

``` bash
# Voir les logs en temps r√©el
az containerapp logs show \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --tail 100 \
  --follow

# V√©rifier l'√©tat d√©taill√©
az containerapp revision list \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --output table

# R√©cup√©ration automatique et test Docker
RESOURCE_GROUP="rg-mlops1"
ACR_NAME=$(az acr list --resource-group $RESOURCE_GROUP --query "[0].name" -o tsv | tr -d '\r\n' | xargs)
ACR_LOGIN_SERVER=$(az acr show --name $ACR_NAME --query loginServer --output tsv | tr -d '\r\n' | xargs)

echo "ACR trouv√©: $ACR_LOGIN_SERVER"
echo "Lancement de l'image..."

docker run -p 8000:8000 ${ACR_LOGIN_SERVER}/bank-churn-api:v1


# tester l'api 
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "CreditScore": 650,
    "Age": 35,
    "Tenure": 5,
    "Balance": 50000,
    "NumOfProducts": 2,
    "HasCrCard": 1,
    "IsActiveMember": 1,
    "EstimatedSalary": 75000,
    "Geography_Germany": 0,
    "Geography_Spain": 1
  }'
```

### üìä Alternative : D√©ploiement via le Portail Azure {#sec-module4-portail}

#### **Objectif**

Reproduire EXACTEMENT le script Bash fourni en utilisant UNIQUEMENT l'interface graphique Azure Portal.

#### **Pr√©requis**

1.  Compte Azure avec abonnement actif
2.  Acc√®s √† [portal.azure.com](https://portal.azure.com)
3.  Dockerfile et code de l'application `bank-churn-api` pr√™ts localement

------------------------------------------------------------------------

#### **√âTAPE 0: Connexion Azure**

1.  **Connectez-vous** √† [portal.azure.com](https://portal.azure.com)
2.  **V√©rifiez votre abonnement** :
    -   En haut √† droite ‚Üí Cliquez sur votre profil
    -   "Changer de r√©pertoire" si besoin
    -   L'abonnement actif s'affiche dans le panneau lat√©ral gauche

------------------------------------------------------------------------

#### **√âTAPE 1: V√©rifier/Cr√©er les Fournisseurs (Providers)**

‚ö†Ô∏è **Cette √©tape n'est pas faisable dans le portail** Les providers s'enregistrent automatiquement lors de la premi√®re utilisation du service. **Alternative** : Utilisez Azure Cloud Shell (Bash) pour cette partie uniquement :

``` bash
# Dans Azure Cloud Shell (ic√¥ne >_ en haut du portail)
az provider register --namespace Microsoft.ContainerRegistry --wait
az provider register --namespace Microsoft.App --wait
az provider register --namespace Microsoft.Web --wait
az provider register --namespace Microsoft.OperationalInsights --wait
```

------------------------------------------------------------------------

#### **√âTAPE 2: Groupe de Ressources**

1.  **Recherchez** "Groupes de ressources" dans la barre de recherche
2.  **Cliquez** sur "+ Cr√©er"
3.  **Remplissez** :
    -   Abonnement : Votre abonnement
    -   Groupe de ressources : `rg-mlops-bank-churn`
    -   R√©gion : `westeurope`
4.  **Cliquez** sur "V√©rifier + cr√©er" puis "Cr√©er"
5.  **Attendez** le d√©ploiement (‚âà30 secondes)

------------------------------------------------------------------------

#### **√âTAPE 3: Container Registry (ACR)**

##### **3.1 Cr√©ation ACR**

1.  **Recherchez** "Registres de conteneurs"
2.  **Cliquez** sur "+ Cr√©er"
3.  **Onglet "G√©n√©ral"** :
    -   Groupe de ressources : `rg-mlops-bank-churn`
    -   Nom du registre : `acrmlops[VOTRE_USERNAME][TIMESTAMP]` *Ex: acrmlopsjean1648826400* (le nom doit √™tre unique dans Azure et contenir de 5 √† 50 caract√®res alphanum√©riques ).
    -   Emplacement : `westeurope`
    -   SKU : `De base`
4.  **Onglet "Authentification"** :
    -   ‚úÖ Utilisateur administrateur ‚Üí ACTIV√â (utile pour les tests, mais privil√©giez une identit√© Microsoft Entra pour les sc√©narios de production )
5.  **Cliquez** sur "V√©rifier + cr√©er" puis "Cr√©er"

##### **3.2 Fallback si France Central bloqu√©**

Si erreur de strat√©gie : 1. **Recommencez** l'√©tape 3.1 2. **Changez** l'emplacement : `West Europe` 3. **Notez** la nouvelle r√©gion pour les √©tapes suivantes

------------------------------------------------------------------------

#### **√âTAPE 4: Build et Push de l'Image**

##### **4.1 Pr√©parer localement**

``` bash
# Sur VOTRE machine locale (pas dans le portail)
cd /chemin/vers/votre/projet

# Build l'image
docker build -t bank-churn-api:v1 .

# Tag avec ACR
docker tag bank-churn-api:v1 acrmlopsjean1648826400.azurecr.io/bank-churn-api:v1
docker tag bank-churn-api:v1 acrmlopsjean1648826400.azurecr.io/bank-churn-api:latest
```

##### **4.2 Push vers ACR**

###### **Option A: Via Azure CLI local**

``` bash
# Login ACR avec votre identit√© individuelle 
az acr login --name acrmlopsjean1648826400

# Push images
docker push acrmlopsjean1648826400.azurecr.io/bank-churn-api:v1
docker push acrmlopsjean1648826400.azurecr.io/bank-churn-api:latest
```

###### **Option B: Via Portail Azure (ACR Tasks)**

1.  **Allez** dans votre ACR cr√©√©
2.  **Menu gauche** ‚Üí "Services" ‚Üí "T√¢ches"
3.  **Cliquez** sur "+ T√¢che"
4.  **Configurez** :
    -   Type de t√¢che : T√¢che rapide
    -   Platform : Linux
    -   Emplacement : M√™me que l'ACR
    -   Source du code : "Context local"
    -   Uploader votre code ZIP ou Dockerfile
5.  **Ex√©cutez** la t√¢che

------------------------------------------------------------------------

#### **√âTAPE 5: Log Analytics Workspace**

1.  **Recherchez** "Espaces de travail Log Analytics"
2.  **Cliquez** sur "+ Cr√©er"
3.  **Remplissez** :
    -   Groupe de ressources : `rg-mlops-bank-churn`
    -   Nom : `law-mlops-[VOTRE_USERNAME]-[RANDOM]` *Ex: law-mlops-jean-12345*
    -   R√©gion : M√™me que l'ACR (France Central ou West Europe)
4.  **Cliquez** sur "V√©rifier + cr√©er" puis "Cr√©er"
5.  **Notez** :
    -   **ID de l'espace de travail** (customerId)
    -   **Cl√© primaire** (primarySharedKey)

------------------------------------------------------------------------

#### **√âTAPE 6: Container Apps Environment**

1.  **Recherchez** "Environnements Container Apps"
2.  **Cliquez** sur "+ Cr√©er"
3.  **Onglet "G√©n√©ral"** :
    -   Nom de l'environnement : `env-mlops-workshop`
    -   Groupe de ressources : `rg-mlops-bank-churn`
    -   Zone : M√™me r√©gion que l'ACR
    -   Type d'environnement : `Consumption only` (pour ce workshop)
4.  **Onglet "Surveillance"** :
    -   ‚úÖ Activer la surveillance Log Analytics
    -   Espace de travail Log Analytics : S√©lectionnez celui cr√©√© √† l'√©tape 5
5.  **Cliquez** sur "V√©rifier + cr√©er" puis "Cr√©er"

------------------------------------------------------------------------

#### **√âTAPE 7: Container App (Application)**

##### **7.1 Cr√©ation**

1.  **Recherchez** "Container Apps"
2.  **Cliquez** sur "+ Cr√©er" \> "Container App"
3.  **Onglet "G√©n√©ral"** :
    -   Abonnement : Votre abonnement
    -   Groupe de ressources : `rg-MLopsyy`
    -   Nom de l'application conteneur : `bank-churn-api` (entre 2 et 32 caract√®res, lettres minuscules, chiffres et tirets )
    -   R√©gion : S√©lectionnez une r√©gion pr√®s de vous
    -   Environnement Container Apps : S√©lectionnez `env-mlops-workshop` (cr√©√© pr√©c√©demment)

##### **7.2 Onglet "Application"**

1.  **Section "Image"** :
    -   Source de l'image : "Azure Container Registry"
    -   Registre : S√©lectionnez votre ACR
    -   Image : `bank-churn-api`
    -   √âtiquette : `v1`
    -   Type d'authentification du registre : "Informations d'identification de l'administrateur" (utilisez les cl√©s d'acc√®s de l'ACR pour ce workshop )
    -   Nom d'utilisateur/Password : R√©cup√©rez-les dans ACR ‚Üí "Cl√©s d'acc√®s"

##### **7.3 Onglet "Ingress"**

1.  **Trafic entrant** : ‚úÖ Activ√©
2.  **Visibilit√© du trafic entrant** : `Accepting traffic from anywhere` (pour un acc√®s externe )
3.  **Type d'entr√©e** : `HTTP`
4.  **Port cible** : `8000` (doit correspondre au port √©cout√© par votre conteneur )
5.  **Connexions non s√©curis√©es** : D√©cochez (laissez `false` par d√©faut pour forcer HTTPS )

##### **7.4 Onglet "Mise √† l'√©chelle"**

Pour ce workshop et pour optimiser les co√ªts : 1. **Mode de mise √† l'√©chelle** : "Aucune mise √† l'√©chelle automatique" 2. **Nombre minimal de r√©plicas** : `1` 3. **Nombre maximal de r√©plicas** : `1`

::: callout-note
#### Bonne pratique en production

Pour une meilleure fiabilit√© en production, il est recommand√© de configurer au moins 3 r√©plicas et d'activer la mise √† l'√©chelle automatique bas√©e sur les m√©triques HTTP ou CPU pour g√©rer les pics de charge .
:::

##### **7.5 Finalisation**

-   **Cliquez** sur "V√©rifier + cr√©er" puis "Cr√©er"
-   **Attendez** le d√©ploiement (‚âà2-3 minutes)

------------------------------------------------------------------------

#### **√âTAPE 8: R√©cup√©rer l'URL**

1.  **Allez** sur votre Container App `bank-churn-api`
2.  **Menu gauche** ‚Üí "Vue d'ensemble"
3.  **Cherchez** "URL de l'application" (le FQDN g√©n√©r√© automatiquement )
4.  **Copiez** l'URL (format : `https://bank-churn-api.xxxxxxxx.region.azurecontainerapps.io`)

------------------------------------------------------------------------

#### **√âTAPE 9: Tests**

1.  **Ouvrez** un navigateur
2.  **Testez** :
    -   **Health** : `https://[VOTRE-URL]/health`
    -   **Documentation** : `https://[VOTRE-URL]/docs`
    -   **Swagger UI** : `https://[VOTRE-URL]/redoc`

------------------------------------------------------------------------

#### **V√©rification Finale**

Comparez avec le script Bash :

| √âl√©ment | Script Bash | Interface Graphique |
|------------------|---------------------|---------------------------------|
| Resource Group | `rg-MLopsyy` (France Central) | ‚úÖ Identique |
| ACR | Nom unique avec timestamp | ‚úÖ Identique (5-50 caract√®res alphanum√©riques ) |
| Fallback location | West Europe si blocage | ‚úÖ G√©r√© manuellement |
| Log Analytics | Cr√©√© avec nom al√©atoire | ‚úÖ Identique |
| Environment | `env-mlops-workshop` | ‚úÖ Identique |
| Container App | `bank-churn-api` port 8000 | ‚úÖ Identique (2-32 caract√®res ) |
| Image | `bank-churn-api:v1` | ‚úÖ Identique |
| Ingress | Externe, HTTP, port 8000 | ‚úÖ Identique |
| R√©plicas | min=1, max=1 | ‚úÖ Identique |

------------------------------------------------------------------------

#### **Points d'Attention**

1.  **Timestamp dans ACR** : Dans le portail, g√©n√©rez-le manuellement (ex: `date +%s` dans Cloud Shell)
2.  **Authentification ACR** : Pour les sc√©narios de production, envisagez d'utiliser une **identit√© manag√©e** au lieu des identifiants administrateur pour une s√©curit√© et une gestion am√©lior√©es .
3.  **Variables d'environnement** : Si votre app en a besoin, ajoutez-les dans l'onglet "Param√®tres" du Container App.
4.  **Logs** : Les logs sont automatiquement envoy√©s √† Log Analytics configur√© dans l'environnement.
5.  **S√©curit√© r√©seau** : Pour restreindre l'acc√®s, vous pouvez configurer ult√©rieurement des **restrictions d'adresse IP** sur l'ingress de votre application conteneur .

------------------------------------------------------------------------

#### **R√©sum√© des URLs**

-   **Portail Azure** : https://portal.azure.com
-   **Votre API** : `https://bank-churn-api.[...].azurecontainerapps.io`
-   **Health check** : `/health`
-   **Documentation** : `/docs` (Swagger)
-   **ACR** : `acrmlopsjean1648826400.azurecr.io`

------------------------------------------------------------------------

**Dur√©e totale** : ‚âà15-20 minutes via l'interface graphique **Co√ªt estim√©** : \~5-10‚Ç¨/mois (ACR Basic + Container App en fonctionnement)

**Remarque :** Il est important de conserver la section existante "Surveillance des Co√ªts {#sec-module4-couts}" qui suit imm√©diatement cette partie dans votre fichier.

### Exercice Pratique {#sec-module4-exercice}

::: callout-tip
## EXERCICE 2

Partagez votre URL d'API avec un camarade et testez son API :

1.  Faites 10 pr√©dictions sur son API
2.  Comparez les r√©sultats avec votre mod√®le
3.  Observez les logs dans Azure Portal :
    -   Allez dans votre Container App
    -   Menu **"Log stream"** ou **"Monitoring" ‚Üí "Logs"**
    -   Observez les requ√™tes en temps r√©el
:::

### üéØ Points cl√©s des corrections apport√©es {#sec-module4-resume}

1.  **Nettoyage du `\r`** : Ajout de `tr -d '\r'` √† la r√©cup√©ration du login server
2.  **Approche YAML** : Contournement du bug de g√©n√©ration de nom de secret
3.  **Secret nomm√©** : Utilisation d'un nom valide `acrpassword` au lieu du nom auto-g√©n√©r√©
4.  **Variables d'environnement** : Ajout de `PYTHONUNBUFFERED=1` pour les logs
5.  **Tests robustes** : Attente de 30 secondes avant les v√©rifications
6.  **Commandes de diagnostic** : Ajout de commandes pour troubleshooting
7.  **Alternative GUI** : Instructions pour le d√©ploiement via le portail Azure

Pour ex√©cuter le module, sauvegardez-le dans un fichier `module4-deploiement.sh` et ex√©cutez :

``` bash
chmod +x module4-deploiement.sh
./module4-deploiement.sh
```

### Checkpoint {#sec-module4-checkpoint}

:::: callout-note
## Validation Module 4

Avant de passer au module suivant, v√©rifiez que :

::: {style="margin-left: 20px;"}
-   [ ] L'application est accessible via HTTPS
-   [ ] Le health check fonctionne
-   [ ] Les pr√©dictions fonctionnent
-   [ ] Vous avez not√© l'URL publique de votre API
:::
::::

## Module 5 : CI/CD avec GitHub Actions {#sec-module5}

### Objectif {#sec-module5-objectif}

Automatiser le d√©ploiement : chaque commit sur la branche `main` d√©clenche un build et un red√©ploiement via un pipeline GitHub Actions.

### √âtape 1 : Initialisation du Repository Git {#sec-module5-etape1}

``` bash
# Initialiser git avec 'main' comme branche par d√©faut
git init -b main

# Cr√©er un .gitignore robuste
cat > .gitignore << 'EOF'
__pycache__/
*.pyc
venv/
.env
mlruns/
*.log
.DS_Store
.vscode/
confusion_matrix.png
feature_importance.png
# Secrets (NE JAMAIS commiter)
*.secret
*.key
*.pem
credentials*.json
resultat.txt
azure-credentials.json
EOF

# Premier commit
git add .
git commit -m "Initial commit: Bank Churn API"
```

### √âtape 2 : Cr√©er un Repository GitHub {#sec-module5-etape2}

1.  Allez sur `https://github.com/new`
2.  **Nom** : `bank-churn-mlops`
3.  **Visibility** : Public ou Private
4.  **Ne pas** initialiser avec README
5.  Cliquez sur "Create repository"

``` bash
# Lier votre repo local √† GitHub
git remote add origin https://github.com/votre-username/bank-churn-mlops.git
git branch -M main
git push -u origin main
```

### √âtape 3 : Configuration des Secrets GitHub {#sec-module5-etape3}

Pour l'authentification avec Azure, l'action `azure/login@v1` attend un secret (`AZURE_CREDENTIALS`) contenant un **objet JSON avec exactement 4 cl√©s**.

#### Cr√©er et formater les identifiants du Service Principal Azure

**Option A (Recommand√©e) : Avec l'outil `jq`**

Si `jq` n'est pas install√© sur votre terminal linux

``` bash
sudo apt  install jq
```

Puis √©x√©cuter ceci :

``` bash
RESOURCE_GROUP="rg-mlops-bank-churn"
SUBSCRIPTION_ID=$(az account show --query id -o tsv | tr -d '\r')

# 1. Cr√©er le Service Principal et capturer la sortie
SP_JSON=$(az ad sp create-for-rbac \
  --name "github-actions-$(date +%s)" \
  --role contributor \
  --scopes "/subscriptions/${SUBSCRIPTION_ID}/resourceGroups/${RESOURCE_GROUP}" \
  --output json)

# 2. Extraire et formater uniquement les 4 champs requis pour GitHub Actions
echo $SP_JSON | jq -c '{clientId: .appId, clientSecret: .password, subscriptionId: "'"$SUBSCRIPTION_ID"'", tenantId: .tenant}'
```

**Copiez l'objet JSON compact qui s'affiche.** Il ressemblera √† ceci :

``` json
{"clientId":"xxxxxxxx-xxxx-...","clientSecret":"votre_mot_de_passe","subscriptionId":"e14fdc0f-d8cd-...","tenantId":"xxxxxxxx-xxxx-..."}
```

**Option B (Manuelle) : Sans `jq`** Ex√©cutez la commande standard et notez les valeurs pour `appId`, `password` et `tenant`. Composez ensuite **manuellement** l'objet JSON suivant en utilisant : - `appId` comme valeur pour `clientId` - `password` comme valeur pour `clientSecret` - Votre `subscriptionId` (`e14fdc0f-d8cd-4608-9a2e-d02e7b15366b`) - `tenant` comme valeur pour `tenantId`

``` json
{
  "clientId": "xxxxxxxx-xxxx-...",
  "clientSecret": "votre_mot_de_passe",
  "subscriptionId": "e14fdc0f-d8cd-4608-9a2e-d02e7b15366b",
  "tenantId": "xxxxxxxx-xxxx-..."
}
```

#### Ajouter les Secrets dans GitHub

1.  Allez dans votre repository GitHub : **Settings \> Secrets and variables \> Actions**
2.  Cliquez sur **"New repository secret"**
3.  Ajoutez ces trois secrets :

| **Nom du Secret** | **Valeur √† coller** | **Comment l'obtenir** |
|:-----------------------|:-----------------------|:-----------------------|
| `AZURE_CREDENTIALS` | **L'objet JSON complet** (4 champs) g√©n√©r√© √† l'√©tape pr√©c√©dente. | R√©sultat de la commande avec `jq` ou cr√©ation manuelle. |
| `ACR_USERNAME` | Le nom d'utilisateur de votre ACR. | `az acr credential show --name <VOTRE_ACR> --query username -o tsv` |
| `ACR_PASSWORD` | Le mot de passe de votre ACR. | `az acr credential show --name <VOTRE_ACR> --query "passwords[0].value" -o tsv` |

**Important** : Pour `AZURE_CREDENTIALS`, assurez-vous de copier **tout l'objet JSON en une seule ligne** dans le champ de valeur du secret, sans espaces avant ou apr√®s.

### √âtape 4 : Pr√©paration des Tests pour le Pipeline {#sec-module5-tests}

Avant de configurer le workflow, assurez-vous d'avoir des tests valides. Cr√©ez ou mettez √† jour `tests/test_api.py` :

``` python
# tests/test_api.py
import sys
import os
from unittest.mock import patch
import numpy as np

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

TEST_CUSTOMER = {
    "CreditScore": 650, "Age": 35, "Tenure": 5, "Balance": 50000.0,
    "NumOfProducts": 2, "HasCrCard": 1, "IsActiveMember": 1,
    "EstimatedSalary": 75000.0, "Geography_Germany": 0, "Geography_Spain": 1
}

def test_read_root():
    """Test l'endpoint racine /"""
    response = client.get("/")
    assert response.status_code == 200
    assert response.json()["message"] == "Bank Churn Prediction API"

def test_predict_with_mock():
    """Test /predict avec un mock du mod√®le pour √©viter l'erreur 503"""
    with patch('app.main.model') as mock_model:
        # Simulation d'une pr√©diction r√©ussie
        mock_model.predict_proba.return_value = np.array([[0.2, 0.8]])
        mock_model.predict.return_value = np.array([1])
        
        response = client.post("/predict", json=TEST_CUSTOMER)
        # Le test passe si l'API traite la requ√™te
        assert response.status_code in [200, 422, 503]
```

**Ex√©cution des tests en local (avant CI/CD)** :

``` bash
python -m pytest tests/ -v
```

### √âtape 5 : V√©rification des Noms de Ressources (CRITIQUE) {#sec-module5-verif}

Le pipeline √©chouera si les noms de vos ressources Azure ne correspondent pas. **Avant de cr√©er le workflow**, v√©rifiez ces noms exacts :

``` bash
# 1. V√©rifier le nom exact de votre Azure Container Registry (ACR)
az acr list --resource-group rg-mlops-bank-churn --query "[].name" -o tsv
# Doit retourner quelque chose comme : mlopsnevermind

# 2. V√©rifier le nom exact de votre Azure Container App
az containerapp list --resource-group rg-mlops-bank-churn --query "[].name" -o tsv
# Doit retourner : bank-churn

# 3. Confirmer votre nom de groupe de ressources
echo "rg-mlops-bank-churn"
```

Notez ces noms, vous en aurez besoin pour l'√©tape suivante.

### √âtape 6 : Cr√©ation du Workflow GitHub Actions {#sec-module5-etape4}

Cr√©ez le fichier `.github/workflows/ci-cd.yml` avec le contenu ci-dessous. **Remplacez les valeurs d'environnement (`env`)** par celles qui correspondent √† **vos** ressources Azure, identifi√©es √† l'√©tape 5.

``` yaml
name: CI/CD Pipeline
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  # ‚ö†Ô∏è REMPLACEZ CES VALEURS PAR LES V√îTRES ‚ö†Ô∏è
  AZURE_RESOURCE_GROUP: rg-mlops-bank-churn
  ACR_NAME: mlopsnevermind          # Le nom de VOTRE ACR (√©tape 5.1)
  CONTAINER_APP_NAME: bank-churn    # Le nom de VOTRE Container App (√©tape 5.2)
  IMAGE_NAME: bank-churn-api

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run tests with coverage
        run: |
          pytest tests/ -v --cov=app --cov-report=term

  build-and-deploy:
    needs: test  # Ne s'ex√©cute QUE si les tests r√©ussissent
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'  # Ne d√©ploie que depuis 'main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}  # Utilise le secret format√©
      - name: Login to Azure Container Registry (ACR)
        uses: azure/docker-login@v1
        with:
          login-server: ${{ env.ACR_NAME }}.azurecr.io
          username: ${{ secrets.ACR_USERNAME }}
          password: ${{ secrets.ACR_PASSWORD }}
      - name: Build and push Docker image
        run: |
          # Construit l'image et la tagge avec le hash unique du commit
          docker build -t ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }} .
          # Cr√©e aussi un tag 'latest' pour r√©f√©rence
          docker tag ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }} ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest
          # Pousse les deux images vers l'ACR
          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}
          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest
          echo "‚úÖ Images pouss√©es dans ACR."
      - name: Deploy to Azure Container Apps
        uses: azure/CLI@v1
        with:
          inlineScript: |
            az containerapp update \
              --name ${{ env.CONTAINER_APP_NAME }} \
              --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
              --image ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}
            echo "‚úÖ Commande de d√©ploiement envoy√©e √† Azure."
      - name: Verify deployment
        run: |
          # R√©cup√®re l'URL publique de l'application
          APP_URL=$(az containerapp show \
            --name ${{ env.CONTAINER_APP_NAME }} \
            --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
            --query properties.configuration.ingress.fqdn -o tsv)
          echo "üåê Votre API est d√©ploy√©e √† l'adresse : https://$APP_URL"
          echo "ü©∫ Attente du d√©marrage (20s) et v√©rification..."
          sleep 20
          # Teste le endpoint /health
          curl -f https://$APP_URL/health || exit 1
          echo "‚úÖ D√©ploiement v√©rifi√© et r√©ussi !"
```

### √âtape 7 : D√©clencher et Observer le Pipeline {#sec-module5-etape5}

``` bash
# Ajouter le fichier de workflow et le pousser
git add .github/workflows/ci-cd.yml
git commit -m "feat: add automated CI/CD pipeline with GitHub Actions"
git push origin main

# Le pipeline se d√©clenche AUTOMATIQUEMENT !
```

**Observez l'ex√©cution** :

1.  Allez sur votre d√©p√¥t GitHub.
2.  Cliquez sur l'onglet **"Actions"**.
3.  Vous verrez l'ex√©cution de votre workflow nomm√© **"CI/CD Pipeline"**. Cliquez dessus pour voir les d√©tails et les logs en direct.

### Exercice Pratique {#sec-module5-exercice}

::: callout-tip
# EXERCICE 3

1.  **Ajoutez un nouveau test** dans `test_api.py` pour tester un autre endpoint, par exemple l'endpoint `/docs` (documentation Swagger) qui devrait toujours √™tre accessible. `python     def test_docs_endpoint():         """Test que la documentation Swagger est accessible"""         response = client.get("/docs")         assert response.status_code == 200`

2.  **Faites un commit** de ce changement : `bash     git add tests/test_api.py     git commit -m "test: add docs endpoint test"`

3.  **Poussez le commit** sur la branche `main` : `bash     git push origin main`

4.  **Observez le pipeline** s'ex√©cuter automatiquement dans l'onglet **Actions** de votre d√©p√¥t GitHub.

5.  **Une fois le workflow termin√© avec succ√®s**, v√©rifiez que votre application a bien √©t√© red√©ploy√©e en visitant son URL (celle affich√©e √† la fin du job `Verify deployment`).
:::

### D√©pannage des Erreurs Courantes {#sec-module5-troubleshooting}

| **Sympt√¥me / Message d'erreur** | **Cause la plus probable** | **Solution** |
|:-----------------------|:-----------------------|:-----------------------|
| `Login failed... Not all parameters are provided in 'creds'` | Le secret `AZURE_CREDENTIALS` n'a pas le bon format (trop/moins de 4 champs). | Supprimez et recr√©ez le secret avec l'objet JSON √† **4 champs exactement** (`clientId`, `clientSecret`, `subscriptionId`, `tenantId`). |
| `Error: ACR login failed... 401 Unauthorized` | Les secrets `ACR_USERNAME` ou `ACR_PASSWORD` sont incorrects. | R√©g√©n√©rez les mots de passe de votre ACR avec `az acr credential renew --name <acr-name>` et mettez √† jour les secrets. |
| √âchec du job `build-and-deploy` avec `Repository not found` ou erreur sur `az containerapp update`. | Les noms dans `env:` (`ACR_NAME`, `CONTAINER_APP_NAME`) ne correspondent pas √† vos ressources. | V√©rifiez les noms exacts avec les commandes de l'**√âtape 5** et corrigez le fichier `ci-cd.yml`. |
| Le job `test` √©choue sur `pytest collected 0 items`. | Vos fichiers dans `tests/` ne sont pas reconnus comme tests. | Assurez-vous que les noms de fonctions commencent par `test_`. Exemple : `def test_health_check():` |
| Le job `test` √©choue sur `list indices must be integers or slices, not tuple`. | Erreur dans `app/main.py`. | Corrigez l'indexation : remplacez `model.predict_proba(...)[0, 1]` par `model.predict_proba(...)[0][1]`. |

### Checkpoint {#sec-module5-checkpoint}

:::: callout-note
# Validation Module 5

Avant de passer au module suivant, v√©rifiez que ces conditions sont remplies :

::: {style="margin-left: 20px; line-height: 1.8;"}
-   [ ] **Le d√©p√¥t GitHub `bank-churn-mlops` existe** et est li√© √† votre projet local.
-   [ ] **Les trois secrets GitHub** (`AZURE_CREDENTIALS`, `ACR_USERNAME`, `ACR_PASSWORD`) sont cr√©√©s avec les **bonnes valeurs et le bon format**.
-   [ ] **Le fichier `.github/workflows/ci-cd.yml`** est pr√©sent dans votre projet et contient les **noms exacts** de vos ressources Azure.
-   [ ] **Le pipeline CI/CD s'ex√©cute sans erreur** dans l'onglet GitHub Actions (les jobs `test` et `build-and-deploy` sont verts ‚úÖ).
-   [ ] **L'application se red√©ploie automatiquement** : apr√®s un `git push`, une nouvelle image est cr√©√©e et votre API conteneuris√©e est mise √† jour sur Azure.
:::
::::

## Module 6 : Monitoring et Maintenance {#sec-module6}

### Objectif {#sec-module6-objectif}

Mettre en place le monitoring de l'application et d√©tecter les probl√®mes en production.

### Configuration Application Insights {#sec-module6-appinsights}

``` bash
# Creation d'Application Insights
az monitor app-insights component create \
  --app bank-churn-insights \
  --location $LOCATION \
  --resource-group $RESOURCE_GROUP \
  --application-type web

# Recuperer la connection string
APPINSIGHTS_CONN=$(az monitor app-insights component show \
  --app bank-churn-insights \
  --resource-group $RESOURCE_GROUP \
  --query connectionString -o tsv)

echo "Connection String : $APPINSIGHTS_CONN"

# Ajouter la variable d'environnement a Container Apps
az containerapp update \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --set-env-vars "APPLICATIONINSIGHTS_CONNECTION_STRING=$APPINSIGHTS_CONN"
```

### Int√©gration du Monitoring dans le Code {#sec-module6-monitoring}

Ajoutez dans `requirements.txt` :

```         
opencensus-ext-azure==1.1.9
opencensus-ext-requests==0.12.1
```

Modifiez `app/main.py` pour ajouter le monitoring :

``` python
import os
from opencensus.ext.azure.log_exporter import AzureLogHandler
import logging

# Configuration du logging avec Application Insights
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

APPINSIGHTS_CONN = os.getenv("APPLICATIONINSIGHTS_CONNECTION_STRING")
if APPINSIGHTS_CONN:
    logger.addHandler(AzureLogHandler(connection_string=APPINSIGHTS_CONN))
    logger.info("Application Insights connecte")
```

### D√©tection de Data Drift {#sec-module6-drift}

Cr√©ez le fichier `drift_detection.py` :

``` python
import pandas as pd
from scipy.stats import ks_2samp
import json

def detect_drift(reference_file, production_file, threshold=0.05):
    """
    Detecte le drift entre donnees de reference et production
    """
    ref_data = pd.read_csv(reference_file)
    prod_data = pd.read_csv(production_file)
    
    drift_results = {}
    
    for column in ref_data.columns:
        if column in prod_data.columns and column != 'Exited':
            # Test de Kolmogorov-Smirnov
            statistic, p_value = ks_2samp(
                ref_data[column].dropna(),
                prod_data[column].dropna()
            )
            
            drift_detected = p_value < threshold
            
            drift_results[column] = {
                'p_value': float(p_value),
                'statistic': float(statistic),
                'drift_detected': drift_detected
            }
    
    # Rapport
    drifted_features = [f for f, r in drift_results.items() if r['drift_detected']]
    
    print("="*50)
    print("DATA DRIFT DETECTION REPORT")
    print("="*50)
    print(f"Threshold: {threshold}")
    print(f"Features analyzed: {len(drift_results)}")
    print(f"Features with drift: {len(drifted_features)}")
    print("\nDrifted features:")
    for feature in drifted_features:
        print(f"  - {feature}: p-value = {drift_results[feature]['p_value']:.4f}")
    print("="*50)
    
    return drift_results

if __name__ == "__main__":
    results = detect_drift(
        "data/bank_churn.csv",
        "data/production_data.csv"
    )
    
    # Sauvegarder les resultats
    with open("drift_report.json", "w") as f:
        json.dump(results, f, indent=2)
    
    print("\nRapport sauvegarde dans drift_report.json")
```

### Checkpoint {#sec-module6-checkpoint}

:::: callout-note
## Validation Module 6

Avant de passer au module suivant, v√©rifiez que :

::: {style="margin-left: 20px; line-height: 1.8;"}
-   [ ] Application Insights est configur√©
-   [ ] Les logs apparaissent dans Azure Portal
-   [ ] Vous pouvez visualiser les m√©triques
-   [ ] Le script de d√©tection de drift fonctionne
:::
::::

## Module 7 : Optimisations et Bonnes Pratiques {#sec-module7}

### Objectif {#sec-module7-objectif}

Am√©liorer les performances, la s√©curit√© et la maintenabilit√© de l'application.

### Ajout d'un Cache pour les Pr√©dictions {#sec-module7-cache}

Modifiez `app/main.py` :

``` python
from functools import lru_cache
import hashlib
import json

def hash_features(features_dict: dict) -> str:
    """Cree un hash unique pour les features"""
    return hashlib.md5(
        json.dumps(features_dict, sort_keys=True).encode()
    ).hexdigest()

# Cache pour les predictions (1000 dernieres)
@lru_cache(maxsize=1000)
def predict_cached(features_hash: str, features_json: str):
    features_dict = json.loads(features_json)
    input_data = np.array([[
        features_dict["CreditScore"],
        features_dict["Age"],
        # ... autres features
    ]])
    
    proba = model.predict_proba(input_data)[0, 1]
    prediction = int(proba > 0.5)
    
    if proba < 0.3:
        risk = "Low"
    elif proba < 0.7:
        risk = "Medium"
    else:
        risk = "High"
    
    return {
        "churn_probability": round(float(proba), 4),
        "prediction": prediction,
        "risk_level": risk
    }

@app.post("/predict", response_model=PredictionResponse)
def predict(features: CustomerFeatures):
    features_dict = features.dict()
    features_hash = hash_features(features_dict)
    features_json = json.dumps(features_dict)
    
    # Utilise le cache si disponible
    result = predict_cached(features_hash, features_json)
    
    logger.info(f"Prediction - Hash: {features_hash[:8]}")
    return result
```

### Checklist de Production {#sec-module7-checklist}

::: callout-tip
## Checklist Avant Production

-   [ ] Tests unitaires avec coverage \> 80%
-   [ ] Tests d'integration
-   [ ] Load testing effectue
-   [ ] Monitoring configure
-   [ ] Alertes definies
-   [ ] Logs centralises
-   [ ] Documentation API complete
-   [ ] HTTPS active
-   [ ] Health checks fonctionnels
-   [ ] Auto-scaling teste
-   [ ] Variables d'environnement securisees
-   [ ] Budget Azure surveille
:::

### Checkpoint Final {#sec-module7-checkpoint}

:::: callout-note
## Validation Module 7

::: {style="margin-left: 20px; line-height: 1.8;"}
-   [ ] Cache de predictions implemente
-   [ ] Documentation complete
-   [ ] Tous les tests passent
-   [ ] Checklist de production verifiee
:::
::::

## Nettoyage des Ressources Azure {#sec-nettoyage}

### IMPORTANT - Suppression pour √âviter les Co√ªts {#sec-nettoyage-important}

::: callout-warning
## ATTENTION - √Ä FAIRE √Ä LA FIN DU WORKSHOP

Pour √©viter de consommer votre budget de 100\$, supprimez toutes les ressources :

``` bash
# Suppression du groupe de ressources (supprime tout)
az group delete --name $RESOURCE_GROUP --yes --no-wait

# Verification
az group list --output table
```

Cette commande supprime : - Azure Container Registry - Azure Container Apps - Application Insights - Tous les logs et donn√©es

**Temps de suppression** : 5-10 minutes
:::

### Script de Nettoyage Automatique {#sec-nettoyage-script}

Cr√©ez `cleanup.sh` :

``` bash
#!/bin/bash

RESOURCE_GROUP="rg-mlops"

echo "=========================================="
echo "Nettoyage des ressources Azure"
echo "=========================================="

read -p "Voulez-vous vraiment supprimer toutes les ressources ? (yes/no): " confirm

if [ "$confirm" != "yes" ]; then
    echo "Operation annulee."
    exit 0
fi

echo "\nRessources a supprimer:"
az resource list --resource-group $RESOURCE_GROUP --output table

echo "\nSuppression en cours..."
az group delete --name $RESOURCE_GROUP --yes --no-wait

echo "\nSuppression lancee (prend 5-10 minutes)"
echo "Verifiez sur : https://portal.azure.com"
```

``` bash
# Rendre executable et lancer
chmod +x cleanup.sh
./cleanup.sh
```

## R√©capitulatif du Workshop {#sec-recapitulatif}

### Ce que Vous Avez Accompli {#sec-recap-accompli}

F√©licitations ! Vous avez d√©ploy√© un syst√®me MLOps complet :

**Architecture Finale :**

`ML Training` ‚Üí `FastAPI` ‚Üí `Docker` ‚Üí `Azure Container Registry` ‚Üí `Azure Container Apps`

‚Üë `GitHub Actions CI/CD`

‚Üë `Application Insights Monitoring`

### Comp√©tences Acquises {#sec-recap-competences}

1.  **Machine Learning**
    -   Entra√Ænement d'un mod√®le Random Forest
    -   √âvaluation avec m√©triques appropri√©es
    -   Tracking avec MLflow
2.  **D√©veloppement d'API**
    -   Cr√©ation d'API REST avec FastAPI
    -   Validation des donn√©es avec Pydantic
    -   Documentation automatique
3.  **Conteneurisation**
    -   Dockerfiles optimis√©s
    -   Bonnes pratiques de s√©curit√©
    -   Gestion des images
4.  **Cloud Azure**
    -   Azure Container Registry
    -   Azure Container Apps
    -   Application Insights
5.  **DevOps/MLOps**
    -   Pipelines CI/CD avec GitHub Actions
    -   Tests automatis√©s
    -   D√©ploiement continu
6.  **Monitoring et Maintenance**
    -   Logs centralis√©s
    -   M√©triques de performance
    -   D√©tection de data drift

### Points Cl√©s √† Retenir {#sec-recap-points-cles}

::: callout-important
## Lecons Importantes

1.  **MLOps = DevOps + ML** : Automatisation du cycle de vie complet
2.  **Conteneurisation** : Portabilit√© et reproductibilit√©
3.  **Tests** : Essentiels pour la fiabilit√©
4.  **Monitoring** : Indispensable en production
5.  **Documentation** : Facilite la collaboration
6.  **S√©curit√©** : √Ä consid√©rer d√®s le d√©but
7.  **Co√ªts** : Toujours surveiller l'utilisation cloud
:::

## FAQ - Foire Aux Questions {#sec-faq}

### Questions Techniques {#sec-faq-techniques}

**Q1 : Mon API est lente, comment l'optimiser ?**

*R :* Plusieurs options : - Activer le cache des pr√©dictions - Utiliser des pr√©dictions batch - Optimiser le mod√®le (quantization, pruning) - Augmenter les ressources CPU/RAM

**Q2 : Comment g√©rer plusieurs versions de mod√®les ?**

*R :* Utilisez MLflow Model Registry et cr√©ez des endpoints diff√©rents (v1, v2).

**Q3 : Comment impl√©menter un rollback ?**

*R :* Conservez les anciennes images Docker avec tags et utilisez :

``` bash
az containerapp update \
  --name $APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --image $ACR_NAME.azurecr.io/bank-churn-api:v1  # Version precedente
```

**Q4 : Mon budget Azure est presque √©puis√©, que faire ?**

*R :* - Mettre min-replicas √† 0 - Utiliser des SKU Basic - Supprimer les ressources inutilis√©es - Activer les budgets alerts

### Questions de Compr√©hension {#sec-faq-comprehension}

**Q5 : Quelle est la diff√©rence entre Docker et Kubernetes ?**

*R :* Docker conteneurise les applications, Kubernetes les orchestre (scaling, load balancing, self-healing).

**Q6 : Pourquoi utiliser FastAPI plut√¥t que Flask ?**

*R :* FastAPI est plus rapide, avec validation automatique, documentation auto-g√©n√©r√©e, et support async natif.

**Q7 : Qu'est-ce que le data drift ?**

*R :* Changement dans la distribution des donn√©es d'entr√©e par rapport aux donn√©es d'entra√Ænement, pouvant d√©grader les performances du mod√®le.

## Conclusion {#sec-conclusion}

### F√©licitations ! {#sec-conclusion-felicitations}

Vous avez termin√© ce workshop intensif de MLOps avec Azure. Vous avez construit un syst√®me complet de d√©ploiement de mod√®le de Machine Learning en production, avec toutes les bonnes pratiques de l'industrie.

### Prochaines √âtapes {#sec-conclusion-next-steps}

1.  **Pratiquez** : Refaites le workshop avec un dataset diff√©rent
2.  **Partagez** : Mettez votre projet sur GitHub
3.  **Am√©liorez** : Impl√©mentez les fonctionnalit√©s avanc√©es
4.  **Certifiez-vous** : Pr√©parez les certifications Azure

------------------------------------------------------------------------

**Bon Apprentissage et Bon D√©ploiement !**

*Ce guide vous a accompagn√© dans votre premier projet MLOps.\
Continuez √† explorer, √† apprendre et √† innover.*

------------------------------------------------------------------------

*Version 1.0 - Novembre 2025*\
*Workshop MLOps avec Azure* \n\## Test de d√©ploiement - jeu. 20 nov. 2025 03:26:42