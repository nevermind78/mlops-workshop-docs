---
title: "Workshop MLOps avec Azure - Guide Pratique"
format: 
  html:
    toc: true
    toc-depth: 3
    toc-location: left
    number-sections: true
    code-fold: true
    code-overflow: wrap
editor: visual
---

## Introduction {#sec-introduction}

### Bienvenue !

Ce workshop vous guidera √† travers le d√©ploiement complet d'un mod√®le de Machine Learning en production sur Microsoft Azure. Vous allez construire une API de pr√©diction de d√©faillance client (churn) et la d√©ployer sur le cloud avec toutes les bonnes pratiques MLOps.

### Objectifs d'Apprentissage {#sec-objectifs}

√Ä la fin de ce workshop, vous serez capable de :

-   Entra√Æner et sauvegarder un mod√®le ML avec MLflow
-   Cr√©er une API REST avec FastAPI
-   Conteneuriser une application avec Docker
-   D√©ployer sur Azure Container Apps
-   Mettre en place un pipeline CI/CD avec GitHub Actions
-   Monitorer votre application en production
-   D√©tecter le data drift

### Le Projet : Bank Churn Prediction {#sec-projet}

**Contexte :** Une banque souhaite pr√©dire quels clients risquent de partir pour proposer des actions de r√©tention.

**Dataset :** 10 features (√¢ge, score cr√©dit, solde, etc.) + 1 target (Exited : 0/1)

**Mod√®le :** Random Forest Classifier

**Livrable :** API REST d√©ploy√©e sur Azure, accessible publiquement

### Architecture Finale {#sec-architecture}

**Flux de d√©ploiement :**

`Code GitHub` ‚Üí `GitHub Actions` ‚Üí `Docker Build` ‚Üí `Azure Container Registry` ‚Üí `Azure Container Apps` ‚Üí `Internet`

## Pr√©paration de l'Environnement {#sec-preparation}

### Logiciels Requis {#sec-logiciels}

**Obligatoire :**

-   Python 3.9+ : https://www.python.org/downloads/
-   Visual Studio Code : https://code.visualstudio.com/
-   Git : https://git-scm.com/downloads
-   Docker Desktop : https://www.docker.com/products/docker-desktop
-   Azure CLI : https://docs.microsoft.com/cli/azure/install-azure-cli

**Comptes √† cr√©er :**

-   Compte GitHub : https://github.com/signup
-   Azure for Students (100\$) : https://azure.microsoft.com/students

### V√©rification de l'Installation {#sec-verification}

Ouvrez un terminal et testez :

``` bash
# Python
python --version
# Doit afficher Python 3.9.x ou superieur

# Git
git --version

# Docker
docker --version
docker ps

# Azure CLI
az --version
```

### Configuration Initiale {#sec-configuration}

#### Configuration Git {#sec-config-git}

``` bash
git config --global user.name "Votre Nom"
git config --global user.email "votre.email@example.com"
```

#### Connexion √† Azure {#sec-config-azure}

``` bash
# Se connecter a Azure
az login

# Verifier l'abonnement
az account show

# Si vous avez plusieurs abonnements, selectionner celui de Students
az account set --subscription "Azure for Students"
```

## Module 1 : Entra√Ænement du Mod√®le {#sec-module1}

### Objectif {#sec-module1-objectif}

Entra√Æner un mod√®le Random Forest pour pr√©dire le churn et le sauvegarder avec MLflow.

### Pr√©paration du Projet {#sec-module1-preparation}

``` bash
# Creer le dossier du projet
mkdir bank-churn-mlops
cd bank-churn-mlops

# Creer un environnement virtuel
python -m venv venv

# Activer l'environnement
# Windows :
venv\Scripts\activate
# Mac/Linux :
source venv/bin/activate

# Creer la structure
mkdir -p data model app tests
touch requirements.txt
```

### Fichier requirements.txt {#sec-module1-requirements}

Cr√©ez le fichier `requirements.txt` avec le contenu suivant :

```         
# API Framework
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0

# Machine Learning
scikit-learn==1.3.2
pandas==2.1.3
numpy==1.26.2
joblib==1.3.2

# MLflow
mlflow==2.8.1

# Testing
pytest==7.4.3
pytest-cov==4.1.0
httpx==0.25.2

# Utilities
python-multipart==0.0.6
requests==2.31.0
```

Puis installez les d√©pendances :

``` bash
pip install -r requirements.txt
```

### T√©l√©chargement du Dataset {#sec-module1-dataset}

Cr√©ez un dataset synth√©tique :

``` python
# generate_data.py
import pandas as pd
import numpy as np

np.random.seed(42)
n_samples = 10000

data = {
    'CreditScore': np.random.randint(300, 850, n_samples),
    'Age': np.random.randint(18, 80, n_samples),
    'Tenure': np.random.randint(0, 11, n_samples),
    'Balance': np.random.uniform(0, 200000, n_samples),
    'NumOfProducts': np.random.randint(1, 5, n_samples),
    'HasCrCard': np.random.choice([0, 1], n_samples),
    'IsActiveMember': np.random.choice([0, 1], n_samples),
    'EstimatedSalary': np.random.uniform(20000, 150000, n_samples),
    'Geography_Germany': np.random.choice([0, 1], n_samples),
    'Geography_Spain': np.random.choice([0, 1], n_samples),
}

# Target : plus de chance de partir si inactif, peu de produits, etc.
churn_prob = (
    (1 - data['IsActiveMember']) * 0.3 +
    (data['NumOfProducts'] == 1) * 0.2 +
    (data['Age'] > 60) * 0.15 +
    (data['Balance'] == 0) * 0.25
)
data['Exited'] = (np.random.random(n_samples) < churn_prob).astype(int)

df = pd.DataFrame(data)
df.to_csv('data/bank_churn.csv', index=False)
print(f"Dataset cree : {len(df)} lignes")
print(f"Taux de churn : {df['Exited'].mean():.2%}")
```

### Script d'Entra√Ænement {#sec-module1-training}

Cr√©ez le fichier `train_model.py` :

``` python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, 
    precision_score, 
    recall_score,
    f1_score, 
    roc_auc_score,
    confusion_matrix
)
import joblib
import mlflow
import mlflow.sklearn
import matplotlib.pyplot as plt
import seaborn as sns

# Configuration MLflow
mlflow.set_tracking_uri("./mlruns")
mlflow.set_experiment("bank-churn-prediction")

print("Chargement des donnees...")
df = pd.read_csv("data/bank_churn.csv")

print(f"Dataset : {len(df)} lignes, {len(df.columns)} colonnes")
print(f"Taux de churn : {df['Exited'].mean():.2%}")

# Separation features/target
X = df.drop('Exited', axis=1)
y = df['Exited']

# Split train/test (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nTrain : {len(X_train)} lignes")
print(f"Test : {len(X_test)} lignes")

# Entrainement avec MLflow tracking
print("\nEntrainement du modele...")
with mlflow.start_run(run_name="random-forest-v1"):
    
    # Parametres du modele
    params = {
        'n_estimators': 100,
        'max_depth': 10,
        'min_samples_split': 5,
        'random_state': 42
    }
    
    # Entrainement
    model = RandomForestClassifier(**params)
    model.fit(X_train, y_train)
    
    # Predictions
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]
    
    # Calcul des metriques
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_proba)
    
    # Log des parametres et metriques dans MLflow
    mlflow.log_params(params)
    mlflow.log_metrics({
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1_score": f1,
        "roc_auc": auc
    })
    
    # Creation et sauvegarde de la matrice de confusion
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title('Matrice de Confusion')
    plt.ylabel('Vraie Classe')
    plt.xlabel('Classe Predite')
    plt.savefig('confusion_matrix.png')
    mlflow.log_artifact('confusion_matrix.png')
    plt.close()
    
    # Feature importance
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    plt.figure(figsize=(10, 6))
    plt.barh(feature_importance['feature'], feature_importance['importance'])
    plt.xlabel('Importance')
    plt.title('Feature Importance')
    plt.tight_layout()
    plt.savefig('feature_importance.png')
    mlflow.log_artifact('feature_importance.png')
    plt.close()
    
    # Enregistrement du modele dans MLflow
    mlflow.sklearn.log_model(
        model,
        "model",
        registered_model_name="bank-churn-classifier"
    )
    
    # Sauvegarde locale du modele
    joblib.dump(model, "model/churn_model.pkl")
    
    # Tags
    mlflow.set_tags({
        "environment": "development",
        "model_type": "RandomForest",
        "task": "binary_classification"
    })
    
    # Affichage des resultats
    print("\n" + "="*50)
    print("RESULTATS DE L'ENTRAINEMENT")
    print("="*50)
    print(f"Accuracy  : {accuracy:.4f}")
    print(f"Precision : {precision:.4f}")
    print(f"Recall    : {recall:.4f}")
    print(f"F1 Score  : {f1:.4f}")
    print(f"ROC AUC   : {auc:.4f}")
    print("="*50)
    
    print(f"\nModele sauvegarde dans : model/churn_model.pkl")
    print(f"MLflow UI : mlflow ui --port 5000")
```

### Ex√©cution {#sec-module1-execution}

``` bash
# Lancer l'entrainement
python train_model.py

# Voir les resultats dans MLflow UI
mlflow ui --port 5000
# Ouvrir http://localhost:5000 dans votre navigateur
```

### Checkpoint {#sec-module1-checkpoint}

:::: callout-note
## Validation Module 1

Avant de passer au module suivant, v√©rifiez que :

::: {style="margin-left: 20px;"}
-   [ ] Le mod√®le est entra√Æn√© avec une accuracy \> 0.75
-   [ ] Le fichier `model/churn_model.pkl` existe
-   [ ] MLflow UI affiche votre exp√©rience
-   [ ] Vous comprenez les m√©triques obtenues
:::
::::

## Module 2 : Cr√©ation de l'API avec FastAPI {#sec-module2}

### Objectif {#sec-module2-objectif}

Cr√©er une API REST qui expose le mod√®le via des endpoints HTTP.

### Structure du Code API {#sec-module2-structure}

```         
bank-churn-mlops/
|-- app/
|   |-- __init__.py
|   |-- main.py
|   |-- models.py
|   +-- utils.py
|-- model/
|   +-- churn_model.pkl
|-- tests/
|   +-- test_api.py
|-- requirements.txt
+-- README.md
```

### Fichier app/models.py {#sec-module2-models}

D√©finition des sch√©mas de donn√©es avec Pydantic :

``` python
from pydantic import BaseModel, Field
from typing import List

class CustomerFeatures(BaseModel):
    """Schema pour les features d'un client"""
    CreditScore: int = Field(..., ge=300, le=850, description="Score de credit")
    Age: int = Field(..., ge=18, le=100, description="Age du client")
    Tenure: int = Field(..., ge=0, le=10, description="Anciennete en annees")
    Balance: float = Field(..., ge=0, description="Solde du compte")
    NumOfProducts: int = Field(..., ge=1, le=4, description="Nombre de produits")
    HasCrCard: int = Field(..., ge=0, le=1, description="Possession carte credit")
    IsActiveMember: int = Field(..., ge=0, le=1, description="Membre actif")
    EstimatedSalary: float = Field(..., ge=0, description="Salaire estime")
    Geography_Germany: int = Field(..., ge=0, le=1, description="Client allemand")
    Geography_Spain: int = Field(..., ge=0, le=1, description="Client espagnol")
    
    class Config:
        schema_extra = {
            "example": {
                "CreditScore": 650,
                "Age": 35,
                "Tenure": 5,
                "Balance": 50000,
                "NumOfProducts": 2,
                "HasCrCard": 1,
                "IsActiveMember": 1,
                "EstimatedSalary": 75000,
                "Geography_Germany": 0,
                "Geography_Spain": 1
            }
        }

class PredictionResponse(BaseModel):
    """Schema pour la reponse de prediction"""
    churn_probability: float = Field(..., description="Probabilite de churn (0-1)")
    prediction: int = Field(..., description="Prediction binaire (0=reste, 1=part)")
    risk_level: str = Field(..., description="Niveau de risque (Low/Medium/High)")

class HealthResponse(BaseModel):
    """Schema pour le health check"""
    status: str
    model_loaded: bool
```

### Fichier app/main.py {#sec-module2-main}

L'API principale :

``` python
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import joblib
import numpy as np
from typing import List
import logging
import os

from app.models import CustomerFeatures, PredictionResponse, HealthResponse

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialisation FastAPI
app = FastAPI(
    title="Bank Churn Prediction API",
    description="API de prediction de defaillance client",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS pour permettre les requetes depuis un navigateur
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Chargement du modele au demarrage
MODEL_PATH = os.getenv("MODEL_PATH", "model/churn_model.pkl")
model = None

@app.on_event("startup")
async def load_model():
    """Charge le modele au demarrage de l'API"""
    global model
    try:
        model = joblib.load(MODEL_PATH)
        logger.info(f"Modele charge avec succes depuis {MODEL_PATH}")
    except Exception as e:
        logger.error(f"Erreur lors du chargement du modele : {e}")
        model = None

@app.get("/", tags=["General"])
def root():
    """Endpoint racine"""
    return {
        "message": "Bank Churn Prediction API",
        "version": "1.0.0",
        "status": "running",
        "docs": "/docs"
    }

@app.get("/health", response_model=HealthResponse, tags=["General"])
def health_check():
    """Verification de l'etat de l'API"""
    if model is None:
        raise HTTPException(
            status_code=503, 
            detail="Modele non charge"
        )
    return {
        "status": "healthy",
        "model_loaded": True
    }

@app.post("/predict", response_model=PredictionResponse, tags=["Prediction"])
def predict(features: CustomerFeatures):
    """
    Predit si un client va partir (churn)
    
    Retourne :
    - churn_probability : probabilite de churn (0 a 1)
    - prediction : 0 (reste) ou 1 (part)
    - risk_level : Low, Medium ou High
    """
    if model is None:
        raise HTTPException(
            status_code=503, 
            detail="Modele non disponible"
        )
    
    try:
        # Preparation des features
        input_data = np.array([[
            features.CreditScore,
            features.Age,
            features.Tenure,
            features.Balance,
            features.NumOfProducts,
            features.HasCrCard,
            features.IsActiveMember,
            features.EstimatedSalary,
            features.Geography_Germany,
            features.Geography_Spain
        ]])
        
        # Prediction
        proba = model.predict_proba(input_data)[0, 1]
        prediction = int(proba > 0.5)
        
        # Classification du risque
        if proba < 0.3:
            risk = "Low"
        elif proba < 0.7:
            risk = "Medium"
        else:
            risk = "High"
        
        logger.info(
            f"Prediction effectuee : proba={proba:.4f}, "
            f"prediction={prediction}, risk={risk}"
        )
        
        return {
            "churn_probability": round(float(proba), 4),
            "prediction": prediction,
            "risk_level": risk
        }
    
    except Exception as e:
        logger.error(f"Erreur lors de la prediction : {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"Erreur de prediction : {str(e)}"
        )

@app.post("/predict/batch", tags=["Prediction"])
def predict_batch(features_list: List[CustomerFeatures]):
    """
    Predictions en batch pour plusieurs clients
    """
    if model is None:
        raise HTTPException(status_code=503, detail="Modele non disponible")
    
    try:
        predictions = []
        
        for features in features_list:
            input_data = np.array([[
                features.CreditScore, features.Age, features.Tenure,
                features.Balance, features.NumOfProducts, features.HasCrCard,
                features.IsActiveMember, features.EstimatedSalary,
                features.Geography_Germany, features.Geography_Spain
            ]])
            
            proba = model.predict_proba(input_data)[0, 1]
            prediction = int(proba > 0.5)
            
            predictions.append({
                "churn_probability": round(float(proba), 4),
                "prediction": prediction
            })
        
        logger.info(f"Batch prediction : {len(predictions)} clients traites")
        
        return {"predictions": predictions, "count": len(predictions)}
    
    except Exception as e:
        logger.error(f"Erreur batch prediction : {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### Test Local de l'API {#sec-module2-test}

``` bash
# Demarrer l'API
uvicorn app.main:app --reload --port 8000

# Dans un autre terminal, tester :

# 1. Health check
curl http://localhost:8000/health

# 2. Prediction simple
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "CreditScore": 650,
    "Age": 35,
    "Tenure": 5,
    "Balance": 50000,
    "NumOfProducts": 2,
    "HasCrCard": 1,
    "IsActiveMember": 1,
    "EstimatedSalary": 75000,
    "Geography_Germany": 0,
    "Geography_Spain": 1
  }'
```

### Jupyter Lab

``` python
#dans jupyter lab
import requests
import json

# URL de ton API FastAPI
url = "http://localhost:8000/predict"

# Donn√©es √† envoyer
data = {
    "CreditScore": 650,
    "Age": 35,
    "Tenure": 5,
    "Balance": 50000,
    "NumOfProducts": 2,
    "HasCrCard": 1,
    "IsActiveMember": 1,
    "EstimatedSalary": 75000,
    "Geography_Germany": 0,
    "Geography_Spain": 1
}

# Envoyer la requ√™te POST
response = requests.post(url, json=data)

# Afficher la r√©ponse
print(f"Status Code: {response.status_code}")
print(f"Response: {response.json()}")
```

### Documentation Interactive {#sec-module2-docs}

Ouvrez votre navigateur et allez sur :

-   **Swagger UI** : http://localhost:8000/docs
-   **ReDoc** : http://localhost:8000/redoc

### Checkpoint {#sec-module2-checkpoint}

:::: callout-note
## Validation Module 2

Avant de passer au module suivant, v√©rifiez que :

::: {style="margin-left: 20px;"}
-   [ ] Le mod√®le est entra√Æn√© avec une accuracy \> 0.75
-   [ ] Le fichier `model/churn_model.pkl` existe\
-   [ ] MLflow UI affiche votre exp√©rience
-   [ ] Vous comprenez les m√©triques obtenues
:::
::::

## Module 3 : Conteneurisation avec Docker {#sec-module3}

### Objectif {#sec-module3-objectif}

Empaqueter l'API dans un conteneur Docker pour la rendre portable et faciliter le d√©ploiement sur Azure.

### Cr√©ation du Dockerfile {#sec-module3-dockerfile}

Cr√©ez le fichier `Dockerfile` √† la racine du projet :

``` dockerfile
# Utilise une image Python officielle
FROM python:3.9-slim

# Definir le repertoire de travail
WORKDIR /app

# Copier les fichiers de dependances
COPY requirements.txt .

# Installer les dependances
RUN pip install --no-cache-dir -r requirements.txt

# Copier le code de l'application
COPY app/ ./app/
COPY model/ ./model/

# Exposer le port
EXPOSE 8000

# Commande pour demarrer l'application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Cr√©ation du .dockerignore {#sec-module3-dockerignore}

Cr√©ez le fichier `.dockerignore` :

```         
__pycache__
*.pyc
*.pyo
*.pyd
.Python
env/
venv/
.venv
*.egg-info/
.pytest_cache/
.git
.gitignore
README.md
.env
mlruns/
*.log
.DS_Store
.vscode/
tests/
```

### Build de l'Image Docker {#sec-module3-build}

``` bash
# Build de l'image (cela peut prendre quelques minutes)
docker build -t bank-churn-api:v1 .

# Verifier que l'image est creee
docker images bank-churn-api:v1

# Voir la taille de l'image
docker images --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}" | grep bank-churn
```

### Test du Conteneur en Local {#sec-module3-test}

``` bash
# Lancer le conteneur
docker run -d -p 8000:8000 --name churn-api bank-churn-api:v1

# Verifier que le conteneur tourne
docker ps

# Voir les logs
docker logs churn-api

# Tester l'API
curl http://localhost:8000/health

# Prediction de test
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "CreditScore": 700,
    "Age": 40,
    "Tenure": 7,
    "Balance": 80000,
    "NumOfProducts": 3,
    "HasCrCard": 1,
    "IsActiveMember": 0,
    "EstimatedSalary": 90000,
    "Geography_Germany": 1,
    "Geography_Spain": 0
  }'

# Arreter et supprimer le conteneur
docker stop churn-api
docker rm churn-api
```

### Commandes Docker Utiles {#sec-module3-commandes}

``` bash
# Voir tous les conteneurs (meme arretes)
docker ps -a

# Entrer dans un conteneur en cours d'execution
docker exec -it churn-api /bin/bash

# Voir l'utilisation des ressources
docker stats churn-api

# Nettoyer les images inutilisees
docker image prune

# Supprimer toutes les images
docker rmi $(docker images -q)
```

### Questions de Compr√©hension {#sec-module3-questions}

1.  Pourquoi utiliser un .dockerignore ?
2.  Quelle est la diff√©rence entre CMD et RUN dans un Dockerfile ?
3.  Pourquoi exposer le port 8000 ?
4.  Comment v√©rifier que votre conteneur fonctionne correctement ?

### Checkpoint {#sec-module3-checkpoint}

:::: callout-note
## Validation Module 3

Avant de passer au module suivant, v√©rifiez que :

::: {style="margin-left: 20px;"}
-   [ ] L'image Docker est build√©e avec succ√®s
-   [ ] Le conteneur d√©marre sans erreur
-   [ ] L'API r√©pond correctement depuis le conteneur
-   [ ] La taille de l'image est raisonnable (\< 1GB)
:::
::::


## Module 4 : D√©ploiement sur Azure {#sec-module4}

### Objectif {#sec-module4-objectif}
D√©ployer l'API sur Azure Container Apps et la rendre accessible publiquement.

### Pr√©requis {#sec-module4-prerequis}
1. **Docker Desktop** en cours d'ex√©cution (mode WSL2 recommand√©)
2. **Azure CLI** install√© et connect√© (`az login`)
3. **Image locale** `bank-churn-api:v1` d√©j√† construite

### √âtape 1 : Cr√©ation du Groupe de Ressources {#sec-module4-etape1}
```bash
# Variables (MODIFIEZ avec vos valeurs)
RESOURCE_GROUP="rg-mlops"
LOCATION="westeurope"
ACR_NAME="acrmlops$(whoami)$(date +%s)"  # Doit √™tre unique globalement
CONTAINER_APP_NAME="app-churn-api"
CONTAINERAPPS_ENV="env-mlops-workshop"

# V√©rifier et d√©finir le contexte Azure (IMPORTANT)
echo "V√©rification du contexte Azure..."
az account show --query "{name:name, cloudName:cloudName}" || az login

# Cr√©ation du groupe de ressources
echo "Cr√©ation du groupe de ressources..."
az group create \
  --name $RESOURCE_GROUP \
  --location $LOCATION

echo "‚úÖ Groupe de ressources cr√©√© : $RESOURCE_GROUP"
```

### √âtape 2 : Azure Container Registry (ACR) {#sec-module4-etape2}
```bash
# Cr√©ation du registry
echo "Cr√©ation du Container Registry..."
az acr create \
  --resource-group $RESOURCE_GROUP \
  --name $ACR_NAME \
  --sku Basic \
  --admin-enabled true \
  --location $LOCATION

echo "‚úÖ Container Registry cr√©√© : $ACR_NAME"

# Se connecter au registry
echo "Connexion au registry..."
az acr login --name $ACR_NAME

# V√©rification de la cr√©ation
echo "V√©rification de la connexion..."
az acr check-health --name $ACR_NAME --ignore-helm --ignore-notary --yes
```

### √âtape 3 : Push de l'Image vers ACR {#sec-module4-etape3}
```bash
# R√©cup√©rer l'URL du registry (CORRECTION DU RETOUR CHARIOT)
echo "R√©cup√©ration de l'URL du registry..."
ACR_LOGIN_SERVER=$(az acr show --name $ACR_NAME --query loginServer --output tsv | tr -d '\r')
echo "Login Server nettoy√© : '$ACR_LOGIN_SERVER'"

# Tagger l'image pour ACR
echo "Tagging des images..."
docker tag bank-churn-api:v1 $ACR_LOGIN_SERVER/bank-churn-api:v1
docker tag bank-churn-api:v1 $ACR_LOGIN_SERVER/bank-churn-api:latest

# Pousser les images vers ACR
echo "Pushing des images vers ACR..."
docker push $ACR_LOGIN_SERVER/bank-churn-api:v1
docker push $ACR_LOGIN_SERVER/bank-churn-api:latest

# V√©rification
echo "V√©rification des images dans ACR..."
az acr repository list --name $ACR_NAME --output table
az acr repository show-tags --name $ACR_NAME --repository bank-churn-api --output table
```

### √âtape 4 : Cr√©ation de l'Environnement Container Apps {#sec-module4-etape4}
```bash
# Cr√©ation de l'environnement
echo "Cr√©ation de l'environnement Container Apps..."
az containerapp env create \
  --name $CONTAINERAPPS_ENV \
  --resource-group $RESOURCE_GROUP \
  --location $LOCATION

echo "‚úÖ Environnement Container Apps cr√©√© : $CONTAINERAPPS_ENV"
```

### √âtape 5 : D√©ploiement de l'Application {#sec-module4-etape5}

::: callout-important
## ‚ö†Ô∏è Probl√®me connu avec les secrets ACR

La commande `az containerapp create` g√©n√®re automatiquement un nom de secret invalide.
Nous utilisons une approche YAML pour contourner ce probl√®me.
:::

```bash
# R√©cup√©rer les credentials ACR
echo "R√©cup√©ration des credentials ACR..."
ACR_USERNAME=$(az acr credential show --name $ACR_NAME --query username -o tsv)
ACR_PASSWORD=$(az acr credential show --name $ACR_NAME --query passwords[0].value -o tsv)

# Cr√©er le fichier de configuration YAML
cat > containerapp.yaml << 'EOFYAML'
properties:
  configuration:
    activeRevisionsMode: Single
    ingress:
      external: true
      targetPort: 8000
      allowInsecure: false
      traffic:
      - weight: 100
        latestRevision: true
    secrets:
    - name: acrpassword
      value: ACR_PASSWORD_PLACEHOLDER
    registries:
    - server: ACR_LOGIN_SERVER_PLACEHOLDER
      username: ACR_USERNAME_PLACEHOLDER
      passwordSecretRef: acrpassword
  template:
    containers:
    - image: ACR_LOGIN_SERVER_PLACEHOLDER/bank-churn-api:v1
      name: app-churn-api
      resources:
        cpu: 0.5
        memory: 1Gi
      env:
      - name: PYTHONUNBUFFERED
        value: "1"
    scale:
      minReplicas: 1
      maxReplicas: 3
EOFYAML

# Remplacer les placeholders (compatible WSL)
sed "s|ACR_PASSWORD_PLACEHOLDER|$ACR_PASSWORD|g" containerapp.yaml > containerapp_tmp.yaml && mv containerapp_tmp.yaml containerapp.yaml
sed "s|ACR_USERNAME_PLACEHOLDER|$ACR_USERNAME|g" containerapp.yaml > containerapp_tmp.yaml && mv containerapp_tmp.yaml containerapp.yaml
sed "s|ACR_LOGIN_SERVER_PLACEHOLDER|$ACR_LOGIN_SERVER|g" containerapp.yaml > containerapp_tmp.yaml && mv containerapp_tmp.yaml containerapp.yaml

# D√©ployer l'application
echo "D√©ploiement de l'application Container App..."
az containerapp create \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --environment $CONTAINERAPPS_ENV \
  --yaml containerapp.yaml

echo "‚úÖ Application d√©ploy√©e !"

# Nettoyage du fichier temporaire
rm -f containerapp.yaml
```

### √âtape 6 : R√©cup√©rer l'URL Publique {#sec-module4-etape6}
```bash
# Attendre le d√©marrage complet
echo "‚è≥ Attente du d√©marrage de l'application (30 secondes)..."
sleep 30

# V√©rifier l'√©tat
az containerapp show \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --query "{Name:name, State:properties.provisioningState, RunningStatus:properties.runningStatus}" \
  --output table

# R√©cup√©rer l'URL de l'application
echo "R√©cup√©ration de l'URL publique..."
APP_URL=$(az containerapp show \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --query properties.configuration.ingress.fqdn -o tsv)

echo ""
echo "=========================================="
echo "‚úÖ API d√©ploy√©e avec succ√®s !"
echo "=========================================="
echo "URL : https://$APP_URL"
echo "Health check : https://$APP_URL/health"
echo "Documentation : https://$APP_URL/docs"
echo "=========================================="
echo ""

# Test initial
echo "Test du endpoint /health..."
curl -s https://$APP_URL/health
echo ""
```

### √âtape 7 : Test de l'API en Production {#sec-module4-etape7}

```bash
RESOURCE_GROUP="rg-mlops1"
CONTAINER_APP_NAME="app-churn-api"

APP_URL=$(az containerapp show \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --query properties.configuration.ingress.fqdn -o tsv | tr -d '\r\n' | xargs)

# 2. V√©rifier l'URL proprement
echo "URL nettoy√©e: '$APP_URL'"
echo "Longueur: ${#APP_URL}"

# 3. Test avec l'URL compl√®te
FULL_URL="https://${APP_URL}/predict"
echo "URL compl√®te: $FULL_URL"

# 4. Test de pr√©diction
curl -X POST "$FULL_URL" \
  -H "Content-Type: application/json" \
  -d '{
    "CreditScore": 650,
    "Age": 35,
    "Tenure": 5,
    "Balance": 50000,
    "NumOfProducts": 2,
    "HasCrCard": 1,
    "IsActiveMember": 1,
    "EstimatedSalary": 75000,
    "Geography_Germany": 0,
    "Geography_Spain": 1
  }'
```

### üîß R√©solution des probl√®mes {#sec-module4-troubleshooting}

| Probl√®me | Solution |
|----------|----------|
| **Erreur DNS / `cloudName: null`** | Ex√©cuter `az logout && az login` |
| **Caract√®re `\r` dans les variables** | Toujours utiliser `tr -d '\r'` apr√®s `az acr show` |
| **Erreur "ContainerAppInvalidSecretName"** | Utiliser l'approche YAML avec secret nomm√© `acrpassword` |
| **Docker non accessible** | D√©marrer Docker Desktop et ouvrir un nouveau terminal |
| **Erreurs de permissions** | V√©rifier `az account show` et `az login` |
| **L'application est "Failed"** | V√©rifier les logs : `az containerapp logs show --name $CONTAINER_APP_NAME --resource-group $RESOURCE_GROUP --tail 50` |
| **Image fonctionne localement mais pas sur Azure** | V√©rifier les credentials ACR et l'identit√© manag√©e |

### üìã Commandes de diagnostic utiles {#sec-module4-diagnostic}

```bash
# Voir les logs en temps r√©el
az containerapp logs show \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --tail 100 \
  --follow

# V√©rifier l'√©tat d√©taill√©
az containerapp revision list \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --output table

# R√©cup√©ration automatique et test Docker
RESOURCE_GROUP="rg-mlops1"
ACR_NAME=$(az acr list --resource-group $RESOURCE_GROUP --query "[0].name" -o tsv | tr -d '\r\n' | xargs)
ACR_LOGIN_SERVER=$(az acr show --name $ACR_NAME --query loginServer --output tsv | tr -d '\r\n' | xargs)

echo "ACR trouv√©: $ACR_LOGIN_SERVER"
echo "Lancement de l'image..."

docker run -p 8000:8000 ${ACR_LOGIN_SERVER}/bank-churn-api:v1


# tester l'api 
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "CreditScore": 650,
    "Age": 35,
    "Tenure": 5,
    "Balance": 50000,
    "NumOfProducts": 2,
    "HasCrCard": 1,
    "IsActiveMember": 1,
    "EstimatedSalary": 75000,
    "Geography_Germany": 0,
    "Geography_Spain": 1
  }'
```

### üìä Alternative : D√©ploiement via le Portail Azure {#sec-module4-portail}

Si vous pr√©f√©rez utiliser l'interface graphique :

1. Allez sur **portal.azure.com**
2. Recherchez **"Container Apps"**
3. Cliquez sur **"+ Create"**
4. **Basics** :
   - Resource group : `rg-mlops`
   - Container app name : `app-churn-api`
   - Region : `West Europe`
   - Environment : `env-mlops-workshop`
5. **Container** :
   - Image source : **Azure Container Registry**
   - Registry : S√©lectionnez votre ACR
   - Image : `bank-churn-api`
   - Tag : `v1`
   - CPU : `0.5`, Memory : `1.0 Gi`
6. **Ingress** :
   - Enabled : **Oui**
   - Traffic : **Accepting traffic from anywhere**
   - Target port : `8000`
7. **Review + Create**

### Surveillance des Co√ªts {#sec-module4-couts}

::: callout-warning
## IMPORTANT - Gestion du Budget

Pour √©viter de d√©passer le budget de 100$ :

```bash
# Voir les co√ªts estim√©s
az consumption usage list \
  --start-date 2025-12-01 \
  --end-date 2025-12-31 \
  --output table

# Mettre l'application en veille (min-replicas=0)
az containerapp update \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --min-replicas 0 \
  --max-replicas 3

# Supprimer toutes les ressources apr√®s le workshop
az group delete --name $RESOURCE_GROUP --yes --no-wait
```

Co√ªts estim√©s pour ce workshop : 8-12$ pour 10 heures d'utilisation.
:::

### Exercice Pratique {#sec-module4-exercice}

::: callout-tip
## EXERCICE 2

Partagez votre URL d'API avec un camarade et testez son API :

1. Faites 10 pr√©dictions sur son API
2. Comparez les r√©sultats avec votre mod√®le
3. Observez les logs dans Azure Portal :
   - Allez dans votre Container App
   - Menu **"Log stream"** ou **"Monitoring" ‚Üí "Logs"**
   - Observez les requ√™tes en temps r√©el
:::

### üéØ Points cl√©s des corrections apport√©es {#sec-module4-resume}

1. **Nettoyage du `\r`** : Ajout de `tr -d '\r'` √† la r√©cup√©ration du login server
2. **Approche YAML** : Contournement du bug de g√©n√©ration de nom de secret
3. **Secret nomm√©** : Utilisation d'un nom valide `acrpassword` au lieu du nom auto-g√©n√©r√©
4. **Variables d'environnement** : Ajout de `PYTHONUNBUFFERED=1` pour les logs
5. **Tests robustes** : Attente de 30 secondes avant les v√©rifications
6. **Commandes de diagnostic** : Ajout de commandes pour troubleshooting
7. **Alternative GUI** : Instructions pour le d√©ploiement via le portail Azure

Pour ex√©cuter le module, sauvegardez-le dans un fichier `module4-deploiement.sh` et ex√©cutez :
```bash
chmod +x module4-deploiement.sh
./module4-deploiement.sh
```

### Checkpoint {#sec-module4-checkpoint}

:::: callout-note
## Validation Module 4

Avant de passer au module suivant, v√©rifiez que :

::: {style="margin-left: 20px;"}
-   [ ] L'application est accessible via HTTPS
-   [ ] Le health check fonctionne
-   [ ] Les pr√©dictions fonctionnent
-   [ ] Vous avez not√© l'URL publique de votre API
:::
::::

## Module 5 : CI/CD avec GitHub Actions {#sec-module5}

### Objectif {#sec-module5-objectif}

Automatiser le d√©ploiement : chaque commit sur la branche main d√©clenche un build et un red√©ploiement.

### √âtape 1 : Initialisation du Repository Git {#sec-module5-etape1}

``` bash
# Initialiser git (si pas deja fait)
git init

# Creer un .gitignore
cat > .gitignore << EOF
__pycache__/
*.pyc
venv/
.env
mlruns/
*.log
.DS_Store
.vscode/
confusion_matrix.png
feature_importance.png
EOF

# Premier commit
git add .
git commit -m "Initial commit: Bank Churn API"
```

### √âtape 2 : Cr√©er un Repository GitHub {#sec-module5-etape2}

1.  Allez sur https://github.com/new
2.  Nom du repository : `bank-churn-mlops`
3.  Visibility : Public ou Private
4.  Ne pas initialiser avec README (d√©j√† fait localement)
5.  Cliquez sur "Create repository"

``` bash
# Lier votre repo local a GitHub (REMPLACEZ username)
git remote add origin https://github.com/username/bank-churn-mlops.git
git branch -M main
git push -u origin main
```

### √âtape 3 : Configuration des Secrets GitHub {#sec-module5-etape3}

#### Cr√©er un Service Principal Azure {#sec-module5-service-principal}

``` bash
# Recuperer votre Subscription ID
SUBSCRIPTION_ID=$(az account show --query id -o tsv)

# Creer un Service Principal
az ad sp create-for-rbac \
  --name "github-actions-mlops" \
  --role contributor \
  --scopes /subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP \
  --sdk-auth
```

Copiez tout le JSON retourn√©.

#### Ajouter les Secrets dans GitHub {#sec-module5-secrets}

1.  Allez dans votre repository GitHub
2.  Settings \> Secrets and variables \> Actions
3.  Cliquez sur "New repository secret"
4.  Ajoutez les secrets suivants :

| **Nom** | **Valeur** |
|------------------------------------|------------------------------------|
| AZURE_CREDENTIALS | Le JSON du Service Principal |
| ACR_USERNAME | R√©sultat de : `az acr credential show --name $ACR_NAME --query username -o tsv` |
| ACR_PASSWORD | R√©sultat de : `az acr credential show --name $ACR_NAME --query passwords[0].value -o tsv` |

### √âtape 4 : Cr√©ation du Workflow GitHub Actions {#sec-module5-etape4}

Cr√©ez le fichier `.github/workflows/ci-cd.yml` :

``` yaml
name: CI/CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  AZURE_RESOURCE_GROUP: rg-mlops
  ACR_NAME: votre-acr-name  # MODIFIEZ ICI
  CONTAINER_APP_NAME: app-churn-api
  IMAGE_NAME: bank-churn-api

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov
      
      - name: Run tests
        run: |
          pytest tests/ -v --cov=app --cov-report=term
      
  build-and-deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      
      - name: Login to ACR
        uses: azure/docker-login@v1
        with:
          login-server: ${{ env.ACR_NAME }}.azurecr.io
          username: ${{ secrets.ACR_USERNAME }}
          password: ${{ secrets.ACR_PASSWORD }}
      
      - name: Build and push Docker image
        run: |
          docker build -t ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }} .
          docker build -t ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest .
          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}
          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest
      
      - name: Deploy to Azure Container Apps
        uses: azure/CLI@v1
        with:
          inlineScript: |
            az containerapp update \
              --name ${{ env.CONTAINER_APP_NAME }} \
              --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
              --image ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}
      
      - name: Verify deployment
        run: |
          APP_URL=$(az containerapp show \
            --name ${{ env.CONTAINER_APP_NAME }} \
            --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
            --query properties.configuration.ingress.fqdn -o tsv)
          
          echo "Application deployed at: https://$APP_URL"
          
          sleep 30
          curl -f https://$APP_URL/health || exit 1
          
          echo "Deployment successful!"
```

### √âtape 5 : D√©clencher le Pipeline {#sec-module5-etape5}

``` bash
# Ajouter le workflow
git add .github/workflows/ci-cd.yml
git add tests/test_api.py
git commit -m "Add CI/CD pipeline and tests"
git push origin main

# Le pipeline se declenche automatiquement !
```

Allez sur GitHub \> Actions pour voir le pipeline en cours d'ex√©cution.

### Exercice Pratique {#sec-module5-exercice}

::: callout-tip
## EXERCICE 3

1.  Ajoutez un nouveau test dans `test_api.py`
2.  Faites un commit et push
3.  Observez le pipeline s'ex√©cuter
4.  V√©rifiez que le d√©ploiement s'est bien fait
:::

### Checkpoint {#sec-module5-checkpoint}

:::: callout-note
## Validation Module 5

Avant de passer au module suivant, v√©rifiez que :

::: {style="margin-left: 20px; line-height: 1.8;"}
-   [ ] Le repository GitHub est cr√©√©
-   [ ] Les secrets sont configur√©s
-   [ ] Le workflow CI/CD s'ex√©cute sans erreur
-   [ ] L'application se red√©ploie
:::

automatiquement
::::

## Module 6 : Monitoring et Maintenance {#sec-module6}

### Objectif {#sec-module6-objectif}

Mettre en place le monitoring de l'application et d√©tecter les probl√®mes en production.

### Configuration Application Insights {#sec-module6-appinsights}

``` bash
# Creation d'Application Insights
az monitor app-insights component create \
  --app bank-churn-insights \
  --location $LOCATION \
  --resource-group $RESOURCE_GROUP \
  --application-type web

# Recuperer la connection string
APPINSIGHTS_CONN=$(az monitor app-insights component show \
  --app bank-churn-insights \
  --resource-group $RESOURCE_GROUP \
  --query connectionString -o tsv)

echo "Connection String : $APPINSIGHTS_CONN"

# Ajouter la variable d'environnement a Container Apps
az containerapp update \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --set-env-vars "APPLICATIONINSIGHTS_CONNECTION_STRING=$APPINSIGHTS_CONN"
```

### Int√©gration du Monitoring dans le Code {#sec-module6-monitoring}

Ajoutez dans `requirements.txt` :

```         
opencensus-ext-azure==1.1.9
opencensus-ext-requests==0.12.1
```

Modifiez `app/main.py` pour ajouter le monitoring :

``` python
import os
from opencensus.ext.azure.log_exporter import AzureLogHandler
import logging

# Configuration du logging avec Application Insights
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

APPINSIGHTS_CONN = os.getenv("APPLICATIONINSIGHTS_CONNECTION_STRING")
if APPINSIGHTS_CONN:
    logger.addHandler(AzureLogHandler(connection_string=APPINSIGHTS_CONN))
    logger.info("Application Insights connecte")
```

### D√©tection de Data Drift {#sec-module6-drift}

Cr√©ez le fichier `drift_detection.py` :

``` python
import pandas as pd
from scipy.stats import ks_2samp
import json

def detect_drift(reference_file, production_file, threshold=0.05):
    """
    Detecte le drift entre donnees de reference et production
    """
    ref_data = pd.read_csv(reference_file)
    prod_data = pd.read_csv(production_file)
    
    drift_results = {}
    
    for column in ref_data.columns:
        if column in prod_data.columns and column != 'Exited':
            # Test de Kolmogorov-Smirnov
            statistic, p_value = ks_2samp(
                ref_data[column].dropna(),
                prod_data[column].dropna()
            )
            
            drift_detected = p_value < threshold
            
            drift_results[column] = {
                'p_value': float(p_value),
                'statistic': float(statistic),
                'drift_detected': drift_detected
            }
    
    # Rapport
    drifted_features = [f for f, r in drift_results.items() if r['drift_detected']]
    
    print("="*50)
    print("DATA DRIFT DETECTION REPORT")
    print("="*50)
    print(f"Threshold: {threshold}")
    print(f"Features analyzed: {len(drift_results)}")
    print(f"Features with drift: {len(drifted_features)}")
    print("\nDrifted features:")
    for feature in drifted_features:
        print(f"  - {feature}: p-value = {drift_results[feature]['p_value']:.4f}")
    print("="*50)
    
    return drift_results

if __name__ == "__main__":
    results = detect_drift(
        "data/bank_churn.csv",
        "data/production_data.csv"
    )
    
    # Sauvegarder les resultats
    with open("drift_report.json", "w") as f:
        json.dump(results, f, indent=2)
    
    print("\nRapport sauvegarde dans drift_report.json")
```

### Checkpoint {#sec-module6-checkpoint}

:::: callout-note
## Validation Module 6

Avant de passer au module suivant, v√©rifiez que :

::: {style="margin-left: 20px; line-height: 1.8;"}
-   [ ] Application Insights est configur√©
-   [ ] Les logs apparaissent dans Azure Portal
-   [ ] Vous pouvez visualiser les m√©triques
-   [ ] Le script de d√©tection de drift fonctionne
:::
::::

## Module 7 : Optimisations et Bonnes Pratiques {#sec-module7}

### Objectif {#sec-module7-objectif}

Am√©liorer les performances, la s√©curit√© et la maintenabilit√© de l'application.

### Ajout d'un Cache pour les Pr√©dictions {#sec-module7-cache}

Modifiez `app/main.py` :

``` python
from functools import lru_cache
import hashlib
import json

def hash_features(features_dict: dict) -> str:
    """Cree un hash unique pour les features"""
    return hashlib.md5(
        json.dumps(features_dict, sort_keys=True).encode()
    ).hexdigest()

# Cache pour les predictions (1000 dernieres)
@lru_cache(maxsize=1000)
def predict_cached(features_hash: str, features_json: str):
    features_dict = json.loads(features_json)
    input_data = np.array([[
        features_dict["CreditScore"],
        features_dict["Age"],
        # ... autres features
    ]])
    
    proba = model.predict_proba(input_data)[0, 1]
    prediction = int(proba > 0.5)
    
    if proba < 0.3:
        risk = "Low"
    elif proba < 0.7:
        risk = "Medium"
    else:
        risk = "High"
    
    return {
        "churn_probability": round(float(proba), 4),
        "prediction": prediction,
        "risk_level": risk
    }

@app.post("/predict", response_model=PredictionResponse)
def predict(features: CustomerFeatures):
    features_dict = features.dict()
    features_hash = hash_features(features_dict)
    features_json = json.dumps(features_dict)
    
    # Utilise le cache si disponible
    result = predict_cached(features_hash, features_json)
    
    logger.info(f"Prediction - Hash: {features_hash[:8]}")
    return result
```

### Checklist de Production {#sec-module7-checklist}

::: callout-tip
## Checklist Avant Production

-   [ ] Tests unitaires avec coverage \> 80%
-   [ ] Tests d'integration
-   [ ] Load testing effectue
-   [ ] Monitoring configure
-   [ ] Alertes definies
-   [ ] Logs centralises
-   [ ] Documentation API complete
-   [ ] HTTPS active
-   [ ] Health checks fonctionnels
-   [ ] Auto-scaling teste
-   [ ] Variables d'environnement securisees
-   [ ] Budget Azure surveille
:::

### Checkpoint Final {#sec-module7-checkpoint}

:::: callout-note
## Validation Module 7

::: {style="margin-left: 20px; line-height: 1.8;"}
-   [ ] Cache de predictions implemente
-   [ ] Documentation complete
-   [ ] Tous les tests passent
-   [ ] Checklist de production verifiee
:::
::::

## Nettoyage des Ressources Azure {#sec-nettoyage}

### IMPORTANT - Suppression pour √âviter les Co√ªts {#sec-nettoyage-important}

::: callout-warning
## ATTENTION - √Ä FAIRE √Ä LA FIN DU WORKSHOP

Pour √©viter de consommer votre budget de 100\$, supprimez toutes les ressources :

``` bash
# Suppression du groupe de ressources (supprime tout)
az group delete --name $RESOURCE_GROUP --yes --no-wait

# Verification
az group list --output table
```

Cette commande supprime : - Azure Container Registry - Azure Container Apps - Application Insights - Tous les logs et donn√©es

**Temps de suppression** : 5-10 minutes
:::

### Script de Nettoyage Automatique {#sec-nettoyage-script}

Cr√©ez `cleanup.sh` :

``` bash
#!/bin/bash

RESOURCE_GROUP="rg-mlops"

echo "=========================================="
echo "Nettoyage des ressources Azure"
echo "=========================================="

read -p "Voulez-vous vraiment supprimer toutes les ressources ? (yes/no): " confirm

if [ "$confirm" != "yes" ]; then
    echo "Operation annulee."
    exit 0
fi

echo "\nRessources a supprimer:"
az resource list --resource-group $RESOURCE_GROUP --output table

echo "\nSuppression en cours..."
az group delete --name $RESOURCE_GROUP --yes --no-wait

echo "\nSuppression lancee (prend 5-10 minutes)"
echo "Verifiez sur : https://portal.azure.com"
```

``` bash
# Rendre executable et lancer
chmod +x cleanup.sh
./cleanup.sh
```

## R√©capitulatif du Workshop {#sec-recapitulatif}

### Ce que Vous Avez Accompli {#sec-recap-accompli}

F√©licitations ! Vous avez d√©ploy√© un syst√®me MLOps complet :

**Architecture Finale :**

`ML Training` ‚Üí `FastAPI` ‚Üí `Docker` ‚Üí `Azure Container Registry` ‚Üí `Azure Container Apps`

‚Üë `GitHub Actions CI/CD`

‚Üë `Application Insights Monitoring`

### Comp√©tences Acquises {#sec-recap-competences}

1.  **Machine Learning**
    -   Entra√Ænement d'un mod√®le Random Forest
    -   √âvaluation avec m√©triques appropri√©es
    -   Tracking avec MLflow
2.  **D√©veloppement d'API**
    -   Cr√©ation d'API REST avec FastAPI
    -   Validation des donn√©es avec Pydantic
    -   Documentation automatique
3.  **Conteneurisation**
    -   Dockerfiles optimis√©s
    -   Bonnes pratiques de s√©curit√©
    -   Gestion des images
4.  **Cloud Azure**
    -   Azure Container Registry
    -   Azure Container Apps
    -   Application Insights
5.  **DevOps/MLOps**
    -   Pipelines CI/CD avec GitHub Actions
    -   Tests automatis√©s
    -   D√©ploiement continu
6.  **Monitoring et Maintenance**
    -   Logs centralis√©s
    -   M√©triques de performance
    -   D√©tection de data drift

### Points Cl√©s √† Retenir {#sec-recap-points-cles}

::: callout-important
## Lecons Importantes

1.  **MLOps = DevOps + ML** : Automatisation du cycle de vie complet
2.  **Conteneurisation** : Portabilit√© et reproductibilit√©
3.  **Tests** : Essentiels pour la fiabilit√©
4.  **Monitoring** : Indispensable en production
5.  **Documentation** : Facilite la collaboration
6.  **S√©curit√©** : √Ä consid√©rer d√®s le d√©but
7.  **Co√ªts** : Toujours surveiller l'utilisation cloud
:::

## FAQ - Foire Aux Questions {#sec-faq}

### Questions Techniques {#sec-faq-techniques}

**Q1 : Mon API est lente, comment l'optimiser ?**

*R :* Plusieurs options : - Activer le cache des pr√©dictions - Utiliser des pr√©dictions batch - Optimiser le mod√®le (quantization, pruning) - Augmenter les ressources CPU/RAM

**Q2 : Comment g√©rer plusieurs versions de mod√®les ?**

*R :* Utilisez MLflow Model Registry et cr√©ez des endpoints diff√©rents (v1, v2).

**Q3 : Comment impl√©menter un rollback ?**

*R :* Conservez les anciennes images Docker avec tags et utilisez :

``` bash
az containerapp update \
  --name $APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --image $ACR_NAME.azurecr.io/bank-churn-api:v1  # Version precedente
```

**Q4 : Mon budget Azure est presque √©puis√©, que faire ?**

*R :* - Mettre min-replicas √† 0 - Utiliser des SKU Basic - Supprimer les ressources inutilis√©es - Activer les budgets alerts

### Questions de Compr√©hension {#sec-faq-comprehension}

**Q5 : Quelle est la diff√©rence entre Docker et Kubernetes ?**

*R :* Docker conteneurise les applications, Kubernetes les orchestre (scaling, load balancing, self-healing).

**Q6 : Pourquoi utiliser FastAPI plut√¥t que Flask ?**

*R :* FastAPI est plus rapide, avec validation automatique, documentation auto-g√©n√©r√©e, et support async natif.

**Q7 : Qu'est-ce que le data drift ?**

*R :* Changement dans la distribution des donn√©es d'entr√©e par rapport aux donn√©es d'entra√Ænement, pouvant d√©grader les performances du mod√®le.

## Conclusion {#sec-conclusion}

### F√©licitations ! {#sec-conclusion-felicitations}

Vous avez termin√© ce workshop intensif de MLOps avec Azure. Vous avez construit un syst√®me complet de d√©ploiement de mod√®le de Machine Learning en production, avec toutes les bonnes pratiques de l'industrie.

### Prochaines √âtapes {#sec-conclusion-next-steps}

1.  **Pratiquez** : Refaites le workshop avec un dataset diff√©rent
2.  **Partagez** : Mettez votre projet sur GitHub
3.  **Am√©liorez** : Impl√©mentez les fonctionnalit√©s avanc√©es
4.  **Certifiez-vous** : Pr√©parez les certifications Azure

------------------------------------------------------------------------

**Bon Apprentissage et Bon D√©ploiement !**

*Ce guide vous a accompagn√© dans votre premier projet MLOps.\
Continuez √† explorer, √† apprendre et √† innover.*

------------------------------------------------------------------------

*Version 1.0 - Novembre 2025*\
*Workshop MLOps avec Azure* \n\## Test de d√©ploiement - jeu. 20 nov. 2025 03:26:42
