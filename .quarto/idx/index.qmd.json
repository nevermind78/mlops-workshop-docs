{"title":"Workshop MLOps avec Azure - Guide Pratique","markdown":{"yaml":{"title":"Workshop MLOps avec Azure - Guide Pratique","format":{"html":{"toc":true,"toc-depth":3,"toc-location":"left","number-sections":true,"code-fold":true,"code-overflow":"wrap"}},"editor":"visual"},"headingText":"Introduction","headingAttr":{"id":"sec-introduction","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n\n### Bienvenue !\n\nCe workshop vous guidera √† travers le d√©ploiement complet d'un mod√®le de Machine Learning en production sur Microsoft Azure. Vous allez construire une API de pr√©diction de d√©faillance client (churn) et la d√©ployer sur le cloud avec toutes les bonnes pratiques MLOps.\n\n### Objectifs d'Apprentissage {#sec-objectifs}\n\n√Ä la fin de ce workshop, vous serez capable de :\n\n-   Entra√Æner et sauvegarder un mod√®le ML avec MLflow\n-   Cr√©er une API REST avec FastAPI\n-   Conteneuriser une application avec Docker\n-   D√©ployer sur Azure Container Apps\n-   Mettre en place un pipeline CI/CD avec GitHub Actions\n-   Monitorer votre application en production\n-   D√©tecter le data drift\n\n### Le Projet : Bank Churn Prediction {#sec-projet}\n\n**Contexte :** Une banque souhaite pr√©dire quels clients risquent de partir pour proposer des actions de r√©tention.\n\n**Dataset :** 10 features (√¢ge, score cr√©dit, solde, etc.) + 1 target (Exited : 0/1)\n\n**Mod√®le :** Random Forest Classifier\n\n**Livrable :** API REST d√©ploy√©e sur Azure, accessible publiquement\n\n### Architecture Finale {#sec-architecture}\n\n**Flux de d√©ploiement :**\n\n`Code GitHub` ‚Üí `GitHub Actions` ‚Üí `Docker Build` ‚Üí `Azure Container Registry` ‚Üí `Azure Container Apps` ‚Üí `Internet`\n\n## Pr√©paration de l'Environnement {#sec-preparation}\n\n### Logiciels Requis {#sec-logiciels}\n\n**Obligatoire :**\n\n-   Python 3.9+ : https://www.python.org/downloads/\n-   Visual Studio Code : https://code.visualstudio.com/\n-   Git : https://git-scm.com/downloads\n-   Docker Desktop : https://www.docker.com/products/docker-desktop\n-   Azure CLI : https://docs.microsoft.com/cli/azure/install-azure-cli\n\n**Comptes √† cr√©er :**\n\n-   Compte GitHub : https://github.com/signup\n-   Azure for Students (100\\$) : https://azure.microsoft.com/students\n\n### V√©rification de l'Installation {#sec-verification}\n\nOuvrez un terminal et testez :\n\n``` bash\n# Python\npython --version\n# Doit afficher Python 3.9.x ou superieur\n\n# Git\ngit --version\n\n# Docker\ndocker --version\ndocker ps\n\n# Azure CLI\naz --version\n```\n\n### Configuration Initiale {#sec-configuration}\n\n#### Configuration Git {#sec-config-git}\n\n``` bash\ngit config --global user.name \"Votre Nom\"\ngit config --global user.email \"votre.email@example.com\"\n```\n\n#### Connexion √† Azure {#sec-config-azure}\n\n``` bash\n# Se connecter a Azure\naz login\n\n# Verifier l'abonnement\naz account show\n\n# Si vous avez plusieurs abonnements, selectionner celui de Students\naz account set --subscription \"Azure for Students\"\n```\n\n## Module 1 : Entra√Ænement du Mod√®le {#sec-module1}\n\n### Objectif {#sec-module1-objectif}\n\nEntra√Æner un mod√®le Random Forest pour pr√©dire le churn et le sauvegarder avec MLflow.\n\n### Pr√©paration du Projet {#sec-module1-preparation}\n\n``` bash\n# Creer le dossier du projet\nmkdir bank-churn-mlops\ncd bank-churn-mlops\n\n# Creer un environnement virtuel\npython -m venv venv\n\n# Activer l'environnement\n# Windows :\nvenv\\Scripts\\activate\n# Mac/Linux :\nsource venv/bin/activate\n\n# Creer la structure\nmkdir -p data model app tests\ntouch requirements.txt\n```\n\n### Fichier requirements.txt {#sec-module1-requirements}\n\nCr√©ez le fichier `requirements.txt` avec le contenu suivant :\n\n```         \n# API Framework\nfastapi==0.104.1\nuvicorn[standard]==0.24.0\npydantic==2.5.0\n\n# Machine Learning\nscikit-learn==1.3.2\npandas==2.1.3\nnumpy==1.26.2\njoblib==1.3.2\n\n# MLflow\nmlflow==2.8.1\n\n# Testing\npytest==7.4.3\npytest-cov==4.1.0\nhttpx==0.25.2\n\n# Utilities\npython-multipart==0.0.6\nrequests==2.31.0\n```\n\nPuis installez les d√©pendances :\n\n``` bash\npip install -r requirements.txt\n```\n\n### T√©l√©chargement du Dataset {#sec-module1-dataset}\n\nCr√©ez un dataset synth√©tique :\n\n``` python\n# generate_data.py\nimport pandas as pd\nimport numpy as np\n\nnp.random.seed(42)\nn_samples = 10000\n\ndata = {\n    'CreditScore': np.random.randint(300, 850, n_samples),\n    'Age': np.random.randint(18, 80, n_samples),\n    'Tenure': np.random.randint(0, 11, n_samples),\n    'Balance': np.random.uniform(0, 200000, n_samples),\n    'NumOfProducts': np.random.randint(1, 5, n_samples),\n    'HasCrCard': np.random.choice([0, 1], n_samples),\n    'IsActiveMember': np.random.choice([0, 1], n_samples),\n    'EstimatedSalary': np.random.uniform(20000, 150000, n_samples),\n    'Geography_Germany': np.random.choice([0, 1], n_samples),\n    'Geography_Spain': np.random.choice([0, 1], n_samples),\n}\n\n# Target : plus de chance de partir si inactif, peu de produits, etc.\nchurn_prob = (\n    (1 - data['IsActiveMember']) * 0.3 +\n    (data['NumOfProducts'] == 1) * 0.2 +\n    (data['Age'] > 60) * 0.15 +\n    (data['Balance'] == 0) * 0.25\n)\ndata['Exited'] = (np.random.random(n_samples) < churn_prob).astype(int)\n\ndf = pd.DataFrame(data)\ndf.to_csv('data/bank_churn.csv', index=False)\nprint(f\"Dataset cree : {len(df)} lignes\")\nprint(f\"Taux de churn : {df['Exited'].mean():.2%}\")\n```\n\n### Script d'Entra√Ænement {#sec-module1-training}\n\nCr√©ez le fichier `train_model.py` :\n\n``` python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, \n    precision_score, \n    recall_score,\n    f1_score, \n    roc_auc_score,\n    confusion_matrix\n)\nimport joblib\nimport mlflow\nimport mlflow.sklearn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configuration MLflow\nmlflow.set_tracking_uri(\"./mlruns\")\nmlflow.set_experiment(\"bank-churn-prediction\")\n\nprint(\"Chargement des donnees...\")\ndf = pd.read_csv(\"data/bank_churn.csv\")\n\nprint(f\"Dataset : {len(df)} lignes, {len(df.columns)} colonnes\")\nprint(f\"Taux de churn : {df['Exited'].mean():.2%}\")\n\n# Separation features/target\nX = df.drop('Exited', axis=1)\ny = df['Exited']\n\n# Split train/test (80/20)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(f\"\\nTrain : {len(X_train)} lignes\")\nprint(f\"Test : {len(X_test)} lignes\")\n\n# Entrainement avec MLflow tracking\nprint(\"\\nEntrainement du modele...\")\nwith mlflow.start_run(run_name=\"random-forest-v1\"):\n    \n    # Parametres du modele\n    params = {\n        'n_estimators': 100,\n        'max_depth': 10,\n        'min_samples_split': 5,\n        'random_state': 42\n    }\n    \n    # Entrainement\n    model = RandomForestClassifier(**params)\n    model.fit(X_train, y_train)\n    \n    # Predictions\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    \n    # Calcul des metriques\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    \n    # Log des parametres et metriques dans MLflow\n    mlflow.log_params(params)\n    mlflow.log_metrics({\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1_score\": f1,\n        \"roc_auc\": auc\n    })\n    \n    # Creation et sauvegarde de la matrice de confusion\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title('Matrice de Confusion')\n    plt.ylabel('Vraie Classe')\n    plt.xlabel('Classe Predite')\n    plt.savefig('confusion_matrix.png')\n    mlflow.log_artifact('confusion_matrix.png')\n    plt.close()\n    \n    # Feature importance\n    feature_importance = pd.DataFrame({\n        'feature': X.columns,\n        'importance': model.feature_importances_\n    }).sort_values('importance', ascending=False)\n    \n    plt.figure(figsize=(10, 6))\n    plt.barh(feature_importance['feature'], feature_importance['importance'])\n    plt.xlabel('Importance')\n    plt.title('Feature Importance')\n    plt.tight_layout()\n    plt.savefig('feature_importance.png')\n    mlflow.log_artifact('feature_importance.png')\n    plt.close()\n    \n    # Enregistrement du modele dans MLflow\n    mlflow.sklearn.log_model(\n        model,\n        \"model\",\n        registered_model_name=\"bank-churn-classifier\"\n    )\n    \n    # Sauvegarde locale du modele\n    joblib.dump(model, \"model/churn_model.pkl\")\n    \n    # Tags\n    mlflow.set_tags({\n        \"environment\": \"development\",\n        \"model_type\": \"RandomForest\",\n        \"task\": \"binary_classification\"\n    })\n    \n    # Affichage des resultats\n    print(\"\\n\" + \"=\"*50)\n    print(\"RESULTATS DE L'ENTRAINEMENT\")\n    print(\"=\"*50)\n    print(f\"Accuracy  : {accuracy:.4f}\")\n    print(f\"Precision : {precision:.4f}\")\n    print(f\"Recall    : {recall:.4f}\")\n    print(f\"F1 Score  : {f1:.4f}\")\n    print(f\"ROC AUC   : {auc:.4f}\")\n    print(\"=\"*50)\n    \n    print(f\"\\nModele sauvegarde dans : model/churn_model.pkl\")\n    print(f\"MLflow UI : mlflow ui --port 5000\")\n```\n\n### Ex√©cution {#sec-module1-execution}\n\n``` bash\n# Lancer l'entrainement\npython train_model.py\n\n# Voir les resultats dans MLflow UI\nmlflow ui --port 5000\n# Ouvrir http://localhost:5000 dans votre navigateur\n```\n\n### Checkpoint {#sec-module1-checkpoint}\n\n:::: callout-note\n## Validation Module 1\n\nAvant de passer au module suivant, v√©rifiez que :\n\n::: {style=\"margin-left: 20px;\"}\n-   [ ] Le mod√®le est entra√Æn√© avec une accuracy \\> 0.75\n-   [ ] Le fichier `model/churn_model.pkl` existe\n-   [ ] MLflow UI affiche votre exp√©rience\n-   [ ] Vous comprenez les m√©triques obtenues\n:::\n::::\n\n## Module 2 : Cr√©ation de l'API avec FastAPI {#sec-module2}\n\n### Objectif {#sec-module2-objectif}\n\nCr√©er une API REST qui expose le mod√®le via des endpoints HTTP.\n\n### Structure du Code API {#sec-module2-structure}\n\n```         \nbank-churn-mlops/\n|-- app/\n|   |-- __init__.py\n|   |-- main.py\n|   |-- models.py\n|   +-- utils.py\n|-- model/\n|   +-- churn_model.pkl\n|-- tests/\n|   +-- test_api.py\n|-- requirements.txt\n+-- README.md\n```\n\n### Fichier app/models.py {#sec-module2-models}\n\nD√©finition des sch√©mas de donn√©es avec Pydantic :\n\n``` python\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass CustomerFeatures(BaseModel):\n    \"\"\"Schema pour les features d'un client\"\"\"\n    CreditScore: int = Field(..., ge=300, le=850, description=\"Score de credit\")\n    Age: int = Field(..., ge=18, le=100, description=\"Age du client\")\n    Tenure: int = Field(..., ge=0, le=10, description=\"Anciennete en annees\")\n    Balance: float = Field(..., ge=0, description=\"Solde du compte\")\n    NumOfProducts: int = Field(..., ge=1, le=4, description=\"Nombre de produits\")\n    HasCrCard: int = Field(..., ge=0, le=1, description=\"Possession carte credit\")\n    IsActiveMember: int = Field(..., ge=0, le=1, description=\"Membre actif\")\n    EstimatedSalary: float = Field(..., ge=0, description=\"Salaire estime\")\n    Geography_Germany: int = Field(..., ge=0, le=1, description=\"Client allemand\")\n    Geography_Spain: int = Field(..., ge=0, le=1, description=\"Client espagnol\")\n    \n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"CreditScore\": 650,\n                \"Age\": 35,\n                \"Tenure\": 5,\n                \"Balance\": 50000,\n                \"NumOfProducts\": 2,\n                \"HasCrCard\": 1,\n                \"IsActiveMember\": 1,\n                \"EstimatedSalary\": 75000,\n                \"Geography_Germany\": 0,\n                \"Geography_Spain\": 1\n            }\n        }\n\nclass PredictionResponse(BaseModel):\n    \"\"\"Schema pour la reponse de prediction\"\"\"\n    churn_probability: float = Field(..., description=\"Probabilite de churn (0-1)\")\n    prediction: int = Field(..., description=\"Prediction binaire (0=reste, 1=part)\")\n    risk_level: str = Field(..., description=\"Niveau de risque (Low/Medium/High)\")\n\nclass HealthResponse(BaseModel):\n    \"\"\"Schema pour le health check\"\"\"\n    status: str\n    model_loaded: bool\n```\n\n### Fichier app/main.py {#sec-module2-main}\n\nL'API principale :\n\n``` python\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nimport joblib\nimport numpy as np\nfrom typing import List\nimport logging\nimport os\n\nfrom app.models import CustomerFeatures, PredictionResponse, HealthResponse\n\n# Configuration du logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Initialisation FastAPI\napp = FastAPI(\n    title=\"Bank Churn Prediction API\",\n    description=\"API de prediction de defaillance client\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\"\n)\n\n# CORS pour permettre les requetes depuis un navigateur\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Chargement du modele au demarrage\nMODEL_PATH = os.getenv(\"MODEL_PATH\", \"model/churn_model.pkl\")\nmodel = None\n\n@app.on_event(\"startup\")\nasync def load_model():\n    \"\"\"Charge le modele au demarrage de l'API\"\"\"\n    global model\n    try:\n        model = joblib.load(MODEL_PATH)\n        logger.info(f\"Modele charge avec succes depuis {MODEL_PATH}\")\n    except Exception as e:\n        logger.error(f\"Erreur lors du chargement du modele : {e}\")\n        model = None\n\n@app.get(\"/\", tags=[\"General\"])\ndef root():\n    \"\"\"Endpoint racine\"\"\"\n    return {\n        \"message\": \"Bank Churn Prediction API\",\n        \"version\": \"1.0.0\",\n        \"status\": \"running\",\n        \"docs\": \"/docs\"\n    }\n\n@app.get(\"/health\", response_model=HealthResponse, tags=[\"General\"])\ndef health_check():\n    \"\"\"Verification de l'etat de l'API\"\"\"\n    if model is None:\n        raise HTTPException(\n            status_code=503, \n            detail=\"Modele non charge\"\n        )\n    return {\n        \"status\": \"healthy\",\n        \"model_loaded\": True\n    }\n\n@app.post(\"/predict\", response_model=PredictionResponse, tags=[\"Prediction\"])\ndef predict(features: CustomerFeatures):\n    \"\"\"\n    Predit si un client va partir (churn)\n    \n    Retourne :\n    - churn_probability : probabilite de churn (0 a 1)\n    - prediction : 0 (reste) ou 1 (part)\n    - risk_level : Low, Medium ou High\n    \"\"\"\n    if model is None:\n        raise HTTPException(\n            status_code=503, \n            detail=\"Modele non disponible\"\n        )\n    \n    try:\n        # Preparation des features\n        input_data = np.array([[\n            features.CreditScore,\n            features.Age,\n            features.Tenure,\n            features.Balance,\n            features.NumOfProducts,\n            features.HasCrCard,\n            features.IsActiveMember,\n            features.EstimatedSalary,\n            features.Geography_Germany,\n            features.Geography_Spain\n        ]])\n        \n        # Prediction\n        proba = model.predict_proba(input_data)[0, 1]\n        prediction = int(proba > 0.5)\n        \n        # Classification du risque\n        if proba < 0.3:\n            risk = \"Low\"\n        elif proba < 0.7:\n            risk = \"Medium\"\n        else:\n            risk = \"High\"\n        \n        logger.info(\n            f\"Prediction effectuee : proba={proba:.4f}, \"\n            f\"prediction={prediction}, risk={risk}\"\n        )\n        \n        return {\n            \"churn_probability\": round(float(proba), 4),\n            \"prediction\": prediction,\n            \"risk_level\": risk\n        }\n    \n    except Exception as e:\n        logger.error(f\"Erreur lors de la prediction : {e}\")\n        raise HTTPException(\n            status_code=500, \n            detail=f\"Erreur de prediction : {str(e)}\"\n        )\n\n@app.post(\"/predict/batch\", tags=[\"Prediction\"])\ndef predict_batch(features_list: List[CustomerFeatures]):\n    \"\"\"\n    Predictions en batch pour plusieurs clients\n    \"\"\"\n    if model is None:\n        raise HTTPException(status_code=503, detail=\"Modele non disponible\")\n    \n    try:\n        predictions = []\n        \n        for features in features_list:\n            input_data = np.array([[\n                features.CreditScore, features.Age, features.Tenure,\n                features.Balance, features.NumOfProducts, features.HasCrCard,\n                features.IsActiveMember, features.EstimatedSalary,\n                features.Geography_Germany, features.Geography_Spain\n            ]])\n            \n            proba = model.predict_proba(input_data)[0, 1]\n            prediction = int(proba > 0.5)\n            \n            predictions.append({\n                \"churn_probability\": round(float(proba), 4),\n                \"prediction\": prediction\n            })\n        \n        logger.info(f\"Batch prediction : {len(predictions)} clients traites\")\n        \n        return {\"predictions\": predictions, \"count\": len(predictions)}\n    \n    except Exception as e:\n        logger.error(f\"Erreur batch prediction : {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n```\n\n### Test Local de l'API {#sec-module2-test}\n\n``` bash\n# Demarrer l'API\nuvicorn app.main:app --reload --port 8000\n\n# Dans un autre terminal, tester :\n\n# 1. Health check\ncurl http://localhost:8000/health\n\n# 2. Prediction simple\ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n  }'\n```\n\n### Jupyter Lab\n\n``` python\n#dans jupyter lab\nimport requests\nimport json\n\n# URL de ton API FastAPI\nurl = \"http://localhost:8000/predict\"\n\n# Donn√©es √† envoyer\ndata = {\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n}\n\n# Envoyer la requ√™te POST\nresponse = requests.post(url, json=data)\n\n# Afficher la r√©ponse\nprint(f\"Status Code: {response.status_code}\")\nprint(f\"Response: {response.json()}\")\n```\n\n### Documentation Interactive {#sec-module2-docs}\n\nOuvrez votre navigateur et allez sur :\n\n-   **Swagger UI** : http://localhost:8000/docs\n-   **ReDoc** : http://localhost:8000/redoc\n\n### Checkpoint {#sec-module2-checkpoint}\n\n:::: callout-note\n## Validation Module 2\n\nAvant de passer au module suivant, v√©rifiez que :\n\n::: {style=\"margin-left: 20px;\"}\n-   [ ] Le mod√®le est entra√Æn√© avec une accuracy \\> 0.75\n-   [ ] Le fichier `model/churn_model.pkl` existe\\\n-   [ ] MLflow UI affiche votre exp√©rience\n-   [ ] Vous comprenez les m√©triques obtenues\n:::\n::::\n\n## Module 3 : Conteneurisation avec Docker {#sec-module3}\n\n### Objectif {#sec-module3-objectif}\n\nEmpaqueter l'API dans un conteneur Docker pour la rendre portable et faciliter le d√©ploiement sur Azure.\n\n### Cr√©ation du Dockerfile {#sec-module3-dockerfile}\n\nCr√©ez le fichier `Dockerfile` √† la racine du projet :\n\n``` dockerfile\n# Utilise une image Python officielle\nFROM python:3.9-slim\n\n# Definir le repertoire de travail\nWORKDIR /app\n\n# Copier les fichiers de dependances\nCOPY requirements.txt .\n\n# Installer les dependances\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copier le code de l'application\nCOPY app/ ./app/\nCOPY model/ ./model/\n\n# Exposer le port\nEXPOSE 8000\n\n# Commande pour demarrer l'application\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```\n\n### Cr√©ation du .dockerignore {#sec-module3-dockerignore}\n\nCr√©ez le fichier `.dockerignore` :\n\n```         \n__pycache__\n*.pyc\n*.pyo\n*.pyd\n.Python\nenv/\nvenv/\n.venv\n*.egg-info/\n.pytest_cache/\n.git\n.gitignore\nREADME.md\n.env\nmlruns/\n*.log\n.DS_Store\n.vscode/\ntests/\n```\n\n### Build de l'Image Docker {#sec-module3-build}\n\n``` bash\n# Build de l'image (cela peut prendre quelques minutes)\ndocker build -t bank-churn-api:v1 .\n\n# Verifier que l'image est creee\ndocker images bank-churn-api:v1\n\n# Voir la taille de l'image\ndocker images --format \"table {{.Repository}}\\t{{.Tag}}\\t{{.Size}}\" | grep bank-churn\n```\n\n### Test du Conteneur en Local {#sec-module3-test}\n\n``` bash\n# Lancer le conteneur\ndocker run -d -p 8000:8000 --name churn-api bank-churn-api:v1\n\n# Verifier que le conteneur tourne\ndocker ps\n\n# Voir les logs\ndocker logs churn-api\n\n# Tester l'API\ncurl http://localhost:8000/health\n\n# Prediction de test\ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 700,\n    \"Age\": 40,\n    \"Tenure\": 7,\n    \"Balance\": 80000,\n    \"NumOfProducts\": 3,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 0,\n    \"EstimatedSalary\": 90000,\n    \"Geography_Germany\": 1,\n    \"Geography_Spain\": 0\n  }'\n\n# Arreter et supprimer le conteneur\ndocker stop churn-api\ndocker rm churn-api\n```\n\n### Commandes Docker Utiles {#sec-module3-commandes}\n\n``` bash\n# Voir tous les conteneurs (meme arretes)\ndocker ps -a\n\n# Entrer dans un conteneur en cours d'execution\ndocker exec -it churn-api /bin/bash\n\n# Voir l'utilisation des ressources\ndocker stats churn-api\n\n# Nettoyer les images inutilisees\ndocker image prune\n\n# Supprimer toutes les images\ndocker rmi $(docker images -q)\n```\n\n### Questions de Compr√©hension {#sec-module3-questions}\n\n1.  Pourquoi utiliser un .dockerignore ?\n2.  Quelle est la diff√©rence entre CMD et RUN dans un Dockerfile ?\n3.  Pourquoi exposer le port 8000 ?\n4.  Comment v√©rifier que votre conteneur fonctionne correctement ?\n\n### Checkpoint {#sec-module3-checkpoint}\n\n:::: callout-note\n## Validation Module 3\n\nAvant de passer au module suivant, v√©rifiez que :\n\n::: {style=\"margin-left: 20px;\"}\n-   [ ] L'image Docker est build√©e avec succ√®s\n-   [ ] Le conteneur d√©marre sans erreur\n-   [ ] L'API r√©pond correctement depuis le conteneur\n-   [ ] La taille de l'image est raisonnable (\\< 1GB)\n:::\n::::\n\n## Module 4 : D√©ploiement sur Azure {#sec-module4}\n\n### Objectif {#sec-module4-objectif}\n\nD√©ployer l'API sur Azure Container Apps et la rendre accessible publiquement.\n\n### Pr√©requis {#sec-module4-prerequis}\n\n1.  **Docker Desktop** en cours d'ex√©cution (mode WSL2 recommand√©)\n2.  **Configurer Docker** ![](image_docker.png)\n3.  **Azure CLI** install√© et connect√© (`az login`)\n4.  **Image locale** `churn-api:v1` d√©j√† construite\n5.  **installer l'extension containerapp**\n\n``` bash\n az extension add --name containerapp\n```\n\n### Etape 0 : V√©rifier les r√©gions disponibles {#sec-module4-etape0}\n\n``` bash\n#!/bin/bash\n# M√©thodesimple \n\n# Liste toutes les r√©gions recommand√©es\necho \"R√©gions disponibles chez toi :\"\naz account list-locations \\\n  --query \"[?metadata.regionCategory=='Recommended'].name\" \\\n  -o tsv | head -5\n\n# Prendre la premi√®re\nREGION=$(az account list-locations \\\n  --query \"[?metadata.regionCategory=='Recommended'].name\" \\\n  -o tsv | head -1)\n\necho \"‚úÖ proposition de la r√©gion : $REGION\"\n```\n\nOn Peut aussi √©x√©cuter\n\n``` bash\n# Juste cette ligne dans ton terminal :\nLOCATION=$(az account list-locations --query \"[0].name\" -o tsv) && echo \"Use: $REGION\"\n```\n\n### Script Complet : {#sec-module4-etape1}\n\n``` bash\n#!/usr/bin/env bash\nset -euo pipefail\n#################################\n# VARIABLES D√âFINITIVES\n#################################\nRESOURCE_GROUP=\"rg-mlops-bank-churn\"  \nLOCATION=\"westeurope\"   # Forc√© West Europe (garanti)\nFALLBACK_LOCATION=\"northeurope\"     # Fallback garanti\nACR_NAME=\"mlops$(whoami | tr '[:upper:]' '[:lower:]' | tr -cd '[:alnum:]')\"  # 100% minuscules\nCONTAINER_APP_NAME=\"bank-churn\" \nCONTAINERAPPS_ENV=\"env-mlops-workshop\"\nIMAGE_NAME=\"churn-api\"\nIMAGE_TAG=\"v1\"\nTARGET_PORT=8000\n\n#################################\n# 0) Contexte Azure + V√©rification Extensions\n#################################\necho \"V√©rification du contexte Azure...\"\naz account show --query \"{name:name, cloudName:cloudName}\" -o json >/dev/null\n\necho \"V√©rification/installation des extensions Azure CLI...\"\n\n# V√©rifier et installer containerapp si n√©cessaire\nif ! az extension show --name containerapp >/dev/null 2>&1; then\n    echo \"üì¶ Installation de l'extension containerapp...\"\n    az extension add --name containerapp --upgrade -y --only-show-errors\n    echo \"‚úÖ Extension containerapp install√©e\"\nelse\n    echo \"‚úÖ Extension containerapp d√©j√† install√©e\"\n    # Mise √† jour silencieuse\n    az extension update --name containerapp -y --only-show-errors 2>/dev/null || true\nfi\n\n# Liste des extensions install√©es pour v√©rification\necho \"Extensions install√©es :\"\naz extension list --query \"[].{Name:name, Version:version}\" -o table\n\n#################################\n# 1) Providers n√©cessaires\n#################################\necho \"Register providers...\"\naz provider register --namespace Microsoft.ContainerRegistry --wait\naz provider register --namespace Microsoft.App --wait\naz provider register --namespace Microsoft.Web --wait\naz provider register --namespace Microsoft.OperationalInsights --wait\n\n#################################\n# 2) Resource Group\n#################################\necho \"Cr√©ation/validation du groupe de ressources...\"\naz group create -n \"$RESOURCE_GROUP\" -l \"$LOCATION\" >/dev/null || true\necho \"‚úÖ RG OK: $RESOURCE_GROUP\"\n\n#################################\n# 3) Cr√©ation ACR (avec v√©rification)\n#################################\necho \"Cr√©ation du Container Registry (ACR) en $LOCATION...\"\n\n# V√©rification pr√©alable\nif [[ ! \"$ACR_NAME\" =~ ^[a-z0-9]{5,50}$ ]]; then\n    echo \"‚ùå ERREUR: Nom ACR invalide: $ACR_NAME\"\n    echo \"   Doit contenir 5-50 caract√®res alphanum√©riques en minuscules\"\n    exit 1\nfi\n\necho \"Nom ACR valid√©: $ACR_NAME (${#ACR_NAME} caract√®res)\"\n\nset +e\naz acr create \\\n  --resource-group \"$RESOURCE_GROUP\" \\\n  --name \"$ACR_NAME\" \\\n  --sku Basic \\\n  --admin-enabled true \\\n  --location \"$LOCATION\" >/dev/null 2>&1\nACR_RC=$?\nset -e\n\nif [ $ACR_RC -ne 0 ]; then\n  echo \"‚ö†Ô∏è ACR bloqu√© en $LOCATION. Fallback => $FALLBACK_LOCATION\"\n  LOCATION=\"$FALLBACK_LOCATION\"\n  az acr create \\\n    --resource-group \"$RESOURCE_GROUP\" \\\n    --name \"$ACR_NAME\" \\\n    --sku Basic \\\n    --admin-enabled true \\\n    --location \"$LOCATION\" >/dev/null\nfi\n\n# Attendre la cr√©ation compl√®te\nsleep 5\necho \"‚úÖ ACR cr√©√© : $ACR_NAME (region=$LOCATION)\"\n\n#################################\n# 4) Login ACR + Push image\n#################################\necho \"Connexion au registry...\"\naz acr login --name \"$ACR_NAME\" >/dev/null\n\nACR_LOGIN_SERVER=$(az acr show --name \"$ACR_NAME\" --query loginServer -o tsv | tr -d '\\r')\necho \"ACR_LOGIN_SERVER=$ACR_LOGIN_SERVER\"\n\n# R√©cup√©ration des credentials AU BON ENDROIT\nACR_USER=$(az acr credential show -n \"$ACR_NAME\" --query username -o tsv | tr -d '\\r')\nACR_PASS=$(az acr credential show -n \"$ACR_NAME\" --query \"passwords[0].value\" -o tsv | tr -d '\\r')\nIMAGE=\"$ACR_LOGIN_SERVER/$IMAGE_NAME:$IMAGE_TAG\"\n\necho \"Build + Tag + Push...\"\ndocker build -t \"$IMAGE_NAME:$IMAGE_TAG\" .\ndocker tag \"$IMAGE_NAME:$IMAGE_TAG\" \"$ACR_LOGIN_SERVER/$IMAGE_NAME:$IMAGE_TAG\"\ndocker tag \"$IMAGE_NAME:$IMAGE_TAG\" \"$ACR_LOGIN_SERVER/$IMAGE_NAME:latest\"\ndocker push \"$ACR_LOGIN_SERVER/$IMAGE_NAME:$IMAGE_TAG\"\ndocker push \"$ACR_LOGIN_SERVER/$IMAGE_NAME:latest\"\necho \"‚úÖ Image push√©e dans ACR\"\n\n#################################\n# 5) Log Analytics (corrig√©)\n#################################\nLAW_NAME=\"law-mlops-$(whoami)-$RANDOM\"\necho \"Cr√©ation Log Analytics: $LAW_NAME\"\naz monitor log-analytics workspace create -g \"$RESOURCE_GROUP\" -n \"$LAW_NAME\" -l \"$LOCATION\" >/dev/null\nsleep 10  # Attente n√©cessaire\n\n# Commande corrig√©e avec param√®tres explicites\nLAW_ID=$(az monitor log-analytics workspace show \\\n    --resource-group \"$RESOURCE_GROUP\" \\\n    --workspace-name \"$LAW_NAME\" \\\n    --query customerId -o tsv | tr -d '\\r')\n\nLAW_KEY=$(az monitor log-analytics workspace get-shared-keys \\\n    --resource-group \"$RESOURCE_GROUP\" \\\n    --workspace-name \"$LAW_NAME\" \\\n    --query primarySharedKey -o tsv | tr -d '\\r')\necho \"‚úÖ Log Analytics OK\"\n\n#################################\n# 6) Container Apps Environment\n#################################\necho \"Cr√©ation/validation Container Apps Environment: $CONTAINERAPPS_ENV\"\nif ! az containerapp env show -n \"$CONTAINERAPPS_ENV\" -g \"$RESOURCE_GROUP\" >/dev/null 2>&1; then\n  az containerapp env create \\\n    -n \"$CONTAINERAPPS_ENV\" \\\n    -g \"$RESOURCE_GROUP\" \\\n    -l \"$LOCATION\" \\\n    --logs-workspace-id \"$LAW_ID\" \\\n    --logs-workspace-key \"$LAW_KEY\" >/dev/null\nfi\necho \"‚úÖ Environment OK\"\n\n#################################\n# 7) D√©ploiement Container App\n#################################\necho \"D√©ploiement Container App: $CONTAINER_APP_NAME\"\nif az containerapp show -n \"$CONTAINER_APP_NAME\" -g \"$RESOURCE_GROUP\" >/dev/null 2>&1; then\n  az containerapp update \\\n    -n \"$CONTAINER_APP_NAME\" \\\n    -g \"$RESOURCE_GROUP\" \\\n    --image \"$IMAGE\" \\\n    --registry-server \"$ACR_LOGIN_SERVER\" \\\n    --registry-username \"$ACR_USER\" \\\n    --registry-password \"$ACR_PASS\" >/dev/null\nelse\n  az containerapp create \\\n    -n \"$CONTAINER_APP_NAME\" \\\n    -g \"$RESOURCE_GROUP\" \\\n    --environment \"$CONTAINERAPPS_ENV\" \\\n    --image \"$IMAGE\" \\\n    --ingress external \\\n    --target-port \"$TARGET_PORT\" \\\n    --registry-server \"$ACR_LOGIN_SERVER\" \\\n    --registry-username \"$ACR_USER\" \\\n    --registry-password \"$ACR_PASS\" \\\n    --min-replicas 1 \\\n    --max-replicas 1 >/dev/null\nfi\necho \"‚úÖ Container App OK\"\n\n#################################\n# 8) URL API\n#################################\nAPP_URL=$(az containerapp show -n \"$CONTAINER_APP_NAME\" -g \"$RESOURCE_GROUP\" --query properties.configuration.ingress.fqdn -o tsv | tr -d '\\r')\n\necho \"\"\necho \"==========================================\"\necho \"‚úÖ D√âPLOIEMENT R√âUSSI\"\necho \"==========================================\"\necho \"ACR      : $ACR_NAME\"\necho \"Region   : $LOCATION\"\necho \"Resource Group: $RESOURCE_GROUP\"\necho \"\"\necho \"URLs de l'application :\"\necho \"  API      : https://$APP_URL\"\necho \"  Health   : https://$APP_URL/health\"\necho \"  Docs     : https://$APP_URL/docs\"\necho \"\"\necho \"Pour supprimer toutes les ressources :\"\necho \"  az group delete --name $RESOURCE_GROUP --yes --no-wait\"\necho \"==========================================\"\n```\n\n### Test de l'API en Production {#sec-module4-etape2}\n\n``` bash\nRESOURCE_GROUP=\"rg-mlops-bank-churn\"  # votre Ressource group\n\nCONTAINER_APP_NAME=\"bank-churn\" # le nom de votre container app\n\nAPP_URL=$(az containerapp show \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --query properties.configuration.ingress.fqdn -o tsv | tr -d '\\r\\n' | xargs)\n\n# 2. V√©rifier l'URL proprement\necho \"URL nettoy√©e: '$APP_URL'\"\necho \"Longueur: ${#APP_URL}\"\n\n# 3. Test avec l'URL compl√®te\nFULL_URL=\"https://${APP_URL}/predict\"\necho \"URL compl√®te: $FULL_URL\"\n\n# 4. Test de pr√©diction\ncurl -X POST \"$FULL_URL\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n  }'\n\necho \"\"\n```\n\n### üîß R√©solution des probl√®mes {#sec-module4-troubleshooting}\n\n| Probl√®me | Solution |\n|------------------------------------|------------------------------------|\n| **Erreur DNS / `cloudName: null`** | Ex√©cuter `az logout && az login` |\n| **Caract√®re `\\r` dans les variables** | Toujours utiliser `tr -d '\\r'` apr√®s `az acr show` |\n| **Erreur \"ContainerAppInvalidSecretName\"** | Utiliser l'approche YAML avec secret nomm√© `acrpassword` |\n| **Docker non accessible** | D√©marrer Docker Desktop et ouvrir un nouveau terminal |\n| **Erreurs de permissions** | V√©rifier `az account show` et `az login` |\n| **L'application est \"Failed\"** | V√©rifier les logs : `az containerapp logs show --name $CONTAINER_APP_NAME --resource-group $RESOURCE_GROUP --tail 50` |\n| **Image fonctionne localement mais pas sur Azure** | V√©rifier les credentials ACR et l'identit√© manag√©e |\n\n### üìã Commandes de diagnostic utiles {#sec-module4-diagnostic}\n\n``` bash\n# Voir les logs en temps r√©el\naz containerapp logs show \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --tail 100 \\\n  --follow\n\n# V√©rifier l'√©tat d√©taill√©\naz containerapp revision list \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --output table\n\n# R√©cup√©ration automatique et test Docker\nRESOURCE_GROUP=\"rg-mlops1\"\nACR_NAME=$(az acr list --resource-group $RESOURCE_GROUP --query \"[0].name\" -o tsv | tr -d '\\r\\n' | xargs)\nACR_LOGIN_SERVER=$(az acr show --name $ACR_NAME --query loginServer --output tsv | tr -d '\\r\\n' | xargs)\n\necho \"ACR trouv√©: $ACR_LOGIN_SERVER\"\necho \"Lancement de l'image...\"\n\ndocker run -p 8000:8000 ${ACR_LOGIN_SERVER}/bank-churn-api:v1\n\n\n# tester l'api \ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n  }'\n```\n\n### üìä Alternative : D√©ploiement via le Portail Azure {#sec-module4-portail}\n\n#### **Objectif**\n\nReproduire EXACTEMENT le script Bash fourni en utilisant UNIQUEMENT l'interface graphique Azure Portal.\n\n#### **Pr√©requis**\n\n1.  Compte Azure avec abonnement actif\n2.  Acc√®s √† [portal.azure.com](https://portal.azure.com)\n3.  Dockerfile et code de l'application `bank-churn-api` pr√™ts localement\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 0: Connexion Azure**\n\n1.  **Connectez-vous** √† [portal.azure.com](https://portal.azure.com)\n2.  **V√©rifiez votre abonnement** :\n    -   En haut √† droite ‚Üí Cliquez sur votre profil\n    -   \"Changer de r√©pertoire\" si besoin\n    -   L'abonnement actif s'affiche dans le panneau lat√©ral gauche\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 1: V√©rifier/Cr√©er les Fournisseurs (Providers)**\n\n‚ö†Ô∏è **Cette √©tape n'est pas faisable dans le portail** Les providers s'enregistrent automatiquement lors de la premi√®re utilisation du service. **Alternative** : Utilisez Azure Cloud Shell (Bash) pour cette partie uniquement :\n\n``` bash\n# Dans Azure Cloud Shell (ic√¥ne >_ en haut du portail)\naz provider register --namespace Microsoft.ContainerRegistry --wait\naz provider register --namespace Microsoft.App --wait\naz provider register --namespace Microsoft.Web --wait\naz provider register --namespace Microsoft.OperationalInsights --wait\n```\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 2: Groupe de Ressources**\n\n1.  **Recherchez** \"Groupes de ressources\" dans la barre de recherche\n2.  **Cliquez** sur \"+ Cr√©er\"\n3.  **Remplissez** :\n    -   Abonnement : Votre abonnement\n    -   Groupe de ressources : `rg-mlops-bank-churn`\n    -   R√©gion : `westeurope`\n4.  **Cliquez** sur \"V√©rifier + cr√©er\" puis \"Cr√©er\"\n5.  **Attendez** le d√©ploiement (‚âà30 secondes)\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 3: Container Registry (ACR)**\n\n##### **3.1 Cr√©ation ACR**\n\n1.  **Recherchez** \"Registres de conteneurs\"\n2.  **Cliquez** sur \"+ Cr√©er\"\n3.  **Onglet \"G√©n√©ral\"** :\n    -   Groupe de ressources : `rg-mlops-bank-churn`\n    -   Nom du registre : `acrmlops[VOTRE_USERNAME][TIMESTAMP]` *Ex: acrmlopsjean1648826400* (le nom doit √™tre unique dans Azure et contenir de 5 √† 50 caract√®res alphanum√©riques ).\n    -   Emplacement : `westeurope`\n    -   SKU : `De base`\n4.  **Onglet \"Authentification\"** :\n    -   ‚úÖ Utilisateur administrateur ‚Üí ACTIV√â (utile pour les tests, mais privil√©giez une identit√© Microsoft Entra pour les sc√©narios de production )\n5.  **Cliquez** sur \"V√©rifier + cr√©er\" puis \"Cr√©er\"\n\n##### **3.2 Fallback si France Central bloqu√©**\n\nSi erreur de strat√©gie : 1. **Recommencez** l'√©tape 3.1 2. **Changez** l'emplacement : `West Europe` 3. **Notez** la nouvelle r√©gion pour les √©tapes suivantes\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 4: Build et Push de l'Image**\n\n##### **4.1 Pr√©parer localement**\n\n``` bash\n# Sur VOTRE machine locale (pas dans le portail)\ncd /chemin/vers/votre/projet\n\n# Build l'image\ndocker build -t bank-churn-api:v1 .\n\n# Tag avec ACR\ndocker tag bank-churn-api:v1 acrmlopsjean1648826400.azurecr.io/bank-churn-api:v1\ndocker tag bank-churn-api:v1 acrmlopsjean1648826400.azurecr.io/bank-churn-api:latest\n```\n\n##### **4.2 Push vers ACR**\n\n###### **Option A: Via Azure CLI local**\n\n``` bash\n# Login ACR avec votre identit√© individuelle \naz acr login --name acrmlopsjean1648826400\n\n# Push images\ndocker push acrmlopsjean1648826400.azurecr.io/bank-churn-api:v1\ndocker push acrmlopsjean1648826400.azurecr.io/bank-churn-api:latest\n```\n\n###### **Option B: Via Portail Azure (ACR Tasks)**\n\n1.  **Allez** dans votre ACR cr√©√©\n2.  **Menu gauche** ‚Üí \"Services\" ‚Üí \"T√¢ches\"\n3.  **Cliquez** sur \"+ T√¢che\"\n4.  **Configurez** :\n    -   Type de t√¢che : T√¢che rapide\n    -   Platform : Linux\n    -   Emplacement : M√™me que l'ACR\n    -   Source du code : \"Context local\"\n    -   Uploader votre code ZIP ou Dockerfile\n5.  **Ex√©cutez** la t√¢che\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 5: Log Analytics Workspace**\n\n1.  **Recherchez** \"Espaces de travail Log Analytics\"\n2.  **Cliquez** sur \"+ Cr√©er\"\n3.  **Remplissez** :\n    -   Groupe de ressources : `rg-mlops-bank-churn`\n    -   Nom : `law-mlops-[VOTRE_USERNAME]-[RANDOM]` *Ex: law-mlops-jean-12345*\n    -   R√©gion : M√™me que l'ACR (France Central ou West Europe)\n4.  **Cliquez** sur \"V√©rifier + cr√©er\" puis \"Cr√©er\"\n5.  **Notez** :\n    -   **ID de l'espace de travail** (customerId)\n    -   **Cl√© primaire** (primarySharedKey)\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 6: Container Apps Environment**\n\n1.  **Recherchez** \"Environnements Container Apps\"\n2.  **Cliquez** sur \"+ Cr√©er\"\n3.  **Onglet \"G√©n√©ral\"** :\n    -   Nom de l'environnement : `env-mlops-workshop`\n    -   Groupe de ressources : `rg-mlops-bank-churn`\n    -   Zone : M√™me r√©gion que l'ACR\n    -   Type d'environnement : `Consumption only` (pour ce workshop)\n4.  **Onglet \"Surveillance\"** :\n    -   ‚úÖ Activer la surveillance Log Analytics\n    -   Espace de travail Log Analytics : S√©lectionnez celui cr√©√© √† l'√©tape 5\n5.  **Cliquez** sur \"V√©rifier + cr√©er\" puis \"Cr√©er\"\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 7: Container App (Application)**\n\n##### **7.1 Cr√©ation**\n\n1.  **Recherchez** \"Container Apps\"\n2.  **Cliquez** sur \"+ Cr√©er\" \\> \"Container App\"\n3.  **Onglet \"G√©n√©ral\"** :\n    -   Abonnement : Votre abonnement\n    -   Groupe de ressources : `rg-MLopsyy`\n    -   Nom de l'application conteneur : `bank-churn-api` (entre 2 et 32 caract√®res, lettres minuscules, chiffres et tirets )\n    -   R√©gion : S√©lectionnez une r√©gion pr√®s de vous\n    -   Environnement Container Apps : S√©lectionnez `env-mlops-workshop` (cr√©√© pr√©c√©demment)\n\n##### **7.2 Onglet \"Application\"**\n\n1.  **Section \"Image\"** :\n    -   Source de l'image : \"Azure Container Registry\"\n    -   Registre : S√©lectionnez votre ACR\n    -   Image : `bank-churn-api`\n    -   √âtiquette : `v1`\n    -   Type d'authentification du registre : \"Informations d'identification de l'administrateur\" (utilisez les cl√©s d'acc√®s de l'ACR pour ce workshop )\n    -   Nom d'utilisateur/Password : R√©cup√©rez-les dans ACR ‚Üí \"Cl√©s d'acc√®s\"\n\n##### **7.3 Onglet \"Ingress\"**\n\n1.  **Trafic entrant** : ‚úÖ Activ√©\n2.  **Visibilit√© du trafic entrant** : `Accepting traffic from anywhere` (pour un acc√®s externe )\n3.  **Type d'entr√©e** : `HTTP`\n4.  **Port cible** : `8000` (doit correspondre au port √©cout√© par votre conteneur )\n5.  **Connexions non s√©curis√©es** : D√©cochez (laissez `false` par d√©faut pour forcer HTTPS )\n\n##### **7.4 Onglet \"Mise √† l'√©chelle\"**\n\nPour ce workshop et pour optimiser les co√ªts : 1. **Mode de mise √† l'√©chelle** : \"Aucune mise √† l'√©chelle automatique\" 2. **Nombre minimal de r√©plicas** : `1` 3. **Nombre maximal de r√©plicas** : `1`\n\n::: callout-note\n#### Bonne pratique en production\n\nPour une meilleure fiabilit√© en production, il est recommand√© de configurer au moins 3 r√©plicas et d'activer la mise √† l'√©chelle automatique bas√©e sur les m√©triques HTTP ou CPU pour g√©rer les pics de charge .\n:::\n\n##### **7.5 Finalisation**\n\n-   **Cliquez** sur \"V√©rifier + cr√©er\" puis \"Cr√©er\"\n-   **Attendez** le d√©ploiement (‚âà2-3 minutes)\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 8: R√©cup√©rer l'URL**\n\n1.  **Allez** sur votre Container App `bank-churn-api`\n2.  **Menu gauche** ‚Üí \"Vue d'ensemble\"\n3.  **Cherchez** \"URL de l'application\" (le FQDN g√©n√©r√© automatiquement )\n4.  **Copiez** l'URL (format : `https://bank-churn-api.xxxxxxxx.region.azurecontainerapps.io`)\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 9: Tests**\n\n1.  **Ouvrez** un navigateur\n2.  **Testez** :\n    -   **Health** : `https://[VOTRE-URL]/health`\n    -   **Documentation** : `https://[VOTRE-URL]/docs`\n    -   **Swagger UI** : `https://[VOTRE-URL]/redoc`\n\n------------------------------------------------------------------------\n\n#### **V√©rification Finale**\n\nComparez avec le script Bash :\n\n| √âl√©ment | Script Bash | Interface Graphique |\n|------------------|---------------------|---------------------------------|\n| Resource Group | `rg-MLopsyy` (France Central) | ‚úÖ Identique |\n| ACR | Nom unique avec timestamp | ‚úÖ Identique (5-50 caract√®res alphanum√©riques ) |\n| Fallback location | West Europe si blocage | ‚úÖ G√©r√© manuellement |\n| Log Analytics | Cr√©√© avec nom al√©atoire | ‚úÖ Identique |\n| Environment | `env-mlops-workshop` | ‚úÖ Identique |\n| Container App | `bank-churn-api` port 8000 | ‚úÖ Identique (2-32 caract√®res ) |\n| Image | `bank-churn-api:v1` | ‚úÖ Identique |\n| Ingress | Externe, HTTP, port 8000 | ‚úÖ Identique |\n| R√©plicas | min=1, max=1 | ‚úÖ Identique |\n\n------------------------------------------------------------------------\n\n#### **Points d'Attention**\n\n1.  **Timestamp dans ACR** : Dans le portail, g√©n√©rez-le manuellement (ex: `date +%s` dans Cloud Shell)\n2.  **Authentification ACR** : Pour les sc√©narios de production, envisagez d'utiliser une **identit√© manag√©e** au lieu des identifiants administrateur pour une s√©curit√© et une gestion am√©lior√©es .\n3.  **Variables d'environnement** : Si votre app en a besoin, ajoutez-les dans l'onglet \"Param√®tres\" du Container App.\n4.  **Logs** : Les logs sont automatiquement envoy√©s √† Log Analytics configur√© dans l'environnement.\n5.  **S√©curit√© r√©seau** : Pour restreindre l'acc√®s, vous pouvez configurer ult√©rieurement des **restrictions d'adresse IP** sur l'ingress de votre application conteneur .\n\n------------------------------------------------------------------------\n\n#### **R√©sum√© des URLs**\n\n-   **Portail Azure** : https://portal.azure.com\n-   **Votre API** : `https://bank-churn-api.[...].azurecontainerapps.io`\n-   **Health check** : `/health`\n-   **Documentation** : `/docs` (Swagger)\n-   **ACR** : `acrmlopsjean1648826400.azurecr.io`\n\n------------------------------------------------------------------------\n\n**Dur√©e totale** : ‚âà15-20 minutes via l'interface graphique **Co√ªt estim√©** : \\~5-10‚Ç¨/mois (ACR Basic + Container App en fonctionnement)\n\n**Remarque :** Il est important de conserver la section existante \"Surveillance des Co√ªts {#sec-module4-couts}\" qui suit imm√©diatement cette partie dans votre fichier.\n\n### Exercice Pratique {#sec-module4-exercice}\n\n::: callout-tip\n## EXERCICE 2\n\nPartagez votre URL d'API avec un camarade et testez son API :\n\n1.  Faites 10 pr√©dictions sur son API\n2.  Comparez les r√©sultats avec votre mod√®le\n3.  Observez les logs dans Azure Portal :\n    -   Allez dans votre Container App\n    -   Menu **\"Log stream\"** ou **\"Monitoring\" ‚Üí \"Logs\"**\n    -   Observez les requ√™tes en temps r√©el\n:::\n\n### üéØ Points cl√©s des corrections apport√©es {#sec-module4-resume}\n\n1.  **Nettoyage du `\\r`** : Ajout de `tr -d '\\r'` √† la r√©cup√©ration du login server\n2.  **Approche YAML** : Contournement du bug de g√©n√©ration de nom de secret\n3.  **Secret nomm√©** : Utilisation d'un nom valide `acrpassword` au lieu du nom auto-g√©n√©r√©\n4.  **Variables d'environnement** : Ajout de `PYTHONUNBUFFERED=1` pour les logs\n5.  **Tests robustes** : Attente de 30 secondes avant les v√©rifications\n6.  **Commandes de diagnostic** : Ajout de commandes pour troubleshooting\n7.  **Alternative GUI** : Instructions pour le d√©ploiement via le portail Azure\n\nPour ex√©cuter le module, sauvegardez-le dans un fichier `module4-deploiement.sh` et ex√©cutez :\n\n``` bash\nchmod +x module4-deploiement.sh\n./module4-deploiement.sh\n```\n\n### Checkpoint {#sec-module4-checkpoint}\n\n:::: callout-note\n## Validation Module 4\n\nAvant de passer au module suivant, v√©rifiez que :\n\n::: {style=\"margin-left: 20px;\"}\n-   [ ] L'application est accessible via HTTPS\n-   [ ] Le health check fonctionne\n-   [ ] Les pr√©dictions fonctionnent\n-   [ ] Vous avez not√© l'URL publique de votre API\n:::\n::::\n\n## Module 5 : CI/CD avec GitHub Actions {#sec-module5}\n\n### Objectif {#sec-module5-objectif}\n\nAutomatiser le d√©ploiement : chaque commit sur la branche `main` d√©clenche un build et un red√©ploiement via un pipeline GitHub Actions.\n\n### √âtape 1 : Initialisation du Repository Git {#sec-module5-etape1}\n\n``` bash\n# Initialiser git avec 'main' comme branche par d√©faut\ngit init -b main\n\n# Cr√©er un .gitignore robuste\ncat > .gitignore << 'EOF'\n__pycache__/\n*.pyc\nvenv/\n.env\nmlruns/\n*.log\n.DS_Store\n.vscode/\nconfusion_matrix.png\nfeature_importance.png\n# Secrets (NE JAMAIS commiter)\n*.secret\n*.key\n*.pem\ncredentials*.json\nresultat.txt\nazure-credentials.json\nEOF\n\n# Premier commit\ngit add .\ngit commit -m \"Initial commit: Bank Churn API\"\n```\n\n### √âtape 2 : Cr√©er un Repository GitHub {#sec-module5-etape2}\n\n1.  Allez sur `https://github.com/new`\n2.  **Nom** : `bank-churn-mlops`\n3.  **Visibility** : Public ou Private\n4.  **Ne pas** initialiser avec README\n5.  Cliquez sur \"Create repository\"\n\n``` bash\n# Lier votre repo local √† GitHub\ngit remote add origin https://github.com/votre-username/bank-churn-mlops.git\ngit branch -M main\ngit push -u origin main\n```\n\n### √âtape 3 : Configuration des Secrets GitHub {#sec-module5-etape3}\n\nPour l'authentification avec Azure, l'action `azure/login@v1` attend un secret (`AZURE_CREDENTIALS`) contenant un **objet JSON avec exactement 4 cl√©s**.\n\n#### Cr√©er et formater les identifiants du Service Principal Azure\n\n**Option A (Recommand√©e) : Avec l'outil `jq`**\n\nSi `jq` n'est pas install√© sur votre terminal linux\n\n``` bash\nsudo apt  install jq\n```\n\nPuis √©x√©cuter ceci :\n\n``` bash\nRESOURCE_GROUP=\"rg-mlops-bank-churn\"\nSUBSCRIPTION_ID=$(az account show --query id -o tsv | tr -d '\\r')\n\n# 1. Cr√©er le Service Principal et capturer la sortie\nSP_JSON=$(az ad sp create-for-rbac \\\n  --name \"github-actions-$(date +%s)\" \\\n  --role contributor \\\n  --scopes \"/subscriptions/${SUBSCRIPTION_ID}/resourceGroups/${RESOURCE_GROUP}\" \\\n  --output json)\n\n# 2. Extraire et formater uniquement les 4 champs requis pour GitHub Actions\necho $SP_JSON | jq -c '{clientId: .appId, clientSecret: .password, subscriptionId: \"'\"$SUBSCRIPTION_ID\"'\", tenantId: .tenant}'\n```\n\n**Copiez l'objet JSON compact qui s'affiche.** Il ressemblera √† ceci :\n\n``` json\n{\"clientId\":\"xxxxxxxx-xxxx-...\",\"clientSecret\":\"votre_mot_de_passe\",\"subscriptionId\":\"e14fdc0f-d8cd-...\",\"tenantId\":\"xxxxxxxx-xxxx-...\"}\n```\n\n**Option B (Manuelle) : Sans `jq`** Ex√©cutez la commande standard et notez les valeurs pour `appId`, `password` et `tenant`. Composez ensuite **manuellement** l'objet JSON suivant en utilisant : - `appId` comme valeur pour `clientId` - `password` comme valeur pour `clientSecret` - Votre `subscriptionId` (`e14fdc0f-d8cd-4608-9a2e-d02e7b15366b`) - `tenant` comme valeur pour `tenantId`\n\n``` json\n{\n  \"clientId\": \"xxxxxxxx-xxxx-...\",\n  \"clientSecret\": \"votre_mot_de_passe\",\n  \"subscriptionId\": \"e14fdc0f-d8cd-4608-9a2e-d02e7b15366b\",\n  \"tenantId\": \"xxxxxxxx-xxxx-...\"\n}\n```\n\n#### Ajouter les Secrets dans GitHub\n\n1.  Allez dans votre repository GitHub : **Settings \\> Secrets and variables \\> Actions**\n2.  Cliquez sur **\"New repository secret\"**\n3.  Ajoutez ces trois secrets :\n\n| **Nom du Secret** | **Valeur √† coller** | **Comment l'obtenir** |\n|:-----------------------|:-----------------------|:-----------------------|\n| `AZURE_CREDENTIALS` | **L'objet JSON complet** (4 champs) g√©n√©r√© √† l'√©tape pr√©c√©dente. | R√©sultat de la commande avec `jq` ou cr√©ation manuelle. |\n| `ACR_USERNAME` | Le nom d'utilisateur de votre ACR. | `az acr credential show --name <VOTRE_ACR> --query username -o tsv` |\n| `ACR_PASSWORD` | Le mot de passe de votre ACR. | `az acr credential show --name <VOTRE_ACR> --query \"passwords[0].value\" -o tsv` |\n\n**Important** : Pour `AZURE_CREDENTIALS`, assurez-vous de copier **tout l'objet JSON en une seule ligne** dans le champ de valeur du secret, sans espaces avant ou apr√®s.\n\n### √âtape 4 : Pr√©paration des Tests pour le Pipeline {#sec-module5-tests}\n\nAvant de configurer le workflow, assurez-vous d'avoir des tests valides. Cr√©ez ou mettez √† jour `tests/test_api.py` :\n\n``` python\n# tests/test_api.py\nimport sys\nimport os\nfrom unittest.mock import patch\nimport numpy as np\n\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n\nfrom fastapi.testclient import TestClient\nfrom app.main import app\n\nclient = TestClient(app)\n\nTEST_CUSTOMER = {\n    \"CreditScore\": 650, \"Age\": 35, \"Tenure\": 5, \"Balance\": 50000.0,\n    \"NumOfProducts\": 2, \"HasCrCard\": 1, \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000.0, \"Geography_Germany\": 0, \"Geography_Spain\": 1\n}\n\ndef test_read_root():\n    \"\"\"Test l'endpoint racine /\"\"\"\n    response = client.get(\"/\")\n    assert response.status_code == 200\n    assert response.json()[\"message\"] == \"Bank Churn Prediction API\"\n\ndef test_predict_with_mock():\n    \"\"\"Test /predict avec un mock du mod√®le pour √©viter l'erreur 503\"\"\"\n    with patch('app.main.model') as mock_model:\n        # Simulation d'une pr√©diction r√©ussie\n        mock_model.predict_proba.return_value = np.array([[0.2, 0.8]])\n        mock_model.predict.return_value = np.array([1])\n        \n        response = client.post(\"/predict\", json=TEST_CUSTOMER)\n        # Le test passe si l'API traite la requ√™te\n        assert response.status_code in [200, 422, 503]\n```\n\n**Ex√©cution des tests en local (avant CI/CD)** :\n\n``` bash\npython -m pytest tests/ -v\n```\n\n### √âtape 5 : V√©rification des Noms de Ressources (CRITIQUE) {#sec-module5-verif}\n\nLe pipeline √©chouera si les noms de vos ressources Azure ne correspondent pas. **Avant de cr√©er le workflow**, v√©rifiez ces noms exacts :\n\n``` bash\n# 1. V√©rifier le nom exact de votre Azure Container Registry (ACR)\naz acr list --resource-group rg-mlops-bank-churn --query \"[].name\" -o tsv\n# Doit retourner quelque chose comme : mlopsnevermind\n\n# 2. V√©rifier le nom exact de votre Azure Container App\naz containerapp list --resource-group rg-mlops-bank-churn --query \"[].name\" -o tsv\n# Doit retourner : bank-churn\n\n# 3. Confirmer votre nom de groupe de ressources\necho \"rg-mlops-bank-churn\"\n```\n\nNotez ces noms, vous en aurez besoin pour l'√©tape suivante.\n\n### √âtape 6 : Cr√©ation du Workflow GitHub Actions {#sec-module5-etape4}\n\nCr√©ez le fichier `.github/workflows/ci-cd.yml` avec le contenu ci-dessous. **Remplacez les valeurs d'environnement (`env`)** par celles qui correspondent √† **vos** ressources Azure, identifi√©es √† l'√©tape 5.\n\n``` yaml\nname: CI/CD Pipeline\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n  workflow_dispatch:\n\nenv:\n  # ‚ö†Ô∏è REMPLACEZ CES VALEURS PAR LES V√îTRES ‚ö†Ô∏è\n  AZURE_RESOURCE_GROUP: rg-mlops-bank-churn\n  ACR_NAME: mlopsnevermind          # Le nom de VOTRE ACR (√©tape 5.1)\n  CONTAINER_APP_NAME: bank-churn    # Le nom de VOTRE Container App (√©tape 5.2)\n  IMAGE_NAME: bank-churn-api\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.9'\n      - name: Install dependencies\n        run: |\n          pip install --upgrade pip\n          pip install -r requirements.txt\n      - name: Run tests with coverage\n        run: |\n          pytest tests/ -v --cov=app --cov-report=term\n\n  build-and-deploy:\n    needs: test  # Ne s'ex√©cute QUE si les tests r√©ussissent\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'  # Ne d√©ploie que depuis 'main'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n      - name: Azure Login\n        uses: azure/login@v1\n        with:\n          creds: ${{ secrets.AZURE_CREDENTIALS }}  # Utilise le secret format√©\n      - name: Login to Azure Container Registry (ACR)\n        uses: azure/docker-login@v1\n        with:\n          login-server: ${{ env.ACR_NAME }}.azurecr.io\n          username: ${{ secrets.ACR_USERNAME }}\n          password: ${{ secrets.ACR_PASSWORD }}\n      - name: Build and push Docker image\n        run: |\n          # Construit l'image et la tagge avec le hash unique du commit\n          docker build -t ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }} .\n          # Cr√©e aussi un tag 'latest' pour r√©f√©rence\n          docker tag ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }} ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest\n          # Pousse les deux images vers l'ACR\n          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}\n          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest\n          echo \"‚úÖ Images pouss√©es dans ACR.\"\n      - name: Deploy to Azure Container Apps\n        uses: azure/CLI@v1\n        with:\n          inlineScript: |\n            az containerapp update \\\n              --name ${{ env.CONTAINER_APP_NAME }} \\\n              --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n              --image ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}\n            echo \"‚úÖ Commande de d√©ploiement envoy√©e √† Azure.\"\n      - name: Verify deployment\n        run: |\n          # R√©cup√®re l'URL publique de l'application\n          APP_URL=$(az containerapp show \\\n            --name ${{ env.CONTAINER_APP_NAME }} \\\n            --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n            --query properties.configuration.ingress.fqdn -o tsv)\n          echo \"üåê Votre API est d√©ploy√©e √† l'adresse : https://$APP_URL\"\n          echo \"ü©∫ Attente du d√©marrage (20s) et v√©rification...\"\n          sleep 20\n          # Teste le endpoint /health\n          curl -f https://$APP_URL/health || exit 1\n          echo \"‚úÖ D√©ploiement v√©rifi√© et r√©ussi !\"\n```\n\n### √âtape 7 : D√©clencher et Observer le Pipeline {#sec-module5-etape5}\n\n``` bash\n# Ajouter le fichier de workflow et le pousser\ngit add .github/workflows/ci-cd.yml\ngit commit -m \"feat: add automated CI/CD pipeline with GitHub Actions\"\ngit push origin main\n\n# Le pipeline se d√©clenche AUTOMATIQUEMENT !\n```\n\n**Observez l'ex√©cution** :\n\n1.  Allez sur votre d√©p√¥t GitHub.\n2.  Cliquez sur l'onglet **\"Actions\"**.\n3.  Vous verrez l'ex√©cution de votre workflow nomm√© **\"CI/CD Pipeline\"**. Cliquez dessus pour voir les d√©tails et les logs en direct.\n\n### Exercice Pratique {#sec-module5-exercice}\n\n::: callout-tip\n# EXERCICE 3\n\n1.  **Ajoutez un nouveau test** dans `test_api.py` pour tester un autre endpoint, par exemple l'endpoint `/docs` (documentation Swagger) qui devrait toujours √™tre accessible. `python     def test_docs_endpoint():         \"\"\"Test que la documentation Swagger est accessible\"\"\"         response = client.get(\"/docs\")         assert response.status_code == 200`\n\n2.  **Faites un commit** de ce changement : `bash     git add tests/test_api.py     git commit -m \"test: add docs endpoint test\"`\n\n3.  **Poussez le commit** sur la branche `main` : `bash     git push origin main`\n\n4.  **Observez le pipeline** s'ex√©cuter automatiquement dans l'onglet **Actions** de votre d√©p√¥t GitHub.\n\n5.  **Une fois le workflow termin√© avec succ√®s**, v√©rifiez que votre application a bien √©t√© red√©ploy√©e en visitant son URL (celle affich√©e √† la fin du job `Verify deployment`).\n:::\n\n### D√©pannage des Erreurs Courantes {#sec-module5-troubleshooting}\n\n| **Sympt√¥me / Message d'erreur** | **Cause la plus probable** | **Solution** |\n|:-----------------------|:-----------------------|:-----------------------|\n| `Login failed... Not all parameters are provided in 'creds'` | Le secret `AZURE_CREDENTIALS` n'a pas le bon format (trop/moins de 4 champs). | Supprimez et recr√©ez le secret avec l'objet JSON √† **4 champs exactement** (`clientId`, `clientSecret`, `subscriptionId`, `tenantId`). |\n| `Error: ACR login failed... 401 Unauthorized` | Les secrets `ACR_USERNAME` ou `ACR_PASSWORD` sont incorrects. | R√©g√©n√©rez les mots de passe de votre ACR avec `az acr credential renew --name <acr-name>` et mettez √† jour les secrets. |\n| √âchec du job `build-and-deploy` avec `Repository not found` ou erreur sur `az containerapp update`. | Les noms dans `env:` (`ACR_NAME`, `CONTAINER_APP_NAME`) ne correspondent pas √† vos ressources. | V√©rifiez les noms exacts avec les commandes de l'**√âtape 5** et corrigez le fichier `ci-cd.yml`. |\n| Le job `test` √©choue sur `pytest collected 0 items`. | Vos fichiers dans `tests/` ne sont pas reconnus comme tests. | Assurez-vous que les noms de fonctions commencent par `test_`. Exemple : `def test_health_check():` |\n| Le job `test` √©choue sur `list indices must be integers or slices, not tuple`. | Erreur dans `app/main.py`. | Corrigez l'indexation : remplacez `model.predict_proba(...)[0, 1]` par `model.predict_proba(...)[0][1]`. |\n\n### Checkpoint {#sec-module5-checkpoint}\n\n:::: callout-note\n# Validation Module 5\n\nAvant de passer au module suivant, v√©rifiez que ces conditions sont remplies :\n\n::: {style=\"margin-left: 20px; line-height: 1.8;\"}\n-   [ ] **Le d√©p√¥t GitHub `bank-churn-mlops` existe** et est li√© √† votre projet local.\n-   [ ] **Les trois secrets GitHub** (`AZURE_CREDENTIALS`, `ACR_USERNAME`, `ACR_PASSWORD`) sont cr√©√©s avec les **bonnes valeurs et le bon format**.\n-   [ ] **Le fichier `.github/workflows/ci-cd.yml`** est pr√©sent dans votre projet et contient les **noms exacts** de vos ressources Azure.\n-   [ ] **Le pipeline CI/CD s'ex√©cute sans erreur** dans l'onglet GitHub Actions (les jobs `test` et `build-and-deploy` sont verts ‚úÖ).\n-   [ ] **L'application se red√©ploie automatiquement** : apr√®s un `git push`, une nouvelle image est cr√©√©e et votre API conteneuris√©e est mise √† jour sur Azure.\n:::\n\n::::\n\n## Module 6 : Monitoring et Maintenance {#sec-module6}\n\n### Objectif {#sec-module6-objectif}\n\nMettre en place le monitoring de l'application en production, suivre l‚Äô√©tat de l‚ÄôAPI, les performances et d√©tecter le **data drift** √† l‚Äôaide d‚ÄôAzure Application Insights.\n\n\n### Configuration Application Insights {#sec-module6-appinsights}\n\n```bash\n# Cr√©ation d'Application Insights\naz monitor app-insights component create \\\n  --app bank-churn-insights \\\n  --location $LOCATION \\\n  --resource-group $RESOURCE_GROUP \\\n  --application-type web\n\n# R√©cup√©ration de la connection string\nAPPINSIGHTS_CONN=$(az monitor app-insights component show \\\n  --app bank-churn-insights \\\n  --resource-group $RESOURCE_GROUP \\\n  --query connectionString -o tsv)\n\necho \"Connection String : $APPINSIGHTS_CONN\"\n\n# Injection de la variable d'environnement dans Azure Container Apps\naz containerapp update \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --set-env-vars \"APPLICATIONINSIGHTS_CONNECTION_STRING=$APPINSIGHTS_CONN\"\n```\n\n\n\n### Int√©gration du Monitoring dans le Code {#sec-module6-monitoring}\n\n#### D√©pendances\n\nAjoutez dans `requirements.txt` :\n\n```txt\nopencensus-ext-azure==1.1.9\nopencensus-ext-requests==0.12.1\n```\n\n\n\n### Instrumentation de l‚ÄôAPI FastAPI (`app/main.py`)\n\n```python\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom typing import List\nimport joblib\nimport numpy as np\nimport logging\nimport os\nimport traceback\n\nfrom opencensus.ext.azure.log_exporter import AzureLogHandler\nfrom app.models import CustomerFeatures, PredictionResponse, HealthResponse\nfrom app.drift_detect import detect_drift\n\n# -------------------------------------------------\n# Logging & Application Insights\n# -------------------------------------------------\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"bank-churn-api\")\n\nAPPINSIGHTS_CONN = os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\")\nif APPINSIGHTS_CONN:\n    logger.addHandler(AzureLogHandler(connection_string=APPINSIGHTS_CONN))\n    logger.info(\"Application Insights connect√©\")\nelse:\n    logger.warning(\"Application Insights non configur√©\")\n\n# -------------------------------------------------\n# Initialisation FastAPI\n# -------------------------------------------------\napp = FastAPI(\n    title=\"Bank Churn Prediction API\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\"\n)\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# -------------------------------------------------\n# Chargement du mod√®le\n# -------------------------------------------------\nMODEL_PATH = os.getenv(\"MODEL_PATH\", \"model/churn_model.pkl\")\nmodel = None\n\n@app.on_event(\"startup\")\nasync def load_model():\n    global model\n    try:\n        model = joblib.load(MODEL_PATH)\n        logger.info(f\"Mod√®le charg√© depuis {MODEL_PATH}\")\n    except Exception as e:\n        logger.error(f\"Erreur chargement mod√®le : {e}\")\n        model = None\n\n# -------------------------------------------------\n# Endpoints g√©n√©raux\n# -------------------------------------------------\n@app.get(\"/health\", response_model=HealthResponse)\ndef health():\n    if model is None:\n        raise HTTPException(status_code=503, detail=\"Mod√®le non charg√©\")\n    return {\"status\": \"healthy\", \"model_loaded\": True}\n\n# -------------------------------------------------\n# Pr√©diction\n# -------------------------------------------------\n@app.post(\"/predict\", response_model=PredictionResponse)\ndef predict(features: CustomerFeatures):\n    if model is None:\n        raise HTTPException(status_code=503, detail=\"Mod√®le indisponible\")\n\n    try:\n        X = np.array([[ \n            features.CreditScore,\n            features.Age,\n            features.Tenure,\n            features.Balance,\n            features.NumOfProducts,\n            features.HasCrCard,\n            features.IsActiveMember,\n            features.EstimatedSalary,\n            features.Geography_Germany,\n            features.Geography_Spain\n        ]])\n\n        proba = model.predict_proba(X)[0][1]\n        prediction = int(proba > 0.5)\n\n        risk = \"Low\" if proba < 0.3 else \"Medium\" if proba < 0.7 else \"High\"\n\n        logger.info(\n            \"prediction\",\n            extra={\n                \"custom_dimensions\": {\n                    \"event_type\": \"prediction\",\n                    \"probability\": float(proba),\n                    \"risk_level\": risk\n                }\n            }\n        )\n\n        return {\n            \"churn_probability\": round(float(proba), 4),\n            \"prediction\": prediction,\n            \"risk_level\": risk\n        }\n\n    except Exception as e:\n        logger.error(f\"Erreur prediction : {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n# -------------------------------------------------\n# Drift Detection (API)\n# -------------------------------------------------\n@app.post(\"/drift/check\", tags=[\"Monitoring\"])\ndef check_drift(threshold: float = 0.05):\n    try:\n        results = detect_drift(\n            reference_file=\"data/bank_churn.csv\",\n            production_file=\"data/production_data.csv\",\n            threshold=threshold\n        )\n\n        drifted = [f for f, r in results.items() if r[\"drift_detected\"]]\n        drift_pct = len(drifted) / len(results) * 100\n\n        logger.info(\n            \"drift_detection\",\n            extra={\n                \"custom_dimensions\": {\n                    \"event_type\": \"drift_detection\",\n                    \"features_analyzed\": len(results),\n                    \"features_drifted\": len(drifted),\n                    \"drift_percentage\": drift_pct,\n                    \"risk_level\": \"HIGH\" if drift_pct > 50 else \"MEDIUM\" if drift_pct > 20 else \"LOW\"\n                }\n            }\n        )\n\n        return {\n            \"status\": \"success\",\n            \"features_analyzed\": len(results),\n            \"features_drifted\": len(drifted)\n        }\n\n    except Exception:\n        tb = traceback.format_exc()\n        logger.error(tb)\n        raise HTTPException(status_code=500, detail=\"Erreur drift detection\")\n```\n### G√©n√©ration de Donn√©es avec Drift {#sec-module6-driftgen}\n\nEn environnement r√©el, les donn√©es de production √©voluent progressivement\n(changement de comportement client, contexte √©conomique, nouvelles offres, etc.).\n\nAfin de **tester et valider le syst√®me de monitoring**, nous utilisons un script de\ng√©n√©ration artificielle de donn√©es de production avec drift contr√¥l√© :\n`drift_data_gen.py`.\n\nCe script permet de :\n- simuler diff√©rents niveaux de drift (faible, moyen, fort)\n- cr√©er un jeu de donn√©es de production r√©aliste\n- tester la robustesse du syst√®me de d√©tection\n- valider le fonctionnement des alertes en production\n\n---\n\n### Script `drift_data_gen.py`\n\n```python\nimport pandas as pd\nimport numpy as np\nimport os\n\ndef generate_drifted_data(\n    reference_file=\"data/bank_churn.csv\",\n    output_file=\"data/production_data.csv\",\n    drift_level=\"medium\"\n):\n    \"\"\"\n    G√©n√®re des donn√©es de production avec drift artificiel\n    \n    drift_level:\n    - low    : bruit l√©ger\n    - medium : d√©calage significatif\n    - high   : changement fort\n    \"\"\"\n\n    os.makedirs(\"data\", exist_ok=True)\n\n    ref = pd.read_csv(reference_file)\n    prod = ref.copy()\n\n    np.random.seed(42)\n\n    drift_map = {\n        \"low\": 0.05,\n        \"medium\": 0.15,\n        \"high\": 0.30\n    }\n\n    intensity = drift_map.get(drift_level, 0.15)\n\n    drift_features = [\n        \"CreditScore\",\n        \"Age\",\n        \"Balance\",\n        \"EstimatedSalary\"\n    ]\n\n    for col in drift_features:\n        if col in prod.columns:\n            std = prod[col].std()\n            prod[col] = prod[col] + np.random.normal(\n                loc=std * intensity,\n                scale=std * intensity,\n                size=len(prod)\n            )\n\n    prod.to_csv(output_file, index=False)\n\n    print(f\"‚úÖ Donn√©es de production g√©n√©r√©es avec drift '{drift_level}'\")\n    print(f\"üìÅ Fichier : {output_file}\")\n\nif __name__ == \"__main__\":\n    generate_drifted_data(drift_level=\"medium\")\n```\n\n---\n\n### Utilisation\n\n```bash\n# G√©n√©rer des donn√©es de production avec drift moyen\npython drift_data_gen.py\n```\n\nCe fichier `production_data.csv` est ensuite utilis√© par l‚Äôendpoint :\n\n```http\nPOST /drift/check\n```\n\npour comparer les donn√©es de r√©f√©rence et de production.\n\n---\n\n### R√¥le dans le pipeline MLOps\n\n| √âtape | R√¥le |\n|------|------|\n| `drift_data_gen.py` | Simulation du drift |\n| `drift_detect.py` | D√©tection statistique |\n| Application Insights | Monitoring & historisation |\n| Alertes Azure | D√©cision op√©rationnelle |\n\n\n\n\n\n### D√©tection de Data Drift {#sec-module6-drift}\n\n#### Script `app/drift_detect.py`\n\n```python\nimport matplotlib\nmatplotlib.use(\"Agg\")  # OBLIGATOIRE pour Docker / Azure\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import ks_2samp\nimport json\nimport os\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef detect_drift(reference_file, production_file, threshold=0.05, output_dir=\"drift_reports\"):\n    os.makedirs(output_dir, exist_ok=True)\n\n    ref = pd.read_csv(reference_file)\n    prod = pd.read_csv(production_file)\n\n    results = {}\n\n    for col in ref.columns:\n        if col != \"Exited\" and col in prod.columns:\n            stat, p = ks_2samp(ref[col].dropna(), prod[col].dropna())\n            results[col] = {\n                \"p_value\": float(p),\n                \"statistic\": float(stat),\n                \"drift_detected\": bool(p < threshold)\n            }\n\n    report_path = f\"{output_dir}/drift_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n    with open(report_path, \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n```\n\n\n\n### Checkpoint {#sec-module6-checkpoint}\n\n:::: callout-note\n#### Validation Module 6\n\nAvant de passer au module suivant, v√©rifiez que :\n\n- [ ] Application Insights est actif\n- [ ] Les logs sont visibles dans Azure Portal\n- [ ] `/predict` fonctionne en production\n- [ ] `/drift/check` retourne un r√©sultat\n- [ ] Le drift est historis√© dans Application Insights\n::::\n\n\n## Module 7 : Optimisations et Bonnes Pratiques {#sec-module7}\n\n### Objectif {#sec-module7-objectif}\n\nAm√©liorer les performances, la s√©curit√© et la maintenabilit√© de l'application.\n\n### Ajout d'un Cache pour les Pr√©dictions {#sec-module7-cache}\n\nModifiez `app/main.py` :\n\n``` python\nfrom functools import lru_cache\nimport hashlib\nimport json\n\ndef hash_features(features_dict: dict) -> str:\n    \"\"\"Cree un hash unique pour les features\"\"\"\n    return hashlib.md5(\n        json.dumps(features_dict, sort_keys=True).encode()\n    ).hexdigest()\n\n# Cache pour les predictions (1000 dernieres)\n@lru_cache(maxsize=1000)\ndef predict_cached(features_hash: str, features_json: str):\n    features_dict = json.loads(features_json)\n    input_data = np.array([[\n        features_dict[\"CreditScore\"],\n        features_dict[\"Age\"],\n        # ... autres features\n    ]])\n    \n    proba = model.predict_proba(input_data)[0, 1]\n    prediction = int(proba > 0.5)\n    \n    if proba < 0.3:\n        risk = \"Low\"\n    elif proba < 0.7:\n        risk = \"Medium\"\n    else:\n        risk = \"High\"\n    \n    return {\n        \"churn_probability\": round(float(proba), 4),\n        \"prediction\": prediction,\n        \"risk_level\": risk\n    }\n\n@app.post(\"/predict\", response_model=PredictionResponse)\ndef predict(features: CustomerFeatures):\n    features_dict = features.dict()\n    features_hash = hash_features(features_dict)\n    features_json = json.dumps(features_dict)\n    \n    # Utilise le cache si disponible\n    result = predict_cached(features_hash, features_json)\n    \n    logger.info(f\"Prediction - Hash: {features_hash[:8]}\")\n    return result\n```\n\n### Checklist de Production {#sec-module7-checklist}\n\n::: callout-tip\n## Checklist Avant Production\n\n-   [ ] Tests unitaires avec coverage \\> 80%\n-   [ ] Tests d'integration\n-   [ ] Load testing effectue\n-   [ ] Monitoring configure\n-   [ ] Alertes definies\n-   [ ] Logs centralises\n-   [ ] Documentation API complete\n-   [ ] HTTPS active\n-   [ ] Health checks fonctionnels\n-   [ ] Auto-scaling teste\n-   [ ] Variables d'environnement securisees\n-   [ ] Budget Azure surveille\n:::\n\n### Checkpoint Final {#sec-module7-checkpoint}\n\n:::: callout-note\n## Validation Module 7\n\n::: {style=\"margin-left: 20px; line-height: 1.8;\"}\n-   [ ] Cache de predictions implemente\n-   [ ] Documentation complete\n-   [ ] Tous les tests passent\n-   [ ] Checklist de production verifiee\n:::\n::::\n\n## Nettoyage des Ressources Azure {#sec-nettoyage}\n\n### IMPORTANT - Suppression pour √âviter les Co√ªts {#sec-nettoyage-important}\n\n::: callout-warning\n## ATTENTION - √Ä FAIRE √Ä LA FIN DU WORKSHOP\n\nPour √©viter de consommer votre budget de 100\\$, supprimez toutes les ressources :\n\n``` bash\n# Suppression du groupe de ressources (supprime tout)\naz group delete --name $RESOURCE_GROUP --yes --no-wait\n\n# Verification\naz group list --output table\n```\n\nCette commande supprime : - Azure Container Registry - Azure Container Apps - Application Insights - Tous les logs et donn√©es\n\n**Temps de suppression** : 5-10 minutes\n:::\n\n### Script de Nettoyage Automatique {#sec-nettoyage-script}\n\nCr√©ez `cleanup.sh` :\n\n``` bash\n#!/bin/bash\n\nRESOURCE_GROUP=\"rg-mlops\"\n\necho \"==========================================\"\necho \"Nettoyage des ressources Azure\"\necho \"==========================================\"\n\nread -p \"Voulez-vous vraiment supprimer toutes les ressources ? (yes/no): \" confirm\n\nif [ \"$confirm\" != \"yes\" ]; then\n    echo \"Operation annulee.\"\n    exit 0\nfi\n\necho \"\\nRessources a supprimer:\"\naz resource list --resource-group $RESOURCE_GROUP --output table\n\necho \"\\nSuppression en cours...\"\naz group delete --name $RESOURCE_GROUP --yes --no-wait\n\necho \"\\nSuppression lancee (prend 5-10 minutes)\"\necho \"Verifiez sur : https://portal.azure.com\"\n```\n\n``` bash\n# Rendre executable et lancer\nchmod +x cleanup.sh\n./cleanup.sh\n```\n\n## R√©capitulatif du Workshop {#sec-recapitulatif}\n\n### Ce que Vous Avez Accompli {#sec-recap-accompli}\n\nF√©licitations ! Vous avez d√©ploy√© un syst√®me MLOps complet :\n\n**Architecture Finale :**\n\n`ML Training` ‚Üí `FastAPI` ‚Üí `Docker` ‚Üí `Azure Container Registry` ‚Üí `Azure Container Apps`\n\n‚Üë `GitHub Actions CI/CD`\n\n‚Üë `Application Insights Monitoring`\n\n### Comp√©tences Acquises {#sec-recap-competences}\n\n1.  **Machine Learning**\n    -   Entra√Ænement d'un mod√®le Random Forest\n    -   √âvaluation avec m√©triques appropri√©es\n    -   Tracking avec MLflow\n2.  **D√©veloppement d'API**\n    -   Cr√©ation d'API REST avec FastAPI\n    -   Validation des donn√©es avec Pydantic\n    -   Documentation automatique\n3.  **Conteneurisation**\n    -   Dockerfiles optimis√©s\n    -   Bonnes pratiques de s√©curit√©\n    -   Gestion des images\n4.  **Cloud Azure**\n    -   Azure Container Registry\n    -   Azure Container Apps\n    -   Application Insights\n5.  **DevOps/MLOps**\n    -   Pipelines CI/CD avec GitHub Actions\n    -   Tests automatis√©s\n    -   D√©ploiement continu\n6.  **Monitoring et Maintenance**\n    -   Logs centralis√©s\n    -   M√©triques de performance\n    -   D√©tection de data drift\n\n### Points Cl√©s √† Retenir {#sec-recap-points-cles}\n\n::: callout-important\n## Lecons Importantes\n\n1.  **MLOps = DevOps + ML** : Automatisation du cycle de vie complet\n2.  **Conteneurisation** : Portabilit√© et reproductibilit√©\n3.  **Tests** : Essentiels pour la fiabilit√©\n4.  **Monitoring** : Indispensable en production\n5.  **Documentation** : Facilite la collaboration\n6.  **S√©curit√©** : √Ä consid√©rer d√®s le d√©but\n7.  **Co√ªts** : Toujours surveiller l'utilisation cloud\n:::\n\n## FAQ - Foire Aux Questions {#sec-faq}\n\n### Questions Techniques {#sec-faq-techniques}\n\n**Q1 : Mon API est lente, comment l'optimiser ?**\n\n*R :* Plusieurs options : - Activer le cache des pr√©dictions - Utiliser des pr√©dictions batch - Optimiser le mod√®le (quantization, pruning) - Augmenter les ressources CPU/RAM\n\n**Q2 : Comment g√©rer plusieurs versions de mod√®les ?**\n\n*R :* Utilisez MLflow Model Registry et cr√©ez des endpoints diff√©rents (v1, v2).\n\n**Q3 : Comment impl√©menter un rollback ?**\n\n*R :* Conservez les anciennes images Docker avec tags et utilisez :\n\n``` bash\naz containerapp update \\\n  --name $APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --image $ACR_NAME.azurecr.io/bank-churn-api:v1  # Version precedente\n```\n\n**Q4 : Mon budget Azure est presque √©puis√©, que faire ?**\n\n*R :* - Mettre min-replicas √† 0 - Utiliser des SKU Basic - Supprimer les ressources inutilis√©es - Activer les budgets alerts\n\n### Questions de Compr√©hension {#sec-faq-comprehension}\n\n**Q5 : Quelle est la diff√©rence entre Docker et Kubernetes ?**\n\n*R :* Docker conteneurise les applications, Kubernetes les orchestre (scaling, load balancing, self-healing).\n\n**Q6 : Pourquoi utiliser FastAPI plut√¥t que Flask ?**\n\n*R :* FastAPI est plus rapide, avec validation automatique, documentation auto-g√©n√©r√©e, et support async natif.\n\n**Q7 : Qu'est-ce que le data drift ?**\n\n*R :* Changement dans la distribution des donn√©es d'entr√©e par rapport aux donn√©es d'entra√Ænement, pouvant d√©grader les performances du mod√®le.\n\n## Conclusion {#sec-conclusion}\n\n### F√©licitations ! {#sec-conclusion-felicitations}\n\nVous avez termin√© ce workshop intensif de MLOps avec Azure. Vous avez construit un syst√®me complet de d√©ploiement de mod√®le de Machine Learning en production, avec toutes les bonnes pratiques de l'industrie.\n\n### Prochaines √âtapes {#sec-conclusion-next-steps}\n\n1.  **Pratiquez** : Refaites le workshop avec un dataset diff√©rent\n2.  **Partagez** : Mettez votre projet sur GitHub\n3.  **Am√©liorez** : Impl√©mentez les fonctionnalit√©s avanc√©es\n4.  **Certifiez-vous** : Pr√©parez les certifications Azure\n\n------------------------------------------------------------------------\n\n**Bon Apprentissage et Bon D√©ploiement !**\n\n*Ce guide vous a accompagn√© dans votre premier projet MLOps.\\\nContinuez √† explorer, √† apprendre et √† innover.*\n\n------------------------------------------------------------------------\n\n*Version 1.0 - Novembre 2025*\\\n*Workshop MLOps avec Azure* \\n\\## Test de d√©ploiement - jeu. 20 nov. 2025 03:26:42","srcMarkdownNoYaml":"\n\n## Introduction {#sec-introduction}\n\n### Bienvenue !\n\nCe workshop vous guidera √† travers le d√©ploiement complet d'un mod√®le de Machine Learning en production sur Microsoft Azure. Vous allez construire une API de pr√©diction de d√©faillance client (churn) et la d√©ployer sur le cloud avec toutes les bonnes pratiques MLOps.\n\n### Objectifs d'Apprentissage {#sec-objectifs}\n\n√Ä la fin de ce workshop, vous serez capable de :\n\n-   Entra√Æner et sauvegarder un mod√®le ML avec MLflow\n-   Cr√©er une API REST avec FastAPI\n-   Conteneuriser une application avec Docker\n-   D√©ployer sur Azure Container Apps\n-   Mettre en place un pipeline CI/CD avec GitHub Actions\n-   Monitorer votre application en production\n-   D√©tecter le data drift\n\n### Le Projet : Bank Churn Prediction {#sec-projet}\n\n**Contexte :** Une banque souhaite pr√©dire quels clients risquent de partir pour proposer des actions de r√©tention.\n\n**Dataset :** 10 features (√¢ge, score cr√©dit, solde, etc.) + 1 target (Exited : 0/1)\n\n**Mod√®le :** Random Forest Classifier\n\n**Livrable :** API REST d√©ploy√©e sur Azure, accessible publiquement\n\n### Architecture Finale {#sec-architecture}\n\n**Flux de d√©ploiement :**\n\n`Code GitHub` ‚Üí `GitHub Actions` ‚Üí `Docker Build` ‚Üí `Azure Container Registry` ‚Üí `Azure Container Apps` ‚Üí `Internet`\n\n## Pr√©paration de l'Environnement {#sec-preparation}\n\n### Logiciels Requis {#sec-logiciels}\n\n**Obligatoire :**\n\n-   Python 3.9+ : https://www.python.org/downloads/\n-   Visual Studio Code : https://code.visualstudio.com/\n-   Git : https://git-scm.com/downloads\n-   Docker Desktop : https://www.docker.com/products/docker-desktop\n-   Azure CLI : https://docs.microsoft.com/cli/azure/install-azure-cli\n\n**Comptes √† cr√©er :**\n\n-   Compte GitHub : https://github.com/signup\n-   Azure for Students (100\\$) : https://azure.microsoft.com/students\n\n### V√©rification de l'Installation {#sec-verification}\n\nOuvrez un terminal et testez :\n\n``` bash\n# Python\npython --version\n# Doit afficher Python 3.9.x ou superieur\n\n# Git\ngit --version\n\n# Docker\ndocker --version\ndocker ps\n\n# Azure CLI\naz --version\n```\n\n### Configuration Initiale {#sec-configuration}\n\n#### Configuration Git {#sec-config-git}\n\n``` bash\ngit config --global user.name \"Votre Nom\"\ngit config --global user.email \"votre.email@example.com\"\n```\n\n#### Connexion √† Azure {#sec-config-azure}\n\n``` bash\n# Se connecter a Azure\naz login\n\n# Verifier l'abonnement\naz account show\n\n# Si vous avez plusieurs abonnements, selectionner celui de Students\naz account set --subscription \"Azure for Students\"\n```\n\n## Module 1 : Entra√Ænement du Mod√®le {#sec-module1}\n\n### Objectif {#sec-module1-objectif}\n\nEntra√Æner un mod√®le Random Forest pour pr√©dire le churn et le sauvegarder avec MLflow.\n\n### Pr√©paration du Projet {#sec-module1-preparation}\n\n``` bash\n# Creer le dossier du projet\nmkdir bank-churn-mlops\ncd bank-churn-mlops\n\n# Creer un environnement virtuel\npython -m venv venv\n\n# Activer l'environnement\n# Windows :\nvenv\\Scripts\\activate\n# Mac/Linux :\nsource venv/bin/activate\n\n# Creer la structure\nmkdir -p data model app tests\ntouch requirements.txt\n```\n\n### Fichier requirements.txt {#sec-module1-requirements}\n\nCr√©ez le fichier `requirements.txt` avec le contenu suivant :\n\n```         \n# API Framework\nfastapi==0.104.1\nuvicorn[standard]==0.24.0\npydantic==2.5.0\n\n# Machine Learning\nscikit-learn==1.3.2\npandas==2.1.3\nnumpy==1.26.2\njoblib==1.3.2\n\n# MLflow\nmlflow==2.8.1\n\n# Testing\npytest==7.4.3\npytest-cov==4.1.0\nhttpx==0.25.2\n\n# Utilities\npython-multipart==0.0.6\nrequests==2.31.0\n```\n\nPuis installez les d√©pendances :\n\n``` bash\npip install -r requirements.txt\n```\n\n### T√©l√©chargement du Dataset {#sec-module1-dataset}\n\nCr√©ez un dataset synth√©tique :\n\n``` python\n# generate_data.py\nimport pandas as pd\nimport numpy as np\n\nnp.random.seed(42)\nn_samples = 10000\n\ndata = {\n    'CreditScore': np.random.randint(300, 850, n_samples),\n    'Age': np.random.randint(18, 80, n_samples),\n    'Tenure': np.random.randint(0, 11, n_samples),\n    'Balance': np.random.uniform(0, 200000, n_samples),\n    'NumOfProducts': np.random.randint(1, 5, n_samples),\n    'HasCrCard': np.random.choice([0, 1], n_samples),\n    'IsActiveMember': np.random.choice([0, 1], n_samples),\n    'EstimatedSalary': np.random.uniform(20000, 150000, n_samples),\n    'Geography_Germany': np.random.choice([0, 1], n_samples),\n    'Geography_Spain': np.random.choice([0, 1], n_samples),\n}\n\n# Target : plus de chance de partir si inactif, peu de produits, etc.\nchurn_prob = (\n    (1 - data['IsActiveMember']) * 0.3 +\n    (data['NumOfProducts'] == 1) * 0.2 +\n    (data['Age'] > 60) * 0.15 +\n    (data['Balance'] == 0) * 0.25\n)\ndata['Exited'] = (np.random.random(n_samples) < churn_prob).astype(int)\n\ndf = pd.DataFrame(data)\ndf.to_csv('data/bank_churn.csv', index=False)\nprint(f\"Dataset cree : {len(df)} lignes\")\nprint(f\"Taux de churn : {df['Exited'].mean():.2%}\")\n```\n\n### Script d'Entra√Ænement {#sec-module1-training}\n\nCr√©ez le fichier `train_model.py` :\n\n``` python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, \n    precision_score, \n    recall_score,\n    f1_score, \n    roc_auc_score,\n    confusion_matrix\n)\nimport joblib\nimport mlflow\nimport mlflow.sklearn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configuration MLflow\nmlflow.set_tracking_uri(\"./mlruns\")\nmlflow.set_experiment(\"bank-churn-prediction\")\n\nprint(\"Chargement des donnees...\")\ndf = pd.read_csv(\"data/bank_churn.csv\")\n\nprint(f\"Dataset : {len(df)} lignes, {len(df.columns)} colonnes\")\nprint(f\"Taux de churn : {df['Exited'].mean():.2%}\")\n\n# Separation features/target\nX = df.drop('Exited', axis=1)\ny = df['Exited']\n\n# Split train/test (80/20)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(f\"\\nTrain : {len(X_train)} lignes\")\nprint(f\"Test : {len(X_test)} lignes\")\n\n# Entrainement avec MLflow tracking\nprint(\"\\nEntrainement du modele...\")\nwith mlflow.start_run(run_name=\"random-forest-v1\"):\n    \n    # Parametres du modele\n    params = {\n        'n_estimators': 100,\n        'max_depth': 10,\n        'min_samples_split': 5,\n        'random_state': 42\n    }\n    \n    # Entrainement\n    model = RandomForestClassifier(**params)\n    model.fit(X_train, y_train)\n    \n    # Predictions\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    \n    # Calcul des metriques\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    \n    # Log des parametres et metriques dans MLflow\n    mlflow.log_params(params)\n    mlflow.log_metrics({\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1_score\": f1,\n        \"roc_auc\": auc\n    })\n    \n    # Creation et sauvegarde de la matrice de confusion\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title('Matrice de Confusion')\n    plt.ylabel('Vraie Classe')\n    plt.xlabel('Classe Predite')\n    plt.savefig('confusion_matrix.png')\n    mlflow.log_artifact('confusion_matrix.png')\n    plt.close()\n    \n    # Feature importance\n    feature_importance = pd.DataFrame({\n        'feature': X.columns,\n        'importance': model.feature_importances_\n    }).sort_values('importance', ascending=False)\n    \n    plt.figure(figsize=(10, 6))\n    plt.barh(feature_importance['feature'], feature_importance['importance'])\n    plt.xlabel('Importance')\n    plt.title('Feature Importance')\n    plt.tight_layout()\n    plt.savefig('feature_importance.png')\n    mlflow.log_artifact('feature_importance.png')\n    plt.close()\n    \n    # Enregistrement du modele dans MLflow\n    mlflow.sklearn.log_model(\n        model,\n        \"model\",\n        registered_model_name=\"bank-churn-classifier\"\n    )\n    \n    # Sauvegarde locale du modele\n    joblib.dump(model, \"model/churn_model.pkl\")\n    \n    # Tags\n    mlflow.set_tags({\n        \"environment\": \"development\",\n        \"model_type\": \"RandomForest\",\n        \"task\": \"binary_classification\"\n    })\n    \n    # Affichage des resultats\n    print(\"\\n\" + \"=\"*50)\n    print(\"RESULTATS DE L'ENTRAINEMENT\")\n    print(\"=\"*50)\n    print(f\"Accuracy  : {accuracy:.4f}\")\n    print(f\"Precision : {precision:.4f}\")\n    print(f\"Recall    : {recall:.4f}\")\n    print(f\"F1 Score  : {f1:.4f}\")\n    print(f\"ROC AUC   : {auc:.4f}\")\n    print(\"=\"*50)\n    \n    print(f\"\\nModele sauvegarde dans : model/churn_model.pkl\")\n    print(f\"MLflow UI : mlflow ui --port 5000\")\n```\n\n### Ex√©cution {#sec-module1-execution}\n\n``` bash\n# Lancer l'entrainement\npython train_model.py\n\n# Voir les resultats dans MLflow UI\nmlflow ui --port 5000\n# Ouvrir http://localhost:5000 dans votre navigateur\n```\n\n### Checkpoint {#sec-module1-checkpoint}\n\n:::: callout-note\n## Validation Module 1\n\nAvant de passer au module suivant, v√©rifiez que :\n\n::: {style=\"margin-left: 20px;\"}\n-   [ ] Le mod√®le est entra√Æn√© avec une accuracy \\> 0.75\n-   [ ] Le fichier `model/churn_model.pkl` existe\n-   [ ] MLflow UI affiche votre exp√©rience\n-   [ ] Vous comprenez les m√©triques obtenues\n:::\n::::\n\n## Module 2 : Cr√©ation de l'API avec FastAPI {#sec-module2}\n\n### Objectif {#sec-module2-objectif}\n\nCr√©er une API REST qui expose le mod√®le via des endpoints HTTP.\n\n### Structure du Code API {#sec-module2-structure}\n\n```         \nbank-churn-mlops/\n|-- app/\n|   |-- __init__.py\n|   |-- main.py\n|   |-- models.py\n|   +-- utils.py\n|-- model/\n|   +-- churn_model.pkl\n|-- tests/\n|   +-- test_api.py\n|-- requirements.txt\n+-- README.md\n```\n\n### Fichier app/models.py {#sec-module2-models}\n\nD√©finition des sch√©mas de donn√©es avec Pydantic :\n\n``` python\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass CustomerFeatures(BaseModel):\n    \"\"\"Schema pour les features d'un client\"\"\"\n    CreditScore: int = Field(..., ge=300, le=850, description=\"Score de credit\")\n    Age: int = Field(..., ge=18, le=100, description=\"Age du client\")\n    Tenure: int = Field(..., ge=0, le=10, description=\"Anciennete en annees\")\n    Balance: float = Field(..., ge=0, description=\"Solde du compte\")\n    NumOfProducts: int = Field(..., ge=1, le=4, description=\"Nombre de produits\")\n    HasCrCard: int = Field(..., ge=0, le=1, description=\"Possession carte credit\")\n    IsActiveMember: int = Field(..., ge=0, le=1, description=\"Membre actif\")\n    EstimatedSalary: float = Field(..., ge=0, description=\"Salaire estime\")\n    Geography_Germany: int = Field(..., ge=0, le=1, description=\"Client allemand\")\n    Geography_Spain: int = Field(..., ge=0, le=1, description=\"Client espagnol\")\n    \n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"CreditScore\": 650,\n                \"Age\": 35,\n                \"Tenure\": 5,\n                \"Balance\": 50000,\n                \"NumOfProducts\": 2,\n                \"HasCrCard\": 1,\n                \"IsActiveMember\": 1,\n                \"EstimatedSalary\": 75000,\n                \"Geography_Germany\": 0,\n                \"Geography_Spain\": 1\n            }\n        }\n\nclass PredictionResponse(BaseModel):\n    \"\"\"Schema pour la reponse de prediction\"\"\"\n    churn_probability: float = Field(..., description=\"Probabilite de churn (0-1)\")\n    prediction: int = Field(..., description=\"Prediction binaire (0=reste, 1=part)\")\n    risk_level: str = Field(..., description=\"Niveau de risque (Low/Medium/High)\")\n\nclass HealthResponse(BaseModel):\n    \"\"\"Schema pour le health check\"\"\"\n    status: str\n    model_loaded: bool\n```\n\n### Fichier app/main.py {#sec-module2-main}\n\nL'API principale :\n\n``` python\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nimport joblib\nimport numpy as np\nfrom typing import List\nimport logging\nimport os\n\nfrom app.models import CustomerFeatures, PredictionResponse, HealthResponse\n\n# Configuration du logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Initialisation FastAPI\napp = FastAPI(\n    title=\"Bank Churn Prediction API\",\n    description=\"API de prediction de defaillance client\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\"\n)\n\n# CORS pour permettre les requetes depuis un navigateur\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Chargement du modele au demarrage\nMODEL_PATH = os.getenv(\"MODEL_PATH\", \"model/churn_model.pkl\")\nmodel = None\n\n@app.on_event(\"startup\")\nasync def load_model():\n    \"\"\"Charge le modele au demarrage de l'API\"\"\"\n    global model\n    try:\n        model = joblib.load(MODEL_PATH)\n        logger.info(f\"Modele charge avec succes depuis {MODEL_PATH}\")\n    except Exception as e:\n        logger.error(f\"Erreur lors du chargement du modele : {e}\")\n        model = None\n\n@app.get(\"/\", tags=[\"General\"])\ndef root():\n    \"\"\"Endpoint racine\"\"\"\n    return {\n        \"message\": \"Bank Churn Prediction API\",\n        \"version\": \"1.0.0\",\n        \"status\": \"running\",\n        \"docs\": \"/docs\"\n    }\n\n@app.get(\"/health\", response_model=HealthResponse, tags=[\"General\"])\ndef health_check():\n    \"\"\"Verification de l'etat de l'API\"\"\"\n    if model is None:\n        raise HTTPException(\n            status_code=503, \n            detail=\"Modele non charge\"\n        )\n    return {\n        \"status\": \"healthy\",\n        \"model_loaded\": True\n    }\n\n@app.post(\"/predict\", response_model=PredictionResponse, tags=[\"Prediction\"])\ndef predict(features: CustomerFeatures):\n    \"\"\"\n    Predit si un client va partir (churn)\n    \n    Retourne :\n    - churn_probability : probabilite de churn (0 a 1)\n    - prediction : 0 (reste) ou 1 (part)\n    - risk_level : Low, Medium ou High\n    \"\"\"\n    if model is None:\n        raise HTTPException(\n            status_code=503, \n            detail=\"Modele non disponible\"\n        )\n    \n    try:\n        # Preparation des features\n        input_data = np.array([[\n            features.CreditScore,\n            features.Age,\n            features.Tenure,\n            features.Balance,\n            features.NumOfProducts,\n            features.HasCrCard,\n            features.IsActiveMember,\n            features.EstimatedSalary,\n            features.Geography_Germany,\n            features.Geography_Spain\n        ]])\n        \n        # Prediction\n        proba = model.predict_proba(input_data)[0, 1]\n        prediction = int(proba > 0.5)\n        \n        # Classification du risque\n        if proba < 0.3:\n            risk = \"Low\"\n        elif proba < 0.7:\n            risk = \"Medium\"\n        else:\n            risk = \"High\"\n        \n        logger.info(\n            f\"Prediction effectuee : proba={proba:.4f}, \"\n            f\"prediction={prediction}, risk={risk}\"\n        )\n        \n        return {\n            \"churn_probability\": round(float(proba), 4),\n            \"prediction\": prediction,\n            \"risk_level\": risk\n        }\n    \n    except Exception as e:\n        logger.error(f\"Erreur lors de la prediction : {e}\")\n        raise HTTPException(\n            status_code=500, \n            detail=f\"Erreur de prediction : {str(e)}\"\n        )\n\n@app.post(\"/predict/batch\", tags=[\"Prediction\"])\ndef predict_batch(features_list: List[CustomerFeatures]):\n    \"\"\"\n    Predictions en batch pour plusieurs clients\n    \"\"\"\n    if model is None:\n        raise HTTPException(status_code=503, detail=\"Modele non disponible\")\n    \n    try:\n        predictions = []\n        \n        for features in features_list:\n            input_data = np.array([[\n                features.CreditScore, features.Age, features.Tenure,\n                features.Balance, features.NumOfProducts, features.HasCrCard,\n                features.IsActiveMember, features.EstimatedSalary,\n                features.Geography_Germany, features.Geography_Spain\n            ]])\n            \n            proba = model.predict_proba(input_data)[0, 1]\n            prediction = int(proba > 0.5)\n            \n            predictions.append({\n                \"churn_probability\": round(float(proba), 4),\n                \"prediction\": prediction\n            })\n        \n        logger.info(f\"Batch prediction : {len(predictions)} clients traites\")\n        \n        return {\"predictions\": predictions, \"count\": len(predictions)}\n    \n    except Exception as e:\n        logger.error(f\"Erreur batch prediction : {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n```\n\n### Test Local de l'API {#sec-module2-test}\n\n``` bash\n# Demarrer l'API\nuvicorn app.main:app --reload --port 8000\n\n# Dans un autre terminal, tester :\n\n# 1. Health check\ncurl http://localhost:8000/health\n\n# 2. Prediction simple\ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n  }'\n```\n\n### Jupyter Lab\n\n``` python\n#dans jupyter lab\nimport requests\nimport json\n\n# URL de ton API FastAPI\nurl = \"http://localhost:8000/predict\"\n\n# Donn√©es √† envoyer\ndata = {\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n}\n\n# Envoyer la requ√™te POST\nresponse = requests.post(url, json=data)\n\n# Afficher la r√©ponse\nprint(f\"Status Code: {response.status_code}\")\nprint(f\"Response: {response.json()}\")\n```\n\n### Documentation Interactive {#sec-module2-docs}\n\nOuvrez votre navigateur et allez sur :\n\n-   **Swagger UI** : http://localhost:8000/docs\n-   **ReDoc** : http://localhost:8000/redoc\n\n### Checkpoint {#sec-module2-checkpoint}\n\n:::: callout-note\n## Validation Module 2\n\nAvant de passer au module suivant, v√©rifiez que :\n\n::: {style=\"margin-left: 20px;\"}\n-   [ ] Le mod√®le est entra√Æn√© avec une accuracy \\> 0.75\n-   [ ] Le fichier `model/churn_model.pkl` existe\\\n-   [ ] MLflow UI affiche votre exp√©rience\n-   [ ] Vous comprenez les m√©triques obtenues\n:::\n::::\n\n## Module 3 : Conteneurisation avec Docker {#sec-module3}\n\n### Objectif {#sec-module3-objectif}\n\nEmpaqueter l'API dans un conteneur Docker pour la rendre portable et faciliter le d√©ploiement sur Azure.\n\n### Cr√©ation du Dockerfile {#sec-module3-dockerfile}\n\nCr√©ez le fichier `Dockerfile` √† la racine du projet :\n\n``` dockerfile\n# Utilise une image Python officielle\nFROM python:3.9-slim\n\n# Definir le repertoire de travail\nWORKDIR /app\n\n# Copier les fichiers de dependances\nCOPY requirements.txt .\n\n# Installer les dependances\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copier le code de l'application\nCOPY app/ ./app/\nCOPY model/ ./model/\n\n# Exposer le port\nEXPOSE 8000\n\n# Commande pour demarrer l'application\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```\n\n### Cr√©ation du .dockerignore {#sec-module3-dockerignore}\n\nCr√©ez le fichier `.dockerignore` :\n\n```         \n__pycache__\n*.pyc\n*.pyo\n*.pyd\n.Python\nenv/\nvenv/\n.venv\n*.egg-info/\n.pytest_cache/\n.git\n.gitignore\nREADME.md\n.env\nmlruns/\n*.log\n.DS_Store\n.vscode/\ntests/\n```\n\n### Build de l'Image Docker {#sec-module3-build}\n\n``` bash\n# Build de l'image (cela peut prendre quelques minutes)\ndocker build -t bank-churn-api:v1 .\n\n# Verifier que l'image est creee\ndocker images bank-churn-api:v1\n\n# Voir la taille de l'image\ndocker images --format \"table {{.Repository}}\\t{{.Tag}}\\t{{.Size}}\" | grep bank-churn\n```\n\n### Test du Conteneur en Local {#sec-module3-test}\n\n``` bash\n# Lancer le conteneur\ndocker run -d -p 8000:8000 --name churn-api bank-churn-api:v1\n\n# Verifier que le conteneur tourne\ndocker ps\n\n# Voir les logs\ndocker logs churn-api\n\n# Tester l'API\ncurl http://localhost:8000/health\n\n# Prediction de test\ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 700,\n    \"Age\": 40,\n    \"Tenure\": 7,\n    \"Balance\": 80000,\n    \"NumOfProducts\": 3,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 0,\n    \"EstimatedSalary\": 90000,\n    \"Geography_Germany\": 1,\n    \"Geography_Spain\": 0\n  }'\n\n# Arreter et supprimer le conteneur\ndocker stop churn-api\ndocker rm churn-api\n```\n\n### Commandes Docker Utiles {#sec-module3-commandes}\n\n``` bash\n# Voir tous les conteneurs (meme arretes)\ndocker ps -a\n\n# Entrer dans un conteneur en cours d'execution\ndocker exec -it churn-api /bin/bash\n\n# Voir l'utilisation des ressources\ndocker stats churn-api\n\n# Nettoyer les images inutilisees\ndocker image prune\n\n# Supprimer toutes les images\ndocker rmi $(docker images -q)\n```\n\n### Questions de Compr√©hension {#sec-module3-questions}\n\n1.  Pourquoi utiliser un .dockerignore ?\n2.  Quelle est la diff√©rence entre CMD et RUN dans un Dockerfile ?\n3.  Pourquoi exposer le port 8000 ?\n4.  Comment v√©rifier que votre conteneur fonctionne correctement ?\n\n### Checkpoint {#sec-module3-checkpoint}\n\n:::: callout-note\n## Validation Module 3\n\nAvant de passer au module suivant, v√©rifiez que :\n\n::: {style=\"margin-left: 20px;\"}\n-   [ ] L'image Docker est build√©e avec succ√®s\n-   [ ] Le conteneur d√©marre sans erreur\n-   [ ] L'API r√©pond correctement depuis le conteneur\n-   [ ] La taille de l'image est raisonnable (\\< 1GB)\n:::\n::::\n\n## Module 4 : D√©ploiement sur Azure {#sec-module4}\n\n### Objectif {#sec-module4-objectif}\n\nD√©ployer l'API sur Azure Container Apps et la rendre accessible publiquement.\n\n### Pr√©requis {#sec-module4-prerequis}\n\n1.  **Docker Desktop** en cours d'ex√©cution (mode WSL2 recommand√©)\n2.  **Configurer Docker** ![](image_docker.png)\n3.  **Azure CLI** install√© et connect√© (`az login`)\n4.  **Image locale** `churn-api:v1` d√©j√† construite\n5.  **installer l'extension containerapp**\n\n``` bash\n az extension add --name containerapp\n```\n\n### Etape 0 : V√©rifier les r√©gions disponibles {#sec-module4-etape0}\n\n``` bash\n#!/bin/bash\n# M√©thodesimple \n\n# Liste toutes les r√©gions recommand√©es\necho \"R√©gions disponibles chez toi :\"\naz account list-locations \\\n  --query \"[?metadata.regionCategory=='Recommended'].name\" \\\n  -o tsv | head -5\n\n# Prendre la premi√®re\nREGION=$(az account list-locations \\\n  --query \"[?metadata.regionCategory=='Recommended'].name\" \\\n  -o tsv | head -1)\n\necho \"‚úÖ proposition de la r√©gion : $REGION\"\n```\n\nOn Peut aussi √©x√©cuter\n\n``` bash\n# Juste cette ligne dans ton terminal :\nLOCATION=$(az account list-locations --query \"[0].name\" -o tsv) && echo \"Use: $REGION\"\n```\n\n### Script Complet : {#sec-module4-etape1}\n\n``` bash\n#!/usr/bin/env bash\nset -euo pipefail\n#################################\n# VARIABLES D√âFINITIVES\n#################################\nRESOURCE_GROUP=\"rg-mlops-bank-churn\"  \nLOCATION=\"westeurope\"   # Forc√© West Europe (garanti)\nFALLBACK_LOCATION=\"northeurope\"     # Fallback garanti\nACR_NAME=\"mlops$(whoami | tr '[:upper:]' '[:lower:]' | tr -cd '[:alnum:]')\"  # 100% minuscules\nCONTAINER_APP_NAME=\"bank-churn\" \nCONTAINERAPPS_ENV=\"env-mlops-workshop\"\nIMAGE_NAME=\"churn-api\"\nIMAGE_TAG=\"v1\"\nTARGET_PORT=8000\n\n#################################\n# 0) Contexte Azure + V√©rification Extensions\n#################################\necho \"V√©rification du contexte Azure...\"\naz account show --query \"{name:name, cloudName:cloudName}\" -o json >/dev/null\n\necho \"V√©rification/installation des extensions Azure CLI...\"\n\n# V√©rifier et installer containerapp si n√©cessaire\nif ! az extension show --name containerapp >/dev/null 2>&1; then\n    echo \"üì¶ Installation de l'extension containerapp...\"\n    az extension add --name containerapp --upgrade -y --only-show-errors\n    echo \"‚úÖ Extension containerapp install√©e\"\nelse\n    echo \"‚úÖ Extension containerapp d√©j√† install√©e\"\n    # Mise √† jour silencieuse\n    az extension update --name containerapp -y --only-show-errors 2>/dev/null || true\nfi\n\n# Liste des extensions install√©es pour v√©rification\necho \"Extensions install√©es :\"\naz extension list --query \"[].{Name:name, Version:version}\" -o table\n\n#################################\n# 1) Providers n√©cessaires\n#################################\necho \"Register providers...\"\naz provider register --namespace Microsoft.ContainerRegistry --wait\naz provider register --namespace Microsoft.App --wait\naz provider register --namespace Microsoft.Web --wait\naz provider register --namespace Microsoft.OperationalInsights --wait\n\n#################################\n# 2) Resource Group\n#################################\necho \"Cr√©ation/validation du groupe de ressources...\"\naz group create -n \"$RESOURCE_GROUP\" -l \"$LOCATION\" >/dev/null || true\necho \"‚úÖ RG OK: $RESOURCE_GROUP\"\n\n#################################\n# 3) Cr√©ation ACR (avec v√©rification)\n#################################\necho \"Cr√©ation du Container Registry (ACR) en $LOCATION...\"\n\n# V√©rification pr√©alable\nif [[ ! \"$ACR_NAME\" =~ ^[a-z0-9]{5,50}$ ]]; then\n    echo \"‚ùå ERREUR: Nom ACR invalide: $ACR_NAME\"\n    echo \"   Doit contenir 5-50 caract√®res alphanum√©riques en minuscules\"\n    exit 1\nfi\n\necho \"Nom ACR valid√©: $ACR_NAME (${#ACR_NAME} caract√®res)\"\n\nset +e\naz acr create \\\n  --resource-group \"$RESOURCE_GROUP\" \\\n  --name \"$ACR_NAME\" \\\n  --sku Basic \\\n  --admin-enabled true \\\n  --location \"$LOCATION\" >/dev/null 2>&1\nACR_RC=$?\nset -e\n\nif [ $ACR_RC -ne 0 ]; then\n  echo \"‚ö†Ô∏è ACR bloqu√© en $LOCATION. Fallback => $FALLBACK_LOCATION\"\n  LOCATION=\"$FALLBACK_LOCATION\"\n  az acr create \\\n    --resource-group \"$RESOURCE_GROUP\" \\\n    --name \"$ACR_NAME\" \\\n    --sku Basic \\\n    --admin-enabled true \\\n    --location \"$LOCATION\" >/dev/null\nfi\n\n# Attendre la cr√©ation compl√®te\nsleep 5\necho \"‚úÖ ACR cr√©√© : $ACR_NAME (region=$LOCATION)\"\n\n#################################\n# 4) Login ACR + Push image\n#################################\necho \"Connexion au registry...\"\naz acr login --name \"$ACR_NAME\" >/dev/null\n\nACR_LOGIN_SERVER=$(az acr show --name \"$ACR_NAME\" --query loginServer -o tsv | tr -d '\\r')\necho \"ACR_LOGIN_SERVER=$ACR_LOGIN_SERVER\"\n\n# R√©cup√©ration des credentials AU BON ENDROIT\nACR_USER=$(az acr credential show -n \"$ACR_NAME\" --query username -o tsv | tr -d '\\r')\nACR_PASS=$(az acr credential show -n \"$ACR_NAME\" --query \"passwords[0].value\" -o tsv | tr -d '\\r')\nIMAGE=\"$ACR_LOGIN_SERVER/$IMAGE_NAME:$IMAGE_TAG\"\n\necho \"Build + Tag + Push...\"\ndocker build -t \"$IMAGE_NAME:$IMAGE_TAG\" .\ndocker tag \"$IMAGE_NAME:$IMAGE_TAG\" \"$ACR_LOGIN_SERVER/$IMAGE_NAME:$IMAGE_TAG\"\ndocker tag \"$IMAGE_NAME:$IMAGE_TAG\" \"$ACR_LOGIN_SERVER/$IMAGE_NAME:latest\"\ndocker push \"$ACR_LOGIN_SERVER/$IMAGE_NAME:$IMAGE_TAG\"\ndocker push \"$ACR_LOGIN_SERVER/$IMAGE_NAME:latest\"\necho \"‚úÖ Image push√©e dans ACR\"\n\n#################################\n# 5) Log Analytics (corrig√©)\n#################################\nLAW_NAME=\"law-mlops-$(whoami)-$RANDOM\"\necho \"Cr√©ation Log Analytics: $LAW_NAME\"\naz monitor log-analytics workspace create -g \"$RESOURCE_GROUP\" -n \"$LAW_NAME\" -l \"$LOCATION\" >/dev/null\nsleep 10  # Attente n√©cessaire\n\n# Commande corrig√©e avec param√®tres explicites\nLAW_ID=$(az monitor log-analytics workspace show \\\n    --resource-group \"$RESOURCE_GROUP\" \\\n    --workspace-name \"$LAW_NAME\" \\\n    --query customerId -o tsv | tr -d '\\r')\n\nLAW_KEY=$(az monitor log-analytics workspace get-shared-keys \\\n    --resource-group \"$RESOURCE_GROUP\" \\\n    --workspace-name \"$LAW_NAME\" \\\n    --query primarySharedKey -o tsv | tr -d '\\r')\necho \"‚úÖ Log Analytics OK\"\n\n#################################\n# 6) Container Apps Environment\n#################################\necho \"Cr√©ation/validation Container Apps Environment: $CONTAINERAPPS_ENV\"\nif ! az containerapp env show -n \"$CONTAINERAPPS_ENV\" -g \"$RESOURCE_GROUP\" >/dev/null 2>&1; then\n  az containerapp env create \\\n    -n \"$CONTAINERAPPS_ENV\" \\\n    -g \"$RESOURCE_GROUP\" \\\n    -l \"$LOCATION\" \\\n    --logs-workspace-id \"$LAW_ID\" \\\n    --logs-workspace-key \"$LAW_KEY\" >/dev/null\nfi\necho \"‚úÖ Environment OK\"\n\n#################################\n# 7) D√©ploiement Container App\n#################################\necho \"D√©ploiement Container App: $CONTAINER_APP_NAME\"\nif az containerapp show -n \"$CONTAINER_APP_NAME\" -g \"$RESOURCE_GROUP\" >/dev/null 2>&1; then\n  az containerapp update \\\n    -n \"$CONTAINER_APP_NAME\" \\\n    -g \"$RESOURCE_GROUP\" \\\n    --image \"$IMAGE\" \\\n    --registry-server \"$ACR_LOGIN_SERVER\" \\\n    --registry-username \"$ACR_USER\" \\\n    --registry-password \"$ACR_PASS\" >/dev/null\nelse\n  az containerapp create \\\n    -n \"$CONTAINER_APP_NAME\" \\\n    -g \"$RESOURCE_GROUP\" \\\n    --environment \"$CONTAINERAPPS_ENV\" \\\n    --image \"$IMAGE\" \\\n    --ingress external \\\n    --target-port \"$TARGET_PORT\" \\\n    --registry-server \"$ACR_LOGIN_SERVER\" \\\n    --registry-username \"$ACR_USER\" \\\n    --registry-password \"$ACR_PASS\" \\\n    --min-replicas 1 \\\n    --max-replicas 1 >/dev/null\nfi\necho \"‚úÖ Container App OK\"\n\n#################################\n# 8) URL API\n#################################\nAPP_URL=$(az containerapp show -n \"$CONTAINER_APP_NAME\" -g \"$RESOURCE_GROUP\" --query properties.configuration.ingress.fqdn -o tsv | tr -d '\\r')\n\necho \"\"\necho \"==========================================\"\necho \"‚úÖ D√âPLOIEMENT R√âUSSI\"\necho \"==========================================\"\necho \"ACR      : $ACR_NAME\"\necho \"Region   : $LOCATION\"\necho \"Resource Group: $RESOURCE_GROUP\"\necho \"\"\necho \"URLs de l'application :\"\necho \"  API      : https://$APP_URL\"\necho \"  Health   : https://$APP_URL/health\"\necho \"  Docs     : https://$APP_URL/docs\"\necho \"\"\necho \"Pour supprimer toutes les ressources :\"\necho \"  az group delete --name $RESOURCE_GROUP --yes --no-wait\"\necho \"==========================================\"\n```\n\n### Test de l'API en Production {#sec-module4-etape2}\n\n``` bash\nRESOURCE_GROUP=\"rg-mlops-bank-churn\"  # votre Ressource group\n\nCONTAINER_APP_NAME=\"bank-churn\" # le nom de votre container app\n\nAPP_URL=$(az containerapp show \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --query properties.configuration.ingress.fqdn -o tsv | tr -d '\\r\\n' | xargs)\n\n# 2. V√©rifier l'URL proprement\necho \"URL nettoy√©e: '$APP_URL'\"\necho \"Longueur: ${#APP_URL}\"\n\n# 3. Test avec l'URL compl√®te\nFULL_URL=\"https://${APP_URL}/predict\"\necho \"URL compl√®te: $FULL_URL\"\n\n# 4. Test de pr√©diction\ncurl -X POST \"$FULL_URL\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n  }'\n\necho \"\"\n```\n\n### üîß R√©solution des probl√®mes {#sec-module4-troubleshooting}\n\n| Probl√®me | Solution |\n|------------------------------------|------------------------------------|\n| **Erreur DNS / `cloudName: null`** | Ex√©cuter `az logout && az login` |\n| **Caract√®re `\\r` dans les variables** | Toujours utiliser `tr -d '\\r'` apr√®s `az acr show` |\n| **Erreur \"ContainerAppInvalidSecretName\"** | Utiliser l'approche YAML avec secret nomm√© `acrpassword` |\n| **Docker non accessible** | D√©marrer Docker Desktop et ouvrir un nouveau terminal |\n| **Erreurs de permissions** | V√©rifier `az account show` et `az login` |\n| **L'application est \"Failed\"** | V√©rifier les logs : `az containerapp logs show --name $CONTAINER_APP_NAME --resource-group $RESOURCE_GROUP --tail 50` |\n| **Image fonctionne localement mais pas sur Azure** | V√©rifier les credentials ACR et l'identit√© manag√©e |\n\n### üìã Commandes de diagnostic utiles {#sec-module4-diagnostic}\n\n``` bash\n# Voir les logs en temps r√©el\naz containerapp logs show \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --tail 100 \\\n  --follow\n\n# V√©rifier l'√©tat d√©taill√©\naz containerapp revision list \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --output table\n\n# R√©cup√©ration automatique et test Docker\nRESOURCE_GROUP=\"rg-mlops1\"\nACR_NAME=$(az acr list --resource-group $RESOURCE_GROUP --query \"[0].name\" -o tsv | tr -d '\\r\\n' | xargs)\nACR_LOGIN_SERVER=$(az acr show --name $ACR_NAME --query loginServer --output tsv | tr -d '\\r\\n' | xargs)\n\necho \"ACR trouv√©: $ACR_LOGIN_SERVER\"\necho \"Lancement de l'image...\"\n\ndocker run -p 8000:8000 ${ACR_LOGIN_SERVER}/bank-churn-api:v1\n\n\n# tester l'api \ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n  }'\n```\n\n### üìä Alternative : D√©ploiement via le Portail Azure {#sec-module4-portail}\n\n#### **Objectif**\n\nReproduire EXACTEMENT le script Bash fourni en utilisant UNIQUEMENT l'interface graphique Azure Portal.\n\n#### **Pr√©requis**\n\n1.  Compte Azure avec abonnement actif\n2.  Acc√®s √† [portal.azure.com](https://portal.azure.com)\n3.  Dockerfile et code de l'application `bank-churn-api` pr√™ts localement\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 0: Connexion Azure**\n\n1.  **Connectez-vous** √† [portal.azure.com](https://portal.azure.com)\n2.  **V√©rifiez votre abonnement** :\n    -   En haut √† droite ‚Üí Cliquez sur votre profil\n    -   \"Changer de r√©pertoire\" si besoin\n    -   L'abonnement actif s'affiche dans le panneau lat√©ral gauche\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 1: V√©rifier/Cr√©er les Fournisseurs (Providers)**\n\n‚ö†Ô∏è **Cette √©tape n'est pas faisable dans le portail** Les providers s'enregistrent automatiquement lors de la premi√®re utilisation du service. **Alternative** : Utilisez Azure Cloud Shell (Bash) pour cette partie uniquement :\n\n``` bash\n# Dans Azure Cloud Shell (ic√¥ne >_ en haut du portail)\naz provider register --namespace Microsoft.ContainerRegistry --wait\naz provider register --namespace Microsoft.App --wait\naz provider register --namespace Microsoft.Web --wait\naz provider register --namespace Microsoft.OperationalInsights --wait\n```\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 2: Groupe de Ressources**\n\n1.  **Recherchez** \"Groupes de ressources\" dans la barre de recherche\n2.  **Cliquez** sur \"+ Cr√©er\"\n3.  **Remplissez** :\n    -   Abonnement : Votre abonnement\n    -   Groupe de ressources : `rg-mlops-bank-churn`\n    -   R√©gion : `westeurope`\n4.  **Cliquez** sur \"V√©rifier + cr√©er\" puis \"Cr√©er\"\n5.  **Attendez** le d√©ploiement (‚âà30 secondes)\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 3: Container Registry (ACR)**\n\n##### **3.1 Cr√©ation ACR**\n\n1.  **Recherchez** \"Registres de conteneurs\"\n2.  **Cliquez** sur \"+ Cr√©er\"\n3.  **Onglet \"G√©n√©ral\"** :\n    -   Groupe de ressources : `rg-mlops-bank-churn`\n    -   Nom du registre : `acrmlops[VOTRE_USERNAME][TIMESTAMP]` *Ex: acrmlopsjean1648826400* (le nom doit √™tre unique dans Azure et contenir de 5 √† 50 caract√®res alphanum√©riques ).\n    -   Emplacement : `westeurope`\n    -   SKU : `De base`\n4.  **Onglet \"Authentification\"** :\n    -   ‚úÖ Utilisateur administrateur ‚Üí ACTIV√â (utile pour les tests, mais privil√©giez une identit√© Microsoft Entra pour les sc√©narios de production )\n5.  **Cliquez** sur \"V√©rifier + cr√©er\" puis \"Cr√©er\"\n\n##### **3.2 Fallback si France Central bloqu√©**\n\nSi erreur de strat√©gie : 1. **Recommencez** l'√©tape 3.1 2. **Changez** l'emplacement : `West Europe` 3. **Notez** la nouvelle r√©gion pour les √©tapes suivantes\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 4: Build et Push de l'Image**\n\n##### **4.1 Pr√©parer localement**\n\n``` bash\n# Sur VOTRE machine locale (pas dans le portail)\ncd /chemin/vers/votre/projet\n\n# Build l'image\ndocker build -t bank-churn-api:v1 .\n\n# Tag avec ACR\ndocker tag bank-churn-api:v1 acrmlopsjean1648826400.azurecr.io/bank-churn-api:v1\ndocker tag bank-churn-api:v1 acrmlopsjean1648826400.azurecr.io/bank-churn-api:latest\n```\n\n##### **4.2 Push vers ACR**\n\n###### **Option A: Via Azure CLI local**\n\n``` bash\n# Login ACR avec votre identit√© individuelle \naz acr login --name acrmlopsjean1648826400\n\n# Push images\ndocker push acrmlopsjean1648826400.azurecr.io/bank-churn-api:v1\ndocker push acrmlopsjean1648826400.azurecr.io/bank-churn-api:latest\n```\n\n###### **Option B: Via Portail Azure (ACR Tasks)**\n\n1.  **Allez** dans votre ACR cr√©√©\n2.  **Menu gauche** ‚Üí \"Services\" ‚Üí \"T√¢ches\"\n3.  **Cliquez** sur \"+ T√¢che\"\n4.  **Configurez** :\n    -   Type de t√¢che : T√¢che rapide\n    -   Platform : Linux\n    -   Emplacement : M√™me que l'ACR\n    -   Source du code : \"Context local\"\n    -   Uploader votre code ZIP ou Dockerfile\n5.  **Ex√©cutez** la t√¢che\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 5: Log Analytics Workspace**\n\n1.  **Recherchez** \"Espaces de travail Log Analytics\"\n2.  **Cliquez** sur \"+ Cr√©er\"\n3.  **Remplissez** :\n    -   Groupe de ressources : `rg-mlops-bank-churn`\n    -   Nom : `law-mlops-[VOTRE_USERNAME]-[RANDOM]` *Ex: law-mlops-jean-12345*\n    -   R√©gion : M√™me que l'ACR (France Central ou West Europe)\n4.  **Cliquez** sur \"V√©rifier + cr√©er\" puis \"Cr√©er\"\n5.  **Notez** :\n    -   **ID de l'espace de travail** (customerId)\n    -   **Cl√© primaire** (primarySharedKey)\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 6: Container Apps Environment**\n\n1.  **Recherchez** \"Environnements Container Apps\"\n2.  **Cliquez** sur \"+ Cr√©er\"\n3.  **Onglet \"G√©n√©ral\"** :\n    -   Nom de l'environnement : `env-mlops-workshop`\n    -   Groupe de ressources : `rg-mlops-bank-churn`\n    -   Zone : M√™me r√©gion que l'ACR\n    -   Type d'environnement : `Consumption only` (pour ce workshop)\n4.  **Onglet \"Surveillance\"** :\n    -   ‚úÖ Activer la surveillance Log Analytics\n    -   Espace de travail Log Analytics : S√©lectionnez celui cr√©√© √† l'√©tape 5\n5.  **Cliquez** sur \"V√©rifier + cr√©er\" puis \"Cr√©er\"\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 7: Container App (Application)**\n\n##### **7.1 Cr√©ation**\n\n1.  **Recherchez** \"Container Apps\"\n2.  **Cliquez** sur \"+ Cr√©er\" \\> \"Container App\"\n3.  **Onglet \"G√©n√©ral\"** :\n    -   Abonnement : Votre abonnement\n    -   Groupe de ressources : `rg-MLopsyy`\n    -   Nom de l'application conteneur : `bank-churn-api` (entre 2 et 32 caract√®res, lettres minuscules, chiffres et tirets )\n    -   R√©gion : S√©lectionnez une r√©gion pr√®s de vous\n    -   Environnement Container Apps : S√©lectionnez `env-mlops-workshop` (cr√©√© pr√©c√©demment)\n\n##### **7.2 Onglet \"Application\"**\n\n1.  **Section \"Image\"** :\n    -   Source de l'image : \"Azure Container Registry\"\n    -   Registre : S√©lectionnez votre ACR\n    -   Image : `bank-churn-api`\n    -   √âtiquette : `v1`\n    -   Type d'authentification du registre : \"Informations d'identification de l'administrateur\" (utilisez les cl√©s d'acc√®s de l'ACR pour ce workshop )\n    -   Nom d'utilisateur/Password : R√©cup√©rez-les dans ACR ‚Üí \"Cl√©s d'acc√®s\"\n\n##### **7.3 Onglet \"Ingress\"**\n\n1.  **Trafic entrant** : ‚úÖ Activ√©\n2.  **Visibilit√© du trafic entrant** : `Accepting traffic from anywhere` (pour un acc√®s externe )\n3.  **Type d'entr√©e** : `HTTP`\n4.  **Port cible** : `8000` (doit correspondre au port √©cout√© par votre conteneur )\n5.  **Connexions non s√©curis√©es** : D√©cochez (laissez `false` par d√©faut pour forcer HTTPS )\n\n##### **7.4 Onglet \"Mise √† l'√©chelle\"**\n\nPour ce workshop et pour optimiser les co√ªts : 1. **Mode de mise √† l'√©chelle** : \"Aucune mise √† l'√©chelle automatique\" 2. **Nombre minimal de r√©plicas** : `1` 3. **Nombre maximal de r√©plicas** : `1`\n\n::: callout-note\n#### Bonne pratique en production\n\nPour une meilleure fiabilit√© en production, il est recommand√© de configurer au moins 3 r√©plicas et d'activer la mise √† l'√©chelle automatique bas√©e sur les m√©triques HTTP ou CPU pour g√©rer les pics de charge .\n:::\n\n##### **7.5 Finalisation**\n\n-   **Cliquez** sur \"V√©rifier + cr√©er\" puis \"Cr√©er\"\n-   **Attendez** le d√©ploiement (‚âà2-3 minutes)\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 8: R√©cup√©rer l'URL**\n\n1.  **Allez** sur votre Container App `bank-churn-api`\n2.  **Menu gauche** ‚Üí \"Vue d'ensemble\"\n3.  **Cherchez** \"URL de l'application\" (le FQDN g√©n√©r√© automatiquement )\n4.  **Copiez** l'URL (format : `https://bank-churn-api.xxxxxxxx.region.azurecontainerapps.io`)\n\n------------------------------------------------------------------------\n\n#### **√âTAPE 9: Tests**\n\n1.  **Ouvrez** un navigateur\n2.  **Testez** :\n    -   **Health** : `https://[VOTRE-URL]/health`\n    -   **Documentation** : `https://[VOTRE-URL]/docs`\n    -   **Swagger UI** : `https://[VOTRE-URL]/redoc`\n\n------------------------------------------------------------------------\n\n#### **V√©rification Finale**\n\nComparez avec le script Bash :\n\n| √âl√©ment | Script Bash | Interface Graphique |\n|------------------|---------------------|---------------------------------|\n| Resource Group | `rg-MLopsyy` (France Central) | ‚úÖ Identique |\n| ACR | Nom unique avec timestamp | ‚úÖ Identique (5-50 caract√®res alphanum√©riques ) |\n| Fallback location | West Europe si blocage | ‚úÖ G√©r√© manuellement |\n| Log Analytics | Cr√©√© avec nom al√©atoire | ‚úÖ Identique |\n| Environment | `env-mlops-workshop` | ‚úÖ Identique |\n| Container App | `bank-churn-api` port 8000 | ‚úÖ Identique (2-32 caract√®res ) |\n| Image | `bank-churn-api:v1` | ‚úÖ Identique |\n| Ingress | Externe, HTTP, port 8000 | ‚úÖ Identique |\n| R√©plicas | min=1, max=1 | ‚úÖ Identique |\n\n------------------------------------------------------------------------\n\n#### **Points d'Attention**\n\n1.  **Timestamp dans ACR** : Dans le portail, g√©n√©rez-le manuellement (ex: `date +%s` dans Cloud Shell)\n2.  **Authentification ACR** : Pour les sc√©narios de production, envisagez d'utiliser une **identit√© manag√©e** au lieu des identifiants administrateur pour une s√©curit√© et une gestion am√©lior√©es .\n3.  **Variables d'environnement** : Si votre app en a besoin, ajoutez-les dans l'onglet \"Param√®tres\" du Container App.\n4.  **Logs** : Les logs sont automatiquement envoy√©s √† Log Analytics configur√© dans l'environnement.\n5.  **S√©curit√© r√©seau** : Pour restreindre l'acc√®s, vous pouvez configurer ult√©rieurement des **restrictions d'adresse IP** sur l'ingress de votre application conteneur .\n\n------------------------------------------------------------------------\n\n#### **R√©sum√© des URLs**\n\n-   **Portail Azure** : https://portal.azure.com\n-   **Votre API** : `https://bank-churn-api.[...].azurecontainerapps.io`\n-   **Health check** : `/health`\n-   **Documentation** : `/docs` (Swagger)\n-   **ACR** : `acrmlopsjean1648826400.azurecr.io`\n\n------------------------------------------------------------------------\n\n**Dur√©e totale** : ‚âà15-20 minutes via l'interface graphique **Co√ªt estim√©** : \\~5-10‚Ç¨/mois (ACR Basic + Container App en fonctionnement)\n\n**Remarque :** Il est important de conserver la section existante \"Surveillance des Co√ªts {#sec-module4-couts}\" qui suit imm√©diatement cette partie dans votre fichier.\n\n### Exercice Pratique {#sec-module4-exercice}\n\n::: callout-tip\n## EXERCICE 2\n\nPartagez votre URL d'API avec un camarade et testez son API :\n\n1.  Faites 10 pr√©dictions sur son API\n2.  Comparez les r√©sultats avec votre mod√®le\n3.  Observez les logs dans Azure Portal :\n    -   Allez dans votre Container App\n    -   Menu **\"Log stream\"** ou **\"Monitoring\" ‚Üí \"Logs\"**\n    -   Observez les requ√™tes en temps r√©el\n:::\n\n### üéØ Points cl√©s des corrections apport√©es {#sec-module4-resume}\n\n1.  **Nettoyage du `\\r`** : Ajout de `tr -d '\\r'` √† la r√©cup√©ration du login server\n2.  **Approche YAML** : Contournement du bug de g√©n√©ration de nom de secret\n3.  **Secret nomm√©** : Utilisation d'un nom valide `acrpassword` au lieu du nom auto-g√©n√©r√©\n4.  **Variables d'environnement** : Ajout de `PYTHONUNBUFFERED=1` pour les logs\n5.  **Tests robustes** : Attente de 30 secondes avant les v√©rifications\n6.  **Commandes de diagnostic** : Ajout de commandes pour troubleshooting\n7.  **Alternative GUI** : Instructions pour le d√©ploiement via le portail Azure\n\nPour ex√©cuter le module, sauvegardez-le dans un fichier `module4-deploiement.sh` et ex√©cutez :\n\n``` bash\nchmod +x module4-deploiement.sh\n./module4-deploiement.sh\n```\n\n### Checkpoint {#sec-module4-checkpoint}\n\n:::: callout-note\n## Validation Module 4\n\nAvant de passer au module suivant, v√©rifiez que :\n\n::: {style=\"margin-left: 20px;\"}\n-   [ ] L'application est accessible via HTTPS\n-   [ ] Le health check fonctionne\n-   [ ] Les pr√©dictions fonctionnent\n-   [ ] Vous avez not√© l'URL publique de votre API\n:::\n::::\n\n## Module 5 : CI/CD avec GitHub Actions {#sec-module5}\n\n### Objectif {#sec-module5-objectif}\n\nAutomatiser le d√©ploiement : chaque commit sur la branche `main` d√©clenche un build et un red√©ploiement via un pipeline GitHub Actions.\n\n### √âtape 1 : Initialisation du Repository Git {#sec-module5-etape1}\n\n``` bash\n# Initialiser git avec 'main' comme branche par d√©faut\ngit init -b main\n\n# Cr√©er un .gitignore robuste\ncat > .gitignore << 'EOF'\n__pycache__/\n*.pyc\nvenv/\n.env\nmlruns/\n*.log\n.DS_Store\n.vscode/\nconfusion_matrix.png\nfeature_importance.png\n# Secrets (NE JAMAIS commiter)\n*.secret\n*.key\n*.pem\ncredentials*.json\nresultat.txt\nazure-credentials.json\nEOF\n\n# Premier commit\ngit add .\ngit commit -m \"Initial commit: Bank Churn API\"\n```\n\n### √âtape 2 : Cr√©er un Repository GitHub {#sec-module5-etape2}\n\n1.  Allez sur `https://github.com/new`\n2.  **Nom** : `bank-churn-mlops`\n3.  **Visibility** : Public ou Private\n4.  **Ne pas** initialiser avec README\n5.  Cliquez sur \"Create repository\"\n\n``` bash\n# Lier votre repo local √† GitHub\ngit remote add origin https://github.com/votre-username/bank-churn-mlops.git\ngit branch -M main\ngit push -u origin main\n```\n\n### √âtape 3 : Configuration des Secrets GitHub {#sec-module5-etape3}\n\nPour l'authentification avec Azure, l'action `azure/login@v1` attend un secret (`AZURE_CREDENTIALS`) contenant un **objet JSON avec exactement 4 cl√©s**.\n\n#### Cr√©er et formater les identifiants du Service Principal Azure\n\n**Option A (Recommand√©e) : Avec l'outil `jq`**\n\nSi `jq` n'est pas install√© sur votre terminal linux\n\n``` bash\nsudo apt  install jq\n```\n\nPuis √©x√©cuter ceci :\n\n``` bash\nRESOURCE_GROUP=\"rg-mlops-bank-churn\"\nSUBSCRIPTION_ID=$(az account show --query id -o tsv | tr -d '\\r')\n\n# 1. Cr√©er le Service Principal et capturer la sortie\nSP_JSON=$(az ad sp create-for-rbac \\\n  --name \"github-actions-$(date +%s)\" \\\n  --role contributor \\\n  --scopes \"/subscriptions/${SUBSCRIPTION_ID}/resourceGroups/${RESOURCE_GROUP}\" \\\n  --output json)\n\n# 2. Extraire et formater uniquement les 4 champs requis pour GitHub Actions\necho $SP_JSON | jq -c '{clientId: .appId, clientSecret: .password, subscriptionId: \"'\"$SUBSCRIPTION_ID\"'\", tenantId: .tenant}'\n```\n\n**Copiez l'objet JSON compact qui s'affiche.** Il ressemblera √† ceci :\n\n``` json\n{\"clientId\":\"xxxxxxxx-xxxx-...\",\"clientSecret\":\"votre_mot_de_passe\",\"subscriptionId\":\"e14fdc0f-d8cd-...\",\"tenantId\":\"xxxxxxxx-xxxx-...\"}\n```\n\n**Option B (Manuelle) : Sans `jq`** Ex√©cutez la commande standard et notez les valeurs pour `appId`, `password` et `tenant`. Composez ensuite **manuellement** l'objet JSON suivant en utilisant : - `appId` comme valeur pour `clientId` - `password` comme valeur pour `clientSecret` - Votre `subscriptionId` (`e14fdc0f-d8cd-4608-9a2e-d02e7b15366b`) - `tenant` comme valeur pour `tenantId`\n\n``` json\n{\n  \"clientId\": \"xxxxxxxx-xxxx-...\",\n  \"clientSecret\": \"votre_mot_de_passe\",\n  \"subscriptionId\": \"e14fdc0f-d8cd-4608-9a2e-d02e7b15366b\",\n  \"tenantId\": \"xxxxxxxx-xxxx-...\"\n}\n```\n\n#### Ajouter les Secrets dans GitHub\n\n1.  Allez dans votre repository GitHub : **Settings \\> Secrets and variables \\> Actions**\n2.  Cliquez sur **\"New repository secret\"**\n3.  Ajoutez ces trois secrets :\n\n| **Nom du Secret** | **Valeur √† coller** | **Comment l'obtenir** |\n|:-----------------------|:-----------------------|:-----------------------|\n| `AZURE_CREDENTIALS` | **L'objet JSON complet** (4 champs) g√©n√©r√© √† l'√©tape pr√©c√©dente. | R√©sultat de la commande avec `jq` ou cr√©ation manuelle. |\n| `ACR_USERNAME` | Le nom d'utilisateur de votre ACR. | `az acr credential show --name <VOTRE_ACR> --query username -o tsv` |\n| `ACR_PASSWORD` | Le mot de passe de votre ACR. | `az acr credential show --name <VOTRE_ACR> --query \"passwords[0].value\" -o tsv` |\n\n**Important** : Pour `AZURE_CREDENTIALS`, assurez-vous de copier **tout l'objet JSON en une seule ligne** dans le champ de valeur du secret, sans espaces avant ou apr√®s.\n\n### √âtape 4 : Pr√©paration des Tests pour le Pipeline {#sec-module5-tests}\n\nAvant de configurer le workflow, assurez-vous d'avoir des tests valides. Cr√©ez ou mettez √† jour `tests/test_api.py` :\n\n``` python\n# tests/test_api.py\nimport sys\nimport os\nfrom unittest.mock import patch\nimport numpy as np\n\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n\nfrom fastapi.testclient import TestClient\nfrom app.main import app\n\nclient = TestClient(app)\n\nTEST_CUSTOMER = {\n    \"CreditScore\": 650, \"Age\": 35, \"Tenure\": 5, \"Balance\": 50000.0,\n    \"NumOfProducts\": 2, \"HasCrCard\": 1, \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000.0, \"Geography_Germany\": 0, \"Geography_Spain\": 1\n}\n\ndef test_read_root():\n    \"\"\"Test l'endpoint racine /\"\"\"\n    response = client.get(\"/\")\n    assert response.status_code == 200\n    assert response.json()[\"message\"] == \"Bank Churn Prediction API\"\n\ndef test_predict_with_mock():\n    \"\"\"Test /predict avec un mock du mod√®le pour √©viter l'erreur 503\"\"\"\n    with patch('app.main.model') as mock_model:\n        # Simulation d'une pr√©diction r√©ussie\n        mock_model.predict_proba.return_value = np.array([[0.2, 0.8]])\n        mock_model.predict.return_value = np.array([1])\n        \n        response = client.post(\"/predict\", json=TEST_CUSTOMER)\n        # Le test passe si l'API traite la requ√™te\n        assert response.status_code in [200, 422, 503]\n```\n\n**Ex√©cution des tests en local (avant CI/CD)** :\n\n``` bash\npython -m pytest tests/ -v\n```\n\n### √âtape 5 : V√©rification des Noms de Ressources (CRITIQUE) {#sec-module5-verif}\n\nLe pipeline √©chouera si les noms de vos ressources Azure ne correspondent pas. **Avant de cr√©er le workflow**, v√©rifiez ces noms exacts :\n\n``` bash\n# 1. V√©rifier le nom exact de votre Azure Container Registry (ACR)\naz acr list --resource-group rg-mlops-bank-churn --query \"[].name\" -o tsv\n# Doit retourner quelque chose comme : mlopsnevermind\n\n# 2. V√©rifier le nom exact de votre Azure Container App\naz containerapp list --resource-group rg-mlops-bank-churn --query \"[].name\" -o tsv\n# Doit retourner : bank-churn\n\n# 3. Confirmer votre nom de groupe de ressources\necho \"rg-mlops-bank-churn\"\n```\n\nNotez ces noms, vous en aurez besoin pour l'√©tape suivante.\n\n### √âtape 6 : Cr√©ation du Workflow GitHub Actions {#sec-module5-etape4}\n\nCr√©ez le fichier `.github/workflows/ci-cd.yml` avec le contenu ci-dessous. **Remplacez les valeurs d'environnement (`env`)** par celles qui correspondent √† **vos** ressources Azure, identifi√©es √† l'√©tape 5.\n\n``` yaml\nname: CI/CD Pipeline\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n  workflow_dispatch:\n\nenv:\n  # ‚ö†Ô∏è REMPLACEZ CES VALEURS PAR LES V√îTRES ‚ö†Ô∏è\n  AZURE_RESOURCE_GROUP: rg-mlops-bank-churn\n  ACR_NAME: mlopsnevermind          # Le nom de VOTRE ACR (√©tape 5.1)\n  CONTAINER_APP_NAME: bank-churn    # Le nom de VOTRE Container App (√©tape 5.2)\n  IMAGE_NAME: bank-churn-api\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.9'\n      - name: Install dependencies\n        run: |\n          pip install --upgrade pip\n          pip install -r requirements.txt\n      - name: Run tests with coverage\n        run: |\n          pytest tests/ -v --cov=app --cov-report=term\n\n  build-and-deploy:\n    needs: test  # Ne s'ex√©cute QUE si les tests r√©ussissent\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'  # Ne d√©ploie que depuis 'main'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n      - name: Azure Login\n        uses: azure/login@v1\n        with:\n          creds: ${{ secrets.AZURE_CREDENTIALS }}  # Utilise le secret format√©\n      - name: Login to Azure Container Registry (ACR)\n        uses: azure/docker-login@v1\n        with:\n          login-server: ${{ env.ACR_NAME }}.azurecr.io\n          username: ${{ secrets.ACR_USERNAME }}\n          password: ${{ secrets.ACR_PASSWORD }}\n      - name: Build and push Docker image\n        run: |\n          # Construit l'image et la tagge avec le hash unique du commit\n          docker build -t ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }} .\n          # Cr√©e aussi un tag 'latest' pour r√©f√©rence\n          docker tag ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }} ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest\n          # Pousse les deux images vers l'ACR\n          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}\n          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest\n          echo \"‚úÖ Images pouss√©es dans ACR.\"\n      - name: Deploy to Azure Container Apps\n        uses: azure/CLI@v1\n        with:\n          inlineScript: |\n            az containerapp update \\\n              --name ${{ env.CONTAINER_APP_NAME }} \\\n              --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n              --image ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}\n            echo \"‚úÖ Commande de d√©ploiement envoy√©e √† Azure.\"\n      - name: Verify deployment\n        run: |\n          # R√©cup√®re l'URL publique de l'application\n          APP_URL=$(az containerapp show \\\n            --name ${{ env.CONTAINER_APP_NAME }} \\\n            --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n            --query properties.configuration.ingress.fqdn -o tsv)\n          echo \"üåê Votre API est d√©ploy√©e √† l'adresse : https://$APP_URL\"\n          echo \"ü©∫ Attente du d√©marrage (20s) et v√©rification...\"\n          sleep 20\n          # Teste le endpoint /health\n          curl -f https://$APP_URL/health || exit 1\n          echo \"‚úÖ D√©ploiement v√©rifi√© et r√©ussi !\"\n```\n\n### √âtape 7 : D√©clencher et Observer le Pipeline {#sec-module5-etape5}\n\n``` bash\n# Ajouter le fichier de workflow et le pousser\ngit add .github/workflows/ci-cd.yml\ngit commit -m \"feat: add automated CI/CD pipeline with GitHub Actions\"\ngit push origin main\n\n# Le pipeline se d√©clenche AUTOMATIQUEMENT !\n```\n\n**Observez l'ex√©cution** :\n\n1.  Allez sur votre d√©p√¥t GitHub.\n2.  Cliquez sur l'onglet **\"Actions\"**.\n3.  Vous verrez l'ex√©cution de votre workflow nomm√© **\"CI/CD Pipeline\"**. Cliquez dessus pour voir les d√©tails et les logs en direct.\n\n### Exercice Pratique {#sec-module5-exercice}\n\n::: callout-tip\n# EXERCICE 3\n\n1.  **Ajoutez un nouveau test** dans `test_api.py` pour tester un autre endpoint, par exemple l'endpoint `/docs` (documentation Swagger) qui devrait toujours √™tre accessible. `python     def test_docs_endpoint():         \"\"\"Test que la documentation Swagger est accessible\"\"\"         response = client.get(\"/docs\")         assert response.status_code == 200`\n\n2.  **Faites un commit** de ce changement : `bash     git add tests/test_api.py     git commit -m \"test: add docs endpoint test\"`\n\n3.  **Poussez le commit** sur la branche `main` : `bash     git push origin main`\n\n4.  **Observez le pipeline** s'ex√©cuter automatiquement dans l'onglet **Actions** de votre d√©p√¥t GitHub.\n\n5.  **Une fois le workflow termin√© avec succ√®s**, v√©rifiez que votre application a bien √©t√© red√©ploy√©e en visitant son URL (celle affich√©e √† la fin du job `Verify deployment`).\n:::\n\n### D√©pannage des Erreurs Courantes {#sec-module5-troubleshooting}\n\n| **Sympt√¥me / Message d'erreur** | **Cause la plus probable** | **Solution** |\n|:-----------------------|:-----------------------|:-----------------------|\n| `Login failed... Not all parameters are provided in 'creds'` | Le secret `AZURE_CREDENTIALS` n'a pas le bon format (trop/moins de 4 champs). | Supprimez et recr√©ez le secret avec l'objet JSON √† **4 champs exactement** (`clientId`, `clientSecret`, `subscriptionId`, `tenantId`). |\n| `Error: ACR login failed... 401 Unauthorized` | Les secrets `ACR_USERNAME` ou `ACR_PASSWORD` sont incorrects. | R√©g√©n√©rez les mots de passe de votre ACR avec `az acr credential renew --name <acr-name>` et mettez √† jour les secrets. |\n| √âchec du job `build-and-deploy` avec `Repository not found` ou erreur sur `az containerapp update`. | Les noms dans `env:` (`ACR_NAME`, `CONTAINER_APP_NAME`) ne correspondent pas √† vos ressources. | V√©rifiez les noms exacts avec les commandes de l'**√âtape 5** et corrigez le fichier `ci-cd.yml`. |\n| Le job `test` √©choue sur `pytest collected 0 items`. | Vos fichiers dans `tests/` ne sont pas reconnus comme tests. | Assurez-vous que les noms de fonctions commencent par `test_`. Exemple : `def test_health_check():` |\n| Le job `test` √©choue sur `list indices must be integers or slices, not tuple`. | Erreur dans `app/main.py`. | Corrigez l'indexation : remplacez `model.predict_proba(...)[0, 1]` par `model.predict_proba(...)[0][1]`. |\n\n### Checkpoint {#sec-module5-checkpoint}\n\n:::: callout-note\n# Validation Module 5\n\nAvant de passer au module suivant, v√©rifiez que ces conditions sont remplies :\n\n::: {style=\"margin-left: 20px; line-height: 1.8;\"}\n-   [ ] **Le d√©p√¥t GitHub `bank-churn-mlops` existe** et est li√© √† votre projet local.\n-   [ ] **Les trois secrets GitHub** (`AZURE_CREDENTIALS`, `ACR_USERNAME`, `ACR_PASSWORD`) sont cr√©√©s avec les **bonnes valeurs et le bon format**.\n-   [ ] **Le fichier `.github/workflows/ci-cd.yml`** est pr√©sent dans votre projet et contient les **noms exacts** de vos ressources Azure.\n-   [ ] **Le pipeline CI/CD s'ex√©cute sans erreur** dans l'onglet GitHub Actions (les jobs `test` et `build-and-deploy` sont verts ‚úÖ).\n-   [ ] **L'application se red√©ploie automatiquement** : apr√®s un `git push`, une nouvelle image est cr√©√©e et votre API conteneuris√©e est mise √† jour sur Azure.\n:::\n\n::::\n\n## Module 6 : Monitoring et Maintenance {#sec-module6}\n\n### Objectif {#sec-module6-objectif}\n\nMettre en place le monitoring de l'application en production, suivre l‚Äô√©tat de l‚ÄôAPI, les performances et d√©tecter le **data drift** √† l‚Äôaide d‚ÄôAzure Application Insights.\n\n\n### Configuration Application Insights {#sec-module6-appinsights}\n\n```bash\n# Cr√©ation d'Application Insights\naz monitor app-insights component create \\\n  --app bank-churn-insights \\\n  --location $LOCATION \\\n  --resource-group $RESOURCE_GROUP \\\n  --application-type web\n\n# R√©cup√©ration de la connection string\nAPPINSIGHTS_CONN=$(az monitor app-insights component show \\\n  --app bank-churn-insights \\\n  --resource-group $RESOURCE_GROUP \\\n  --query connectionString -o tsv)\n\necho \"Connection String : $APPINSIGHTS_CONN\"\n\n# Injection de la variable d'environnement dans Azure Container Apps\naz containerapp update \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --set-env-vars \"APPLICATIONINSIGHTS_CONNECTION_STRING=$APPINSIGHTS_CONN\"\n```\n\n\n\n### Int√©gration du Monitoring dans le Code {#sec-module6-monitoring}\n\n#### D√©pendances\n\nAjoutez dans `requirements.txt` :\n\n```txt\nopencensus-ext-azure==1.1.9\nopencensus-ext-requests==0.12.1\n```\n\n\n\n### Instrumentation de l‚ÄôAPI FastAPI (`app/main.py`)\n\n```python\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom typing import List\nimport joblib\nimport numpy as np\nimport logging\nimport os\nimport traceback\n\nfrom opencensus.ext.azure.log_exporter import AzureLogHandler\nfrom app.models import CustomerFeatures, PredictionResponse, HealthResponse\nfrom app.drift_detect import detect_drift\n\n# -------------------------------------------------\n# Logging & Application Insights\n# -------------------------------------------------\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"bank-churn-api\")\n\nAPPINSIGHTS_CONN = os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\")\nif APPINSIGHTS_CONN:\n    logger.addHandler(AzureLogHandler(connection_string=APPINSIGHTS_CONN))\n    logger.info(\"Application Insights connect√©\")\nelse:\n    logger.warning(\"Application Insights non configur√©\")\n\n# -------------------------------------------------\n# Initialisation FastAPI\n# -------------------------------------------------\napp = FastAPI(\n    title=\"Bank Churn Prediction API\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\"\n)\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# -------------------------------------------------\n# Chargement du mod√®le\n# -------------------------------------------------\nMODEL_PATH = os.getenv(\"MODEL_PATH\", \"model/churn_model.pkl\")\nmodel = None\n\n@app.on_event(\"startup\")\nasync def load_model():\n    global model\n    try:\n        model = joblib.load(MODEL_PATH)\n        logger.info(f\"Mod√®le charg√© depuis {MODEL_PATH}\")\n    except Exception as e:\n        logger.error(f\"Erreur chargement mod√®le : {e}\")\n        model = None\n\n# -------------------------------------------------\n# Endpoints g√©n√©raux\n# -------------------------------------------------\n@app.get(\"/health\", response_model=HealthResponse)\ndef health():\n    if model is None:\n        raise HTTPException(status_code=503, detail=\"Mod√®le non charg√©\")\n    return {\"status\": \"healthy\", \"model_loaded\": True}\n\n# -------------------------------------------------\n# Pr√©diction\n# -------------------------------------------------\n@app.post(\"/predict\", response_model=PredictionResponse)\ndef predict(features: CustomerFeatures):\n    if model is None:\n        raise HTTPException(status_code=503, detail=\"Mod√®le indisponible\")\n\n    try:\n        X = np.array([[ \n            features.CreditScore,\n            features.Age,\n            features.Tenure,\n            features.Balance,\n            features.NumOfProducts,\n            features.HasCrCard,\n            features.IsActiveMember,\n            features.EstimatedSalary,\n            features.Geography_Germany,\n            features.Geography_Spain\n        ]])\n\n        proba = model.predict_proba(X)[0][1]\n        prediction = int(proba > 0.5)\n\n        risk = \"Low\" if proba < 0.3 else \"Medium\" if proba < 0.7 else \"High\"\n\n        logger.info(\n            \"prediction\",\n            extra={\n                \"custom_dimensions\": {\n                    \"event_type\": \"prediction\",\n                    \"probability\": float(proba),\n                    \"risk_level\": risk\n                }\n            }\n        )\n\n        return {\n            \"churn_probability\": round(float(proba), 4),\n            \"prediction\": prediction,\n            \"risk_level\": risk\n        }\n\n    except Exception as e:\n        logger.error(f\"Erreur prediction : {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n# -------------------------------------------------\n# Drift Detection (API)\n# -------------------------------------------------\n@app.post(\"/drift/check\", tags=[\"Monitoring\"])\ndef check_drift(threshold: float = 0.05):\n    try:\n        results = detect_drift(\n            reference_file=\"data/bank_churn.csv\",\n            production_file=\"data/production_data.csv\",\n            threshold=threshold\n        )\n\n        drifted = [f for f, r in results.items() if r[\"drift_detected\"]]\n        drift_pct = len(drifted) / len(results) * 100\n\n        logger.info(\n            \"drift_detection\",\n            extra={\n                \"custom_dimensions\": {\n                    \"event_type\": \"drift_detection\",\n                    \"features_analyzed\": len(results),\n                    \"features_drifted\": len(drifted),\n                    \"drift_percentage\": drift_pct,\n                    \"risk_level\": \"HIGH\" if drift_pct > 50 else \"MEDIUM\" if drift_pct > 20 else \"LOW\"\n                }\n            }\n        )\n\n        return {\n            \"status\": \"success\",\n            \"features_analyzed\": len(results),\n            \"features_drifted\": len(drifted)\n        }\n\n    except Exception:\n        tb = traceback.format_exc()\n        logger.error(tb)\n        raise HTTPException(status_code=500, detail=\"Erreur drift detection\")\n```\n### G√©n√©ration de Donn√©es avec Drift {#sec-module6-driftgen}\n\nEn environnement r√©el, les donn√©es de production √©voluent progressivement\n(changement de comportement client, contexte √©conomique, nouvelles offres, etc.).\n\nAfin de **tester et valider le syst√®me de monitoring**, nous utilisons un script de\ng√©n√©ration artificielle de donn√©es de production avec drift contr√¥l√© :\n`drift_data_gen.py`.\n\nCe script permet de :\n- simuler diff√©rents niveaux de drift (faible, moyen, fort)\n- cr√©er un jeu de donn√©es de production r√©aliste\n- tester la robustesse du syst√®me de d√©tection\n- valider le fonctionnement des alertes en production\n\n---\n\n### Script `drift_data_gen.py`\n\n```python\nimport pandas as pd\nimport numpy as np\nimport os\n\ndef generate_drifted_data(\n    reference_file=\"data/bank_churn.csv\",\n    output_file=\"data/production_data.csv\",\n    drift_level=\"medium\"\n):\n    \"\"\"\n    G√©n√®re des donn√©es de production avec drift artificiel\n    \n    drift_level:\n    - low    : bruit l√©ger\n    - medium : d√©calage significatif\n    - high   : changement fort\n    \"\"\"\n\n    os.makedirs(\"data\", exist_ok=True)\n\n    ref = pd.read_csv(reference_file)\n    prod = ref.copy()\n\n    np.random.seed(42)\n\n    drift_map = {\n        \"low\": 0.05,\n        \"medium\": 0.15,\n        \"high\": 0.30\n    }\n\n    intensity = drift_map.get(drift_level, 0.15)\n\n    drift_features = [\n        \"CreditScore\",\n        \"Age\",\n        \"Balance\",\n        \"EstimatedSalary\"\n    ]\n\n    for col in drift_features:\n        if col in prod.columns:\n            std = prod[col].std()\n            prod[col] = prod[col] + np.random.normal(\n                loc=std * intensity,\n                scale=std * intensity,\n                size=len(prod)\n            )\n\n    prod.to_csv(output_file, index=False)\n\n    print(f\"‚úÖ Donn√©es de production g√©n√©r√©es avec drift '{drift_level}'\")\n    print(f\"üìÅ Fichier : {output_file}\")\n\nif __name__ == \"__main__\":\n    generate_drifted_data(drift_level=\"medium\")\n```\n\n---\n\n### Utilisation\n\n```bash\n# G√©n√©rer des donn√©es de production avec drift moyen\npython drift_data_gen.py\n```\n\nCe fichier `production_data.csv` est ensuite utilis√© par l‚Äôendpoint :\n\n```http\nPOST /drift/check\n```\n\npour comparer les donn√©es de r√©f√©rence et de production.\n\n---\n\n### R√¥le dans le pipeline MLOps\n\n| √âtape | R√¥le |\n|------|------|\n| `drift_data_gen.py` | Simulation du drift |\n| `drift_detect.py` | D√©tection statistique |\n| Application Insights | Monitoring & historisation |\n| Alertes Azure | D√©cision op√©rationnelle |\n\n\n\n\n\n### D√©tection de Data Drift {#sec-module6-drift}\n\n#### Script `app/drift_detect.py`\n\n```python\nimport matplotlib\nmatplotlib.use(\"Agg\")  # OBLIGATOIRE pour Docker / Azure\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import ks_2samp\nimport json\nimport os\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef detect_drift(reference_file, production_file, threshold=0.05, output_dir=\"drift_reports\"):\n    os.makedirs(output_dir, exist_ok=True)\n\n    ref = pd.read_csv(reference_file)\n    prod = pd.read_csv(production_file)\n\n    results = {}\n\n    for col in ref.columns:\n        if col != \"Exited\" and col in prod.columns:\n            stat, p = ks_2samp(ref[col].dropna(), prod[col].dropna())\n            results[col] = {\n                \"p_value\": float(p),\n                \"statistic\": float(stat),\n                \"drift_detected\": bool(p < threshold)\n            }\n\n    report_path = f\"{output_dir}/drift_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n    with open(report_path, \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n```\n\n\n\n### Checkpoint {#sec-module6-checkpoint}\n\n:::: callout-note\n#### Validation Module 6\n\nAvant de passer au module suivant, v√©rifiez que :\n\n- [ ] Application Insights est actif\n- [ ] Les logs sont visibles dans Azure Portal\n- [ ] `/predict` fonctionne en production\n- [ ] `/drift/check` retourne un r√©sultat\n- [ ] Le drift est historis√© dans Application Insights\n::::\n\n\n## Module 7 : Optimisations et Bonnes Pratiques {#sec-module7}\n\n### Objectif {#sec-module7-objectif}\n\nAm√©liorer les performances, la s√©curit√© et la maintenabilit√© de l'application.\n\n### Ajout d'un Cache pour les Pr√©dictions {#sec-module7-cache}\n\nModifiez `app/main.py` :\n\n``` python\nfrom functools import lru_cache\nimport hashlib\nimport json\n\ndef hash_features(features_dict: dict) -> str:\n    \"\"\"Cree un hash unique pour les features\"\"\"\n    return hashlib.md5(\n        json.dumps(features_dict, sort_keys=True).encode()\n    ).hexdigest()\n\n# Cache pour les predictions (1000 dernieres)\n@lru_cache(maxsize=1000)\ndef predict_cached(features_hash: str, features_json: str):\n    features_dict = json.loads(features_json)\n    input_data = np.array([[\n        features_dict[\"CreditScore\"],\n        features_dict[\"Age\"],\n        # ... autres features\n    ]])\n    \n    proba = model.predict_proba(input_data)[0, 1]\n    prediction = int(proba > 0.5)\n    \n    if proba < 0.3:\n        risk = \"Low\"\n    elif proba < 0.7:\n        risk = \"Medium\"\n    else:\n        risk = \"High\"\n    \n    return {\n        \"churn_probability\": round(float(proba), 4),\n        \"prediction\": prediction,\n        \"risk_level\": risk\n    }\n\n@app.post(\"/predict\", response_model=PredictionResponse)\ndef predict(features: CustomerFeatures):\n    features_dict = features.dict()\n    features_hash = hash_features(features_dict)\n    features_json = json.dumps(features_dict)\n    \n    # Utilise le cache si disponible\n    result = predict_cached(features_hash, features_json)\n    \n    logger.info(f\"Prediction - Hash: {features_hash[:8]}\")\n    return result\n```\n\n### Checklist de Production {#sec-module7-checklist}\n\n::: callout-tip\n## Checklist Avant Production\n\n-   [ ] Tests unitaires avec coverage \\> 80%\n-   [ ] Tests d'integration\n-   [ ] Load testing effectue\n-   [ ] Monitoring configure\n-   [ ] Alertes definies\n-   [ ] Logs centralises\n-   [ ] Documentation API complete\n-   [ ] HTTPS active\n-   [ ] Health checks fonctionnels\n-   [ ] Auto-scaling teste\n-   [ ] Variables d'environnement securisees\n-   [ ] Budget Azure surveille\n:::\n\n### Checkpoint Final {#sec-module7-checkpoint}\n\n:::: callout-note\n## Validation Module 7\n\n::: {style=\"margin-left: 20px; line-height: 1.8;\"}\n-   [ ] Cache de predictions implemente\n-   [ ] Documentation complete\n-   [ ] Tous les tests passent\n-   [ ] Checklist de production verifiee\n:::\n::::\n\n## Nettoyage des Ressources Azure {#sec-nettoyage}\n\n### IMPORTANT - Suppression pour √âviter les Co√ªts {#sec-nettoyage-important}\n\n::: callout-warning\n## ATTENTION - √Ä FAIRE √Ä LA FIN DU WORKSHOP\n\nPour √©viter de consommer votre budget de 100\\$, supprimez toutes les ressources :\n\n``` bash\n# Suppression du groupe de ressources (supprime tout)\naz group delete --name $RESOURCE_GROUP --yes --no-wait\n\n# Verification\naz group list --output table\n```\n\nCette commande supprime : - Azure Container Registry - Azure Container Apps - Application Insights - Tous les logs et donn√©es\n\n**Temps de suppression** : 5-10 minutes\n:::\n\n### Script de Nettoyage Automatique {#sec-nettoyage-script}\n\nCr√©ez `cleanup.sh` :\n\n``` bash\n#!/bin/bash\n\nRESOURCE_GROUP=\"rg-mlops\"\n\necho \"==========================================\"\necho \"Nettoyage des ressources Azure\"\necho \"==========================================\"\n\nread -p \"Voulez-vous vraiment supprimer toutes les ressources ? (yes/no): \" confirm\n\nif [ \"$confirm\" != \"yes\" ]; then\n    echo \"Operation annulee.\"\n    exit 0\nfi\n\necho \"\\nRessources a supprimer:\"\naz resource list --resource-group $RESOURCE_GROUP --output table\n\necho \"\\nSuppression en cours...\"\naz group delete --name $RESOURCE_GROUP --yes --no-wait\n\necho \"\\nSuppression lancee (prend 5-10 minutes)\"\necho \"Verifiez sur : https://portal.azure.com\"\n```\n\n``` bash\n# Rendre executable et lancer\nchmod +x cleanup.sh\n./cleanup.sh\n```\n\n## R√©capitulatif du Workshop {#sec-recapitulatif}\n\n### Ce que Vous Avez Accompli {#sec-recap-accompli}\n\nF√©licitations ! Vous avez d√©ploy√© un syst√®me MLOps complet :\n\n**Architecture Finale :**\n\n`ML Training` ‚Üí `FastAPI` ‚Üí `Docker` ‚Üí `Azure Container Registry` ‚Üí `Azure Container Apps`\n\n‚Üë `GitHub Actions CI/CD`\n\n‚Üë `Application Insights Monitoring`\n\n### Comp√©tences Acquises {#sec-recap-competences}\n\n1.  **Machine Learning**\n    -   Entra√Ænement d'un mod√®le Random Forest\n    -   √âvaluation avec m√©triques appropri√©es\n    -   Tracking avec MLflow\n2.  **D√©veloppement d'API**\n    -   Cr√©ation d'API REST avec FastAPI\n    -   Validation des donn√©es avec Pydantic\n    -   Documentation automatique\n3.  **Conteneurisation**\n    -   Dockerfiles optimis√©s\n    -   Bonnes pratiques de s√©curit√©\n    -   Gestion des images\n4.  **Cloud Azure**\n    -   Azure Container Registry\n    -   Azure Container Apps\n    -   Application Insights\n5.  **DevOps/MLOps**\n    -   Pipelines CI/CD avec GitHub Actions\n    -   Tests automatis√©s\n    -   D√©ploiement continu\n6.  **Monitoring et Maintenance**\n    -   Logs centralis√©s\n    -   M√©triques de performance\n    -   D√©tection de data drift\n\n### Points Cl√©s √† Retenir {#sec-recap-points-cles}\n\n::: callout-important\n## Lecons Importantes\n\n1.  **MLOps = DevOps + ML** : Automatisation du cycle de vie complet\n2.  **Conteneurisation** : Portabilit√© et reproductibilit√©\n3.  **Tests** : Essentiels pour la fiabilit√©\n4.  **Monitoring** : Indispensable en production\n5.  **Documentation** : Facilite la collaboration\n6.  **S√©curit√©** : √Ä consid√©rer d√®s le d√©but\n7.  **Co√ªts** : Toujours surveiller l'utilisation cloud\n:::\n\n## FAQ - Foire Aux Questions {#sec-faq}\n\n### Questions Techniques {#sec-faq-techniques}\n\n**Q1 : Mon API est lente, comment l'optimiser ?**\n\n*R :* Plusieurs options : - Activer le cache des pr√©dictions - Utiliser des pr√©dictions batch - Optimiser le mod√®le (quantization, pruning) - Augmenter les ressources CPU/RAM\n\n**Q2 : Comment g√©rer plusieurs versions de mod√®les ?**\n\n*R :* Utilisez MLflow Model Registry et cr√©ez des endpoints diff√©rents (v1, v2).\n\n**Q3 : Comment impl√©menter un rollback ?**\n\n*R :* Conservez les anciennes images Docker avec tags et utilisez :\n\n``` bash\naz containerapp update \\\n  --name $APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --image $ACR_NAME.azurecr.io/bank-churn-api:v1  # Version precedente\n```\n\n**Q4 : Mon budget Azure est presque √©puis√©, que faire ?**\n\n*R :* - Mettre min-replicas √† 0 - Utiliser des SKU Basic - Supprimer les ressources inutilis√©es - Activer les budgets alerts\n\n### Questions de Compr√©hension {#sec-faq-comprehension}\n\n**Q5 : Quelle est la diff√©rence entre Docker et Kubernetes ?**\n\n*R :* Docker conteneurise les applications, Kubernetes les orchestre (scaling, load balancing, self-healing).\n\n**Q6 : Pourquoi utiliser FastAPI plut√¥t que Flask ?**\n\n*R :* FastAPI est plus rapide, avec validation automatique, documentation auto-g√©n√©r√©e, et support async natif.\n\n**Q7 : Qu'est-ce que le data drift ?**\n\n*R :* Changement dans la distribution des donn√©es d'entr√©e par rapport aux donn√©es d'entra√Ænement, pouvant d√©grader les performances du mod√®le.\n\n## Conclusion {#sec-conclusion}\n\n### F√©licitations ! {#sec-conclusion-felicitations}\n\nVous avez termin√© ce workshop intensif de MLOps avec Azure. Vous avez construit un syst√®me complet de d√©ploiement de mod√®le de Machine Learning en production, avec toutes les bonnes pratiques de l'industrie.\n\n### Prochaines √âtapes {#sec-conclusion-next-steps}\n\n1.  **Pratiquez** : Refaites le workshop avec un dataset diff√©rent\n2.  **Partagez** : Mettez votre projet sur GitHub\n3.  **Am√©liorez** : Impl√©mentez les fonctionnalit√©s avanc√©es\n4.  **Certifiez-vous** : Pr√©parez les certifications Azure\n\n------------------------------------------------------------------------\n\n**Bon Apprentissage et Bon D√©ploiement !**\n\n*Ce guide vous a accompagn√© dans votre premier projet MLOps.\\\nContinuez √† explorer, √† apprendre et √† innover.*\n\n------------------------------------------------------------------------\n\n*Version 1.0 - Novembre 2025*\\\n*Workshop MLOps avec Azure* \\n\\## Test de d√©ploiement - jeu. 20 nov. 2025 03:26:42"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"css":["styles.css"],"toc-depth":3,"number-sections":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.25","theme":"cosmo","title":"Workshop MLOps avec Azure - Guide Pratique","editor":"visual","toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}