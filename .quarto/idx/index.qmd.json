{"title":"Workshop MLOps avec Azure - Guide Pratique","markdown":{"yaml":{"title":"Workshop MLOps avec Azure - Guide Pratique","format":{"html":{"toc":true,"toc-depth":3,"toc-location":"left","number-sections":true,"code-fold":true,"code-overflow":"wrap"}},"editor":"visual"},"headingText":"Introduction","headingAttr":{"id":"sec-introduction","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n\n### Bienvenue !\n\nCe workshop vous guidera à travers le déploiement complet d'un modèle de Machine Learning en production sur Microsoft Azure. Vous allez construire une API de prédiction de défaillance client (churn) et la déployer sur le cloud avec toutes les bonnes pratiques MLOps.\n\n### Objectifs d'Apprentissage {#sec-objectifs}\n\nÀ la fin de ce workshop, vous serez capable de :\n\n-   Entraîner et sauvegarder un modèle ML avec MLflow\n-   Créer une API REST avec FastAPI\n-   Conteneuriser une application avec Docker\n-   Déployer sur Azure Container Apps\n-   Mettre en place un pipeline CI/CD avec GitHub Actions\n-   Monitorer votre application en production\n-   Détecter le data drift\n\n### Le Projet : Bank Churn Prediction {#sec-projet}\n\n**Contexte :** Une banque souhaite prédire quels clients risquent de partir pour proposer des actions de rétention.\n\n**Dataset :** 10 features (âge, score crédit, solde, etc.) + 1 target (Exited : 0/1)\n\n**Modèle :** Random Forest Classifier\n\n**Livrable :** API REST déployée sur Azure, accessible publiquement\n\n### Architecture Finale {#sec-architecture}\n\n**Flux de déploiement :**\n\n`Code GitHub` → `GitHub Actions` → `Docker Build` → `Azure Container Registry` → `Azure Container Apps` → `Internet`\n\n## Préparation de l'Environnement {#sec-preparation}\n\n### Logiciels Requis {#sec-logiciels}\n\n**Obligatoire :**\n\n-   Python 3.9+ : https://www.python.org/downloads/\n-   Visual Studio Code : https://code.visualstudio.com/\n-   Git : https://git-scm.com/downloads\n-   Docker Desktop : https://www.docker.com/products/docker-desktop\n-   Azure CLI : https://docs.microsoft.com/cli/azure/install-azure-cli\n\n**Comptes à créer :**\n\n-   Compte GitHub : https://github.com/signup\n-   Azure for Students (100\\$) : https://azure.microsoft.com/students\n\n### Vérification de l'Installation {#sec-verification}\n\nOuvrez un terminal et testez :\n\n``` bash\n# Python\npython --version\n# Doit afficher Python 3.9.x ou superieur\n\n# Git\ngit --version\n\n# Docker\ndocker --version\ndocker ps\n\n# Azure CLI\naz --version\n```\n\n### Configuration Initiale {#sec-configuration}\n\n#### Configuration Git {#sec-config-git}\n\n``` bash\ngit config --global user.name \"Votre Nom\"\ngit config --global user.email \"votre.email@example.com\"\n```\n\n#### Connexion à Azure {#sec-config-azure}\n\n``` bash\n# Se connecter a Azure\naz login\n\n# Verifier l'abonnement\naz account show\n\n# Si vous avez plusieurs abonnements, selectionner celui de Students\naz account set --subscription \"Azure for Students\"\n```\n\n## Module 1 : Entraînement du Modèle {#sec-module1}\n\n### Objectif {#sec-module1-objectif}\n\nEntraîner un modèle Random Forest pour prédire le churn et le sauvegarder avec MLflow.\n\n### Préparation du Projet {#sec-module1-preparation}\n\n``` bash\n# Creer le dossier du projet\nmkdir bank-churn-mlops\ncd bank-churn-mlops\n\n# Creer un environnement virtuel\npython -m venv venv\n\n# Activer l'environnement\n# Windows :\nvenv\\Scripts\\activate\n# Mac/Linux :\nsource venv/bin/activate\n\n# Creer la structure\nmkdir -p data model app tests\ntouch requirements.txt\n```\n\n### Fichier requirements.txt {#sec-module1-requirements}\n\nCréez le fichier `requirements.txt` avec le contenu suivant :\n\n```         \n# API Framework\nfastapi==0.104.1\nuvicorn[standard]==0.24.0\npydantic==2.5.0\n\n# Machine Learning\nscikit-learn==1.3.2\npandas==2.1.3\nnumpy==1.26.2\njoblib==1.3.2\n\n# MLflow\nmlflow==2.8.1\n\n# Testing\npytest==7.4.3\npytest-cov==4.1.0\nhttpx==0.25.2\n\n# Utilities\npython-multipart==0.0.6\nrequests==2.31.0\n```\n\nPuis installez les dépendances :\n\n``` bash\npip install -r requirements.txt\n```\n\n### Téléchargement du Dataset {#sec-module1-dataset}\n\nCréez un dataset synthétique :\n\n``` python\n# generate_data.py\nimport pandas as pd\nimport numpy as np\n\nnp.random.seed(42)\nn_samples = 10000\n\ndata = {\n    'CreditScore': np.random.randint(300, 850, n_samples),\n    'Age': np.random.randint(18, 80, n_samples),\n    'Tenure': np.random.randint(0, 11, n_samples),\n    'Balance': np.random.uniform(0, 200000, n_samples),\n    'NumOfProducts': np.random.randint(1, 5, n_samples),\n    'HasCrCard': np.random.choice([0, 1], n_samples),\n    'IsActiveMember': np.random.choice([0, 1], n_samples),\n    'EstimatedSalary': np.random.uniform(20000, 150000, n_samples),\n    'Geography_Germany': np.random.choice([0, 1], n_samples),\n    'Geography_Spain': np.random.choice([0, 1], n_samples),\n}\n\n# Target : plus de chance de partir si inactif, peu de produits, etc.\nchurn_prob = (\n    (1 - data['IsActiveMember']) * 0.3 +\n    (data['NumOfProducts'] == 1) * 0.2 +\n    (data['Age'] > 60) * 0.15 +\n    (data['Balance'] == 0) * 0.25\n)\ndata['Exited'] = (np.random.random(n_samples) < churn_prob).astype(int)\n\ndf = pd.DataFrame(data)\ndf.to_csv('data/bank_churn.csv', index=False)\nprint(f\"Dataset cree : {len(df)} lignes\")\nprint(f\"Taux de churn : {df['Exited'].mean():.2%}\")\n```\n\n### Script d'Entraînement {#sec-module1-training}\n\nCréez le fichier `train_model.py` :\n\n``` python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, \n    precision_score, \n    recall_score,\n    f1_score, \n    roc_auc_score,\n    confusion_matrix\n)\nimport joblib\nimport mlflow\nimport mlflow.sklearn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configuration MLflow\nmlflow.set_tracking_uri(\"./mlruns\")\nmlflow.set_experiment(\"bank-churn-prediction\")\n\nprint(\"Chargement des donnees...\")\ndf = pd.read_csv(\"data/bank_churn.csv\")\n\nprint(f\"Dataset : {len(df)} lignes, {len(df.columns)} colonnes\")\nprint(f\"Taux de churn : {df['Exited'].mean():.2%}\")\n\n# Separation features/target\nX = df.drop('Exited', axis=1)\ny = df['Exited']\n\n# Split train/test (80/20)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(f\"\\nTrain : {len(X_train)} lignes\")\nprint(f\"Test : {len(X_test)} lignes\")\n\n# Entrainement avec MLflow tracking\nprint(\"\\nEntrainement du modele...\")\nwith mlflow.start_run(run_name=\"random-forest-v1\"):\n    \n    # Parametres du modele\n    params = {\n        'n_estimators': 100,\n        'max_depth': 10,\n        'min_samples_split': 5,\n        'random_state': 42\n    }\n    \n    # Entrainement\n    model = RandomForestClassifier(**params)\n    model.fit(X_train, y_train)\n    \n    # Predictions\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    \n    # Calcul des metriques\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    \n    # Log des parametres et metriques dans MLflow\n    mlflow.log_params(params)\n    mlflow.log_metrics({\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1_score\": f1,\n        \"roc_auc\": auc\n    })\n    \n    # Creation et sauvegarde de la matrice de confusion\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title('Matrice de Confusion')\n    plt.ylabel('Vraie Classe')\n    plt.xlabel('Classe Predite')\n    plt.savefig('confusion_matrix.png')\n    mlflow.log_artifact('confusion_matrix.png')\n    plt.close()\n    \n    # Feature importance\n    feature_importance = pd.DataFrame({\n        'feature': X.columns,\n        'importance': model.feature_importances_\n    }).sort_values('importance', ascending=False)\n    \n    plt.figure(figsize=(10, 6))\n    plt.barh(feature_importance['feature'], feature_importance['importance'])\n    plt.xlabel('Importance')\n    plt.title('Feature Importance')\n    plt.tight_layout()\n    plt.savefig('feature_importance.png')\n    mlflow.log_artifact('feature_importance.png')\n    plt.close()\n    \n    # Enregistrement du modele dans MLflow\n    mlflow.sklearn.log_model(\n        model,\n        \"model\",\n        registered_model_name=\"bank-churn-classifier\"\n    )\n    \n    # Sauvegarde locale du modele\n    joblib.dump(model, \"model/churn_model.pkl\")\n    \n    # Tags\n    mlflow.set_tags({\n        \"environment\": \"development\",\n        \"model_type\": \"RandomForest\",\n        \"task\": \"binary_classification\"\n    })\n    \n    # Affichage des resultats\n    print(\"\\n\" + \"=\"*50)\n    print(\"RESULTATS DE L'ENTRAINEMENT\")\n    print(\"=\"*50)\n    print(f\"Accuracy  : {accuracy:.4f}\")\n    print(f\"Precision : {precision:.4f}\")\n    print(f\"Recall    : {recall:.4f}\")\n    print(f\"F1 Score  : {f1:.4f}\")\n    print(f\"ROC AUC   : {auc:.4f}\")\n    print(\"=\"*50)\n    \n    print(f\"\\nModele sauvegarde dans : model/churn_model.pkl\")\n    print(f\"MLflow UI : mlflow ui --port 5000\")\n```\n\n### Exécution {#sec-module1-execution}\n\n``` bash\n# Lancer l'entrainement\npython train_model.py\n\n# Voir les resultats dans MLflow UI\nmlflow ui --port 5000\n# Ouvrir http://localhost:5000 dans votre navigateur\n```\n\n### Checkpoint {#sec-module1-checkpoint}\n\n:::: callout-note\n## Validation Module 1\n\nAvant de passer au module suivant, vérifiez que :\n\n::: {style=\"margin-left: 20px;\"}\n-   [ ] Le modèle est entraîné avec une accuracy \\> 0.75\n-   [ ] Le fichier `model/churn_model.pkl` existe\n-   [ ] MLflow UI affiche votre expérience\n-   [ ] Vous comprenez les métriques obtenues\n:::\n::::\n\n## Module 2 : Création de l'API avec FastAPI {#sec-module2}\n\n### Objectif {#sec-module2-objectif}\n\nCréer une API REST qui expose le modèle via des endpoints HTTP.\n\n### Structure du Code API {#sec-module2-structure}\n\n```         \nbank-churn-mlops/\n|-- app/\n|   |-- __init__.py\n|   |-- main.py\n|   |-- models.py\n|   +-- utils.py\n|-- model/\n|   +-- churn_model.pkl\n|-- tests/\n|   +-- test_api.py\n|-- requirements.txt\n+-- README.md\n```\n\n### Fichier app/models.py {#sec-module2-models}\n\nDéfinition des schémas de données avec Pydantic :\n\n``` python\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass CustomerFeatures(BaseModel):\n    \"\"\"Schema pour les features d'un client\"\"\"\n    CreditScore: int = Field(..., ge=300, le=850, description=\"Score de credit\")\n    Age: int = Field(..., ge=18, le=100, description=\"Age du client\")\n    Tenure: int = Field(..., ge=0, le=10, description=\"Anciennete en annees\")\n    Balance: float = Field(..., ge=0, description=\"Solde du compte\")\n    NumOfProducts: int = Field(..., ge=1, le=4, description=\"Nombre de produits\")\n    HasCrCard: int = Field(..., ge=0, le=1, description=\"Possession carte credit\")\n    IsActiveMember: int = Field(..., ge=0, le=1, description=\"Membre actif\")\n    EstimatedSalary: float = Field(..., ge=0, description=\"Salaire estime\")\n    Geography_Germany: int = Field(..., ge=0, le=1, description=\"Client allemand\")\n    Geography_Spain: int = Field(..., ge=0, le=1, description=\"Client espagnol\")\n    \n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"CreditScore\": 650,\n                \"Age\": 35,\n                \"Tenure\": 5,\n                \"Balance\": 50000,\n                \"NumOfProducts\": 2,\n                \"HasCrCard\": 1,\n                \"IsActiveMember\": 1,\n                \"EstimatedSalary\": 75000,\n                \"Geography_Germany\": 0,\n                \"Geography_Spain\": 1\n            }\n        }\n\nclass PredictionResponse(BaseModel):\n    \"\"\"Schema pour la reponse de prediction\"\"\"\n    churn_probability: float = Field(..., description=\"Probabilite de churn (0-1)\")\n    prediction: int = Field(..., description=\"Prediction binaire (0=reste, 1=part)\")\n    risk_level: str = Field(..., description=\"Niveau de risque (Low/Medium/High)\")\n\nclass HealthResponse(BaseModel):\n    \"\"\"Schema pour le health check\"\"\"\n    status: str\n    model_loaded: bool\n```\n\n### Fichier app/main.py {#sec-module2-main}\n\nL'API principale :\n\n``` python\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nimport joblib\nimport numpy as np\nfrom typing import List\nimport logging\nimport os\n\nfrom app.models import CustomerFeatures, PredictionResponse, HealthResponse\n\n# Configuration du logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Initialisation FastAPI\napp = FastAPI(\n    title=\"Bank Churn Prediction API\",\n    description=\"API de prediction de defaillance client\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\"\n)\n\n# CORS pour permettre les requetes depuis un navigateur\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Chargement du modele au demarrage\nMODEL_PATH = os.getenv(\"MODEL_PATH\", \"model/churn_model.pkl\")\nmodel = None\n\n@app.on_event(\"startup\")\nasync def load_model():\n    \"\"\"Charge le modele au demarrage de l'API\"\"\"\n    global model\n    try:\n        model = joblib.load(MODEL_PATH)\n        logger.info(f\"Modele charge avec succes depuis {MODEL_PATH}\")\n    except Exception as e:\n        logger.error(f\"Erreur lors du chargement du modele : {e}\")\n        model = None\n\n@app.get(\"/\", tags=[\"General\"])\ndef root():\n    \"\"\"Endpoint racine\"\"\"\n    return {\n        \"message\": \"Bank Churn Prediction API\",\n        \"version\": \"1.0.0\",\n        \"status\": \"running\",\n        \"docs\": \"/docs\"\n    }\n\n@app.get(\"/health\", response_model=HealthResponse, tags=[\"General\"])\ndef health_check():\n    \"\"\"Verification de l'etat de l'API\"\"\"\n    if model is None:\n        raise HTTPException(\n            status_code=503, \n            detail=\"Modele non charge\"\n        )\n    return {\n        \"status\": \"healthy\",\n        \"model_loaded\": True\n    }\n\n@app.post(\"/predict\", response_model=PredictionResponse, tags=[\"Prediction\"])\ndef predict(features: CustomerFeatures):\n    \"\"\"\n    Predit si un client va partir (churn)\n    \n    Retourne :\n    - churn_probability : probabilite de churn (0 a 1)\n    - prediction : 0 (reste) ou 1 (part)\n    - risk_level : Low, Medium ou High\n    \"\"\"\n    if model is None:\n        raise HTTPException(\n            status_code=503, \n            detail=\"Modele non disponible\"\n        )\n    \n    try:\n        # Preparation des features\n        input_data = np.array([[\n            features.CreditScore,\n            features.Age,\n            features.Tenure,\n            features.Balance,\n            features.NumOfProducts,\n            features.HasCrCard,\n            features.IsActiveMember,\n            features.EstimatedSalary,\n            features.Geography_Germany,\n            features.Geography_Spain\n        ]])\n        \n        # Prediction\n        proba = model.predict_proba(input_data)[0, 1]\n        prediction = int(proba > 0.5)\n        \n        # Classification du risque\n        if proba < 0.3:\n            risk = \"Low\"\n        elif proba < 0.7:\n            risk = \"Medium\"\n        else:\n            risk = \"High\"\n        \n        logger.info(\n            f\"Prediction effectuee : proba={proba:.4f}, \"\n            f\"prediction={prediction}, risk={risk}\"\n        )\n        \n        return {\n            \"churn_probability\": round(float(proba), 4),\n            \"prediction\": prediction,\n            \"risk_level\": risk\n        }\n    \n    except Exception as e:\n        logger.error(f\"Erreur lors de la prediction : {e}\")\n        raise HTTPException(\n            status_code=500, \n            detail=f\"Erreur de prediction : {str(e)}\"\n        )\n\n@app.post(\"/predict/batch\", tags=[\"Prediction\"])\ndef predict_batch(features_list: List[CustomerFeatures]):\n    \"\"\"\n    Predictions en batch pour plusieurs clients\n    \"\"\"\n    if model is None:\n        raise HTTPException(status_code=503, detail=\"Modele non disponible\")\n    \n    try:\n        predictions = []\n        \n        for features in features_list:\n            input_data = np.array([[\n                features.CreditScore, features.Age, features.Tenure,\n                features.Balance, features.NumOfProducts, features.HasCrCard,\n                features.IsActiveMember, features.EstimatedSalary,\n                features.Geography_Germany, features.Geography_Spain\n            ]])\n            \n            proba = model.predict_proba(input_data)[0, 1]\n            prediction = int(proba > 0.5)\n            \n            predictions.append({\n                \"churn_probability\": round(float(proba), 4),\n                \"prediction\": prediction\n            })\n        \n        logger.info(f\"Batch prediction : {len(predictions)} clients traites\")\n        \n        return {\"predictions\": predictions, \"count\": len(predictions)}\n    \n    except Exception as e:\n        logger.error(f\"Erreur batch prediction : {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n```\n\n### Test Local de l'API {#sec-module2-test}\n\n``` bash\n# Demarrer l'API\nuvicorn app.main:app --reload --port 8000\n\n# Dans un autre terminal, tester :\n\n# 1. Health check\ncurl http://localhost:8000/health\n\n# 2. Prediction simple\ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n  }'\n```\n### Jupyter Lab \n\n```python\n#dans jupyter lab\nimport requests\nimport json\n\n# URL de ton API FastAPI\nurl = \"http://localhost:8000/predict\"\n\n# Données à envoyer\ndata = {\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n}\n\n# Envoyer la requête POST\nresponse = requests.post(url, json=data)\n\n# Afficher la réponse\nprint(f\"Status Code: {response.status_code}\")\nprint(f\"Response: {response.json()}\")\n```\n\n### Documentation Interactive {#sec-module2-docs}\n\nOuvrez votre navigateur et allez sur :\n\n-   **Swagger UI** : http://localhost:8000/docs\n-   **ReDoc** : http://localhost:8000/redoc\n\n### Checkpoint {#sec-module2-checkpoint}\n\n:::: callout-note\n## Validation Module 2\n\nAvant de passer au module suivant, vérifiez que :\n\n::: {style=\"margin-left: 20px;\"}\n-   [ ] Le modèle est entraîné avec une accuracy \\> 0.75\n-   [ ] Le fichier `model/churn_model.pkl` existe\\\n-   [ ] MLflow UI affiche votre expérience\n-   [ ] Vous comprenez les métriques obtenues\n:::\n::::\n\n## Module 3 : Conteneurisation avec Docker {#sec-module3}\n\n### Objectif {#sec-module3-objectif}\n\nEmpaqueter l'API dans un conteneur Docker pour la rendre portable et faciliter le déploiement sur Azure.\n\n### Création du Dockerfile {#sec-module3-dockerfile}\n\nCréez le fichier `Dockerfile` à la racine du projet :\n\n``` dockerfile\n# Utilise une image Python officielle\nFROM python:3.9-slim\n\n# Definir le repertoire de travail\nWORKDIR /app\n\n# Copier les fichiers de dependances\nCOPY requirements.txt .\n\n# Installer les dependances\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copier le code de l'application\nCOPY app/ ./app/\nCOPY model/ ./model/\n\n# Exposer le port\nEXPOSE 8000\n\n# Commande pour demarrer l'application\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```\n\n### Création du .dockerignore {#sec-module3-dockerignore}\n\nCréez le fichier `.dockerignore` :\n\n```         \n__pycache__\n*.pyc\n*.pyo\n*.pyd\n.Python\nenv/\nvenv/\n.venv\n*.egg-info/\n.pytest_cache/\n.git\n.gitignore\nREADME.md\n.env\nmlruns/\n*.log\n.DS_Store\n.vscode/\ntests/\n```\n\n### Build de l'Image Docker {#sec-module3-build}\n\n``` bash\n# Build de l'image (cela peut prendre quelques minutes)\ndocker build -t bank-churn-api:v1 .\n\n# Verifier que l'image est creee\ndocker images bank-churn-api:v1\n\n# Voir la taille de l'image\ndocker images --format \"table {{.Repository}}\\t{{.Tag}}\\t{{.Size}}\" | grep bank-churn\n```\n\n### Test du Conteneur en Local {#sec-module3-test}\n\n``` bash\n# Lancer le conteneur\ndocker run -d -p 8000:8000 --name churn-api bank-churn-api:v1\n\n# Verifier que le conteneur tourne\ndocker ps\n\n# Voir les logs\ndocker logs churn-api\n\n# Tester l'API\ncurl http://localhost:8000/health\n\n# Prediction de test\ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 700,\n    \"Age\": 40,\n    \"Tenure\": 7,\n    \"Balance\": 80000,\n    \"NumOfProducts\": 3,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 0,\n    \"EstimatedSalary\": 90000,\n    \"Geography_Germany\": 1,\n    \"Geography_Spain\": 0\n  }'\n\n# Arreter et supprimer le conteneur\ndocker stop churn-api\ndocker rm churn-api\n```\n\n### Commandes Docker Utiles {#sec-module3-commandes}\n\n``` bash\n# Voir tous les conteneurs (meme arretes)\ndocker ps -a\n\n# Entrer dans un conteneur en cours d'execution\ndocker exec -it churn-api /bin/bash\n\n# Voir l'utilisation des ressources\ndocker stats churn-api\n\n# Nettoyer les images inutilisees\ndocker image prune\n\n# Supprimer toutes les images\ndocker rmi $(docker images -q)\n```\n\n### Questions de Compréhension {#sec-module3-questions}\n\n1.  Pourquoi utiliser un .dockerignore ?\n2.  Quelle est la différence entre CMD et RUN dans un Dockerfile ?\n3.  Pourquoi exposer le port 8000 ?\n4.  Comment vérifier que votre conteneur fonctionne correctement ?\n\n### Checkpoint {#sec-module3-checkpoint}\n\n:::: callout-note\n## Validation Module 3\n\nAvant de passer au module suivant, vérifiez que :\n\n::: {style=\"margin-left: 20px;\"}\n-   [ ] L'image Docker est buildée avec succès\n-   [ ] Le conteneur démarre sans erreur\n-   [ ] L'API répond correctement depuis le conteneur\n-   [ ] La taille de l'image est raisonnable (\\< 1GB)\n:::\n::::\n\n## Module 4 : Déploiement sur Azure {#sec-module4}\n\n### Objectif {#sec-module4-objectif}\n\nDéployer l'API sur Azure Container Apps et la rendre accessible publiquement.\n\n### Étape 1 : Création du Groupe de Ressources {#sec-module4-etape1}\n\n``` bash\n# Variables (MODIFIEZ avec vos valeurs)\nRESOURCE_GROUP=\"rg-mlops-workshop\"\nLOCATION=\"westeurope\"\nACR_NAME=\"acrmlops$(whoami)$(date +%s)\"  # Doit etre unique globalement\nCONTAINER_APP_NAME=\"app-churn-api\"\n\n# Creation du groupe de ressources\naz group create \\\n  --name $RESOURCE_GROUP \\\n  --location $LOCATION\n\necho \"Groupe de ressources cree : $RESOURCE_GROUP\"\n```\n\n### Étape 2 : Azure Container Registry (ACR) {#sec-module4-etape2}\n\n``` bash\n# Creation du registry (SKU Basic pour economiser)\naz acr create \\\n  --resource-group $RESOURCE_GROUP \\\n  --name $ACR_NAME \\\n  --sku Basic \\\n  --admin-enabled true\n\necho \"Container Registry cree : $ACR_NAME\"\n\n# Se connecter au registry\naz acr login --name $ACR_NAME\n\n# Verifier la connexion\naz acr show --name $ACR_NAME --query loginServer --output tsv\n```\n\n### Étape 3 : Push de l'Image vers ACR {#sec-module4-etape3}\n\n``` bash\n# Recuperer l'URL du registry\nACR_LOGIN_SERVER=$(az acr show --name $ACR_NAME --query loginServer --output tsv)\n\n# Tagger l'image pour ACR\ndocker tag bank-churn-api:v1 $ACR_LOGIN_SERVER/bank-churn-api:v1\ndocker tag bank-churn-api:v1 $ACR_LOGIN_SERVER/bank-churn-api:latest\n\n# Pousser l'image vers ACR\ndocker push $ACR_LOGIN_SERVER/bank-churn-api:v1\ndocker push $ACR_LOGIN_SERVER/bank-churn-api:latest\n\n# Verifier que l'image est bien dans ACR\naz acr repository list --name $ACR_NAME --output table\naz acr repository show-tags --name $ACR_NAME --repository bank-churn-api --output table\n```\n\n### Étape 4 : Création de l'Environnement Container Apps {#sec-module4-etape4}\n\n``` bash\n# Variables\nCONTAINERAPPS_ENV=\"env-mlops-workshop\"\n\n# Creation de l'environnement\naz containerapp env create \\\n  --name $CONTAINERAPPS_ENV \\\n  --resource-group $RESOURCE_GROUP \\\n  --location $LOCATION\n\necho \"Environnement Container Apps cree : $CONTAINERAPPS_ENV\"\n```\n\n### Étape 5 : Déploiement de l'Application {#sec-module4-etape5}\n\n``` bash\n# Recuperer les credentials ACR\nACR_USERNAME=$(az acr credential show --name $ACR_NAME --query username -o tsv)\nACR_PASSWORD=$(az acr credential show --name $ACR_NAME --query passwords[0].value -o tsv)\n\n# Deployer l'application\naz containerapp create \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --environment $CONTAINERAPPS_ENV \\\n  --image $ACR_LOGIN_SERVER/bank-churn-api:v1 \\\n  --registry-server $ACR_LOGIN_SERVER \\\n  --registry-username $ACR_USERNAME \\\n  --registry-password $ACR_PASSWORD \\\n  --target-port 8000 \\\n  --ingress external \\\n  --min-replicas 1 \\\n  --max-replicas 3 \\\n  --cpu 0.5 \\\n  --memory 1Gi\n\necho \"Application deployee !\"\n```\n\n### Étape 6 : Récupérer l'URL Publique {#sec-module4-etape6}\n\n``` bash\n# Recuperer l'URL de l'application\nAPP_URL=$(az containerapp show \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --query properties.configuration.ingress.fqdn -o tsv)\n\necho \"==========================================\"\necho \"API deployee avec succes !\"\necho \"URL : https://$APP_URL\"\necho \"Health check : https://$APP_URL/health\"\necho \"Documentation : https://$APP_URL/docs\"\necho \"==========================================\"\n\n# Tester l'API deployee\ncurl https://$APP_URL/health\n```\n\n### Étape 7 : Test de l'API en Production {#sec-module4-etape7}\n\n``` bash\n# Test de prediction\ncurl -X POST \"https://$APP_URL/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n  }'\n```\n\n### Surveillance des Coûts {#sec-module4-couts}\n\n::: callout-warning\n## IMPORTANT - Gestion du Budget\n\nPour éviter de dépasser le budget de 100\\$ :\n\n``` bash\n# Voir les couts estimes\naz consumption usage list \\\n  --start-date 2024-11-01 \\\n  --end-date 2024-11-30 \\\n  --output table\n\n# Mettre l'application en veille (min-replicas=0)\naz containerapp update \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --min-replicas 0 \\\n  --max-replicas 3\n```\n\nCoûts estimés pour ce workshop : 8-12\\$ pour 10 heures d'utilisation.\n:::\n\n### Exercice Pratique {#sec-module4-exercice}\n\n::: callout-tip\n## EXERCICE 2\n\nPartagez votre URL d'API avec un camarade et testez son API :\n\n1.  Faites 10 prédictions sur son API\n2.  Comparez les résultats avec votre modèle\n3.  Observez les logs dans Azure Portal\n:::\n\n### Checkpoint {#sec-module4-checkpoint}\n\n:::: callout-note\n## Validation Module 4\n\nAvant de passer au module suivant, vérifiez que :\n\n::: {style=\"margin-left: 20px;\"}\n-   [ ] L'application est accessible via HTTPS\n-   [ ] Le health check fonctionne\n-   [ ] Les prédictions fonctionnent\n-   [ ] Vous avez noté l'URL publique de votre API\n:::\n::::\n\n## Module 5 : CI/CD avec GitHub Actions {#sec-module5}\n\n### Objectif {#sec-module5-objectif}\n\nAutomatiser le déploiement : chaque commit sur la branche main déclenche un build et un redéploiement.\n\n### Étape 1 : Initialisation du Repository Git {#sec-module5-etape1}\n\n``` bash\n# Initialiser git (si pas deja fait)\ngit init\n\n# Creer un .gitignore\ncat > .gitignore << EOF\n__pycache__/\n*.pyc\nvenv/\n.env\nmlruns/\n*.log\n.DS_Store\n.vscode/\nconfusion_matrix.png\nfeature_importance.png\nEOF\n\n# Premier commit\ngit add .\ngit commit -m \"Initial commit: Bank Churn API\"\n```\n\n### Étape 2 : Créer un Repository GitHub {#sec-module5-etape2}\n\n1.  Allez sur https://github.com/new\n2.  Nom du repository : `bank-churn-mlops`\n3.  Visibility : Public ou Private\n4.  Ne pas initialiser avec README (déjà fait localement)\n5.  Cliquez sur \"Create repository\"\n\n``` bash\n# Lier votre repo local a GitHub (REMPLACEZ username)\ngit remote add origin https://github.com/username/bank-churn-mlops.git\ngit branch -M main\ngit push -u origin main\n```\n\n### Étape 3 : Configuration des Secrets GitHub {#sec-module5-etape3}\n\n#### Créer un Service Principal Azure {#sec-module5-service-principal}\n\n``` bash\n# Recuperer votre Subscription ID\nSUBSCRIPTION_ID=$(az account show --query id -o tsv)\n\n# Creer un Service Principal\naz ad sp create-for-rbac \\\n  --name \"github-actions-mlops\" \\\n  --role contributor \\\n  --scopes /subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP \\\n  --sdk-auth\n```\n\nCopiez tout le JSON retourné.\n\n#### Ajouter les Secrets dans GitHub {#sec-module5-secrets}\n\n1.  Allez dans votre repository GitHub\n2.  Settings \\> Secrets and variables \\> Actions\n3.  Cliquez sur \"New repository secret\"\n4.  Ajoutez les secrets suivants :\n\n| **Nom** | **Valeur** |\n|------------------------------------|------------------------------------|\n| AZURE_CREDENTIALS | Le JSON du Service Principal |\n| ACR_USERNAME | Résultat de : `az acr credential show --name $ACR_NAME --query username -o tsv` |\n| ACR_PASSWORD | Résultat de : `az acr credential show --name $ACR_NAME --query passwords[0].value -o tsv` |\n\n### Étape 4 : Création du Workflow GitHub Actions {#sec-module5-etape4}\n\nCréez le fichier `.github/workflows/ci-cd.yml` :\n\n``` yaml\nname: CI/CD Pipeline\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n  workflow_dispatch:\n\nenv:\n  AZURE_RESOURCE_GROUP: rg-mlops-workshop\n  ACR_NAME: votre-acr-name  # MODIFIEZ ICI\n  CONTAINER_APP_NAME: app-churn-api\n  IMAGE_NAME: bank-churn-api\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n      \n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.9'\n      \n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements.txt\n          pip install pytest pytest-cov\n      \n      - name: Run tests\n        run: |\n          pytest tests/ -v --cov=app --cov-report=term\n      \n  build-and-deploy:\n    needs: test\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'\n    \n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n      \n      - name: Azure Login\n        uses: azure/login@v1\n        with:\n          creds: ${{ secrets.AZURE_CREDENTIALS }}\n      \n      - name: Login to ACR\n        uses: azure/docker-login@v1\n        with:\n          login-server: ${{ env.ACR_NAME }}.azurecr.io\n          username: ${{ secrets.ACR_USERNAME }}\n          password: ${{ secrets.ACR_PASSWORD }}\n      \n      - name: Build and push Docker image\n        run: |\n          docker build -t ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }} .\n          docker build -t ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest .\n          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}\n          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest\n      \n      - name: Deploy to Azure Container Apps\n        uses: azure/CLI@v1\n        with:\n          inlineScript: |\n            az containerapp update \\\n              --name ${{ env.CONTAINER_APP_NAME }} \\\n              --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n              --image ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}\n      \n      - name: Verify deployment\n        run: |\n          APP_URL=$(az containerapp show \\\n            --name ${{ env.CONTAINER_APP_NAME }} \\\n            --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n            --query properties.configuration.ingress.fqdn -o tsv)\n          \n          echo \"Application deployed at: https://$APP_URL\"\n          \n          sleep 30\n          curl -f https://$APP_URL/health || exit 1\n          \n          echo \"Deployment successful!\"\n```\n\n### Étape 5 : Déclencher le Pipeline {#sec-module5-etape5}\n\n``` bash\n# Ajouter le workflow\ngit add .github/workflows/ci-cd.yml\ngit add tests/test_api.py\ngit commit -m \"Add CI/CD pipeline and tests\"\ngit push origin main\n\n# Le pipeline se declenche automatiquement !\n```\n\nAllez sur GitHub \\> Actions pour voir le pipeline en cours d'exécution.\n\n### Exercice Pratique {#sec-module5-exercice}\n\n::: callout-tip\n## EXERCICE 3\n\n1.  Ajoutez un nouveau test dans `test_api.py`\n2.  Faites un commit et push\n3.  Observez le pipeline s'exécuter\n4.  Vérifiez que le déploiement s'est bien fait\n:::\n\n### Checkpoint {#sec-module5-checkpoint}\n\n:::: callout-note\n## Validation Module 5\n\nAvant de passer au module suivant, vérifiez que :\n\n::: {style=\"margin-left: 20px; line-height: 1.8;\"}\n-   [ ] Le repository GitHub est créé\n-   [ ] Les secrets sont configurés\n-   [ ] Le workflow CI/CD s'exécute sans erreur\n-   [ ] L'application se redéploie\n:::\n\nautomatiquement\n::::\n\n## Module 6 : Monitoring et Maintenance {#sec-module6}\n\n### Objectif {#sec-module6-objectif}\n\nMettre en place le monitoring de l'application et détecter les problèmes en production.\n\n### Configuration Application Insights {#sec-module6-appinsights}\n\n``` bash\n# Creation d'Application Insights\naz monitor app-insights component create \\\n  --app bank-churn-insights \\\n  --location $LOCATION \\\n  --resource-group $RESOURCE_GROUP \\\n  --application-type web\n\n# Recuperer la connection string\nAPPINSIGHTS_CONN=$(az monitor app-insights component show \\\n  --app bank-churn-insights \\\n  --resource-group $RESOURCE_GROUP \\\n  --query connectionString -o tsv)\n\necho \"Connection String : $APPINSIGHTS_CONN\"\n\n# Ajouter la variable d'environnement a Container Apps\naz containerapp update \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --set-env-vars \"APPLICATIONINSIGHTS_CONNECTION_STRING=$APPINSIGHTS_CONN\"\n```\n\n### Intégration du Monitoring dans le Code {#sec-module6-monitoring}\n\nAjoutez dans `requirements.txt` :\n\n```         \nopencensus-ext-azure==1.1.9\nopencensus-ext-requests==0.12.1\n```\n\nModifiez `app/main.py` pour ajouter le monitoring :\n\n``` python\nimport os\nfrom opencensus.ext.azure.log_exporter import AzureLogHandler\nimport logging\n\n# Configuration du logging avec Application Insights\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n\nAPPINSIGHTS_CONN = os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\")\nif APPINSIGHTS_CONN:\n    logger.addHandler(AzureLogHandler(connection_string=APPINSIGHTS_CONN))\n    logger.info(\"Application Insights connecte\")\n```\n\n### Détection de Data Drift {#sec-module6-drift}\n\nCréez le fichier `drift_detection.py` :\n\n``` python\nimport pandas as pd\nfrom scipy.stats import ks_2samp\nimport json\n\ndef detect_drift(reference_file, production_file, threshold=0.05):\n    \"\"\"\n    Detecte le drift entre donnees de reference et production\n    \"\"\"\n    ref_data = pd.read_csv(reference_file)\n    prod_data = pd.read_csv(production_file)\n    \n    drift_results = {}\n    \n    for column in ref_data.columns:\n        if column in prod_data.columns and column != 'Exited':\n            # Test de Kolmogorov-Smirnov\n            statistic, p_value = ks_2samp(\n                ref_data[column].dropna(),\n                prod_data[column].dropna()\n            )\n            \n            drift_detected = p_value < threshold\n            \n            drift_results[column] = {\n                'p_value': float(p_value),\n                'statistic': float(statistic),\n                'drift_detected': drift_detected\n            }\n    \n    # Rapport\n    drifted_features = [f for f, r in drift_results.items() if r['drift_detected']]\n    \n    print(\"=\"*50)\n    print(\"DATA DRIFT DETECTION REPORT\")\n    print(\"=\"*50)\n    print(f\"Threshold: {threshold}\")\n    print(f\"Features analyzed: {len(drift_results)}\")\n    print(f\"Features with drift: {len(drifted_features)}\")\n    print(\"\\nDrifted features:\")\n    for feature in drifted_features:\n        print(f\"  - {feature}: p-value = {drift_results[feature]['p_value']:.4f}\")\n    print(\"=\"*50)\n    \n    return drift_results\n\nif __name__ == \"__main__\":\n    results = detect_drift(\n        \"data/bank_churn.csv\",\n        \"data/production_data.csv\"\n    )\n    \n    # Sauvegarder les resultats\n    with open(\"drift_report.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n    \n    print(\"\\nRapport sauvegarde dans drift_report.json\")\n```\n\n### Checkpoint {#sec-module6-checkpoint}\n\n:::: callout-note\n## Validation Module 6\n\nAvant de passer au module suivant, vérifiez que :\n\n::: {style=\"margin-left: 20px; line-height: 1.8;\"}\n-   [ ] Application Insights est configuré\n-   [ ] Les logs apparaissent dans Azure Portal\n-   [ ] Vous pouvez visualiser les métriques\n-   [ ] Le script de détection de drift fonctionne\n:::\n::::\n\n## Module 7 : Optimisations et Bonnes Pratiques {#sec-module7}\n\n### Objectif {#sec-module7-objectif}\n\nAméliorer les performances, la sécurité et la maintenabilité de l'application.\n\n### Ajout d'un Cache pour les Prédictions {#sec-module7-cache}\n\nModifiez `app/main.py` :\n\n``` python\nfrom functools import lru_cache\nimport hashlib\nimport json\n\ndef hash_features(features_dict: dict) -> str:\n    \"\"\"Cree un hash unique pour les features\"\"\"\n    return hashlib.md5(\n        json.dumps(features_dict, sort_keys=True).encode()\n    ).hexdigest()\n\n# Cache pour les predictions (1000 dernieres)\n@lru_cache(maxsize=1000)\ndef predict_cached(features_hash: str, features_json: str):\n    features_dict = json.loads(features_json)\n    input_data = np.array([[\n        features_dict[\"CreditScore\"],\n        features_dict[\"Age\"],\n        # ... autres features\n    ]])\n    \n    proba = model.predict_proba(input_data)[0, 1]\n    prediction = int(proba > 0.5)\n    \n    if proba < 0.3:\n        risk = \"Low\"\n    elif proba < 0.7:\n        risk = \"Medium\"\n    else:\n        risk = \"High\"\n    \n    return {\n        \"churn_probability\": round(float(proba), 4),\n        \"prediction\": prediction,\n        \"risk_level\": risk\n    }\n\n@app.post(\"/predict\", response_model=PredictionResponse)\ndef predict(features: CustomerFeatures):\n    features_dict = features.dict()\n    features_hash = hash_features(features_dict)\n    features_json = json.dumps(features_dict)\n    \n    # Utilise le cache si disponible\n    result = predict_cached(features_hash, features_json)\n    \n    logger.info(f\"Prediction - Hash: {features_hash[:8]}\")\n    return result\n```\n\n### Checklist de Production {#sec-module7-checklist}\n\n::: callout-tip\n## Checklist Avant Production\n\n-   [ ] Tests unitaires avec coverage \\> 80%\n-   [ ] Tests d'integration\n-   [ ] Load testing effectue\n-   [ ] Monitoring configure\n-   [ ] Alertes definies\n-   [ ] Logs centralises\n-   [ ] Documentation API complete\n-   [ ] HTTPS active\n-   [ ] Health checks fonctionnels\n-   [ ] Auto-scaling teste\n-   [ ] Variables d'environnement securisees\n-   [ ] Budget Azure surveille\n:::\n\n### Checkpoint Final {#sec-module7-checkpoint}\n\n:::: callout-note\n## Validation Module 7\n\n::: {style=\"margin-left: 20px; line-height: 1.8;\"}\n-   [ ] Cache de predictions implemente\n-   [ ] Documentation complete\n-   [ ] Tous les tests passent\n-   [ ] Checklist de production verifiee\n:::\n::::\n\n## Nettoyage des Ressources Azure {#sec-nettoyage}\n\n### IMPORTANT - Suppression pour Éviter les Coûts {#sec-nettoyage-important}\n\n::: callout-warning\n## ATTENTION - À FAIRE À LA FIN DU WORKSHOP\n\nPour éviter de consommer votre budget de 100\\$, supprimez toutes les ressources :\n\n``` bash\n# Suppression du groupe de ressources (supprime tout)\naz group delete --name $RESOURCE_GROUP --yes --no-wait\n\n# Verification\naz group list --output table\n```\n\nCette commande supprime : - Azure Container Registry - Azure Container Apps - Application Insights - Tous les logs et données\n\n**Temps de suppression** : 5-10 minutes\n:::\n\n### Script de Nettoyage Automatique {#sec-nettoyage-script}\n\nCréez `cleanup.sh` :\n\n``` bash\n#!/bin/bash\n\nRESOURCE_GROUP=\"rg-mlops-workshop\"\n\necho \"==========================================\"\necho \"Nettoyage des ressources Azure\"\necho \"==========================================\"\n\nread -p \"Voulez-vous vraiment supprimer toutes les ressources ? (yes/no): \" confirm\n\nif [ \"$confirm\" != \"yes\" ]; then\n    echo \"Operation annulee.\"\n    exit 0\nfi\n\necho \"\\nRessources a supprimer:\"\naz resource list --resource-group $RESOURCE_GROUP --output table\n\necho \"\\nSuppression en cours...\"\naz group delete --name $RESOURCE_GROUP --yes --no-wait\n\necho \"\\nSuppression lancee (prend 5-10 minutes)\"\necho \"Verifiez sur : https://portal.azure.com\"\n```\n\n``` bash\n# Rendre executable et lancer\nchmod +x cleanup.sh\n./cleanup.sh\n```\n\n## Récapitulatif du Workshop {#sec-recapitulatif}\n\n### Ce que Vous Avez Accompli {#sec-recap-accompli}\n\nFélicitations ! Vous avez déployé un système MLOps complet :\n\n**Architecture Finale :**\n\n`ML Training` → `FastAPI` → `Docker` → `Azure Container Registry` → `Azure Container Apps`\n\n↑ `GitHub Actions CI/CD`\n\n↑ `Application Insights Monitoring`\n\n### Compétences Acquises {#sec-recap-competences}\n\n1.  **Machine Learning**\n    -   Entraînement d'un modèle Random Forest\n    -   Évaluation avec métriques appropriées\n    -   Tracking avec MLflow\n2.  **Développement d'API**\n    -   Création d'API REST avec FastAPI\n    -   Validation des données avec Pydantic\n    -   Documentation automatique\n3.  **Conteneurisation**\n    -   Dockerfiles optimisés\n    -   Bonnes pratiques de sécurité\n    -   Gestion des images\n4.  **Cloud Azure**\n    -   Azure Container Registry\n    -   Azure Container Apps\n    -   Application Insights\n5.  **DevOps/MLOps**\n    -   Pipelines CI/CD avec GitHub Actions\n    -   Tests automatisés\n    -   Déploiement continu\n6.  **Monitoring et Maintenance**\n    -   Logs centralisés\n    -   Métriques de performance\n    -   Détection de data drift\n\n### Points Clés à Retenir {#sec-recap-points-cles}\n\n::: callout-important\n## Lecons Importantes\n\n1.  **MLOps = DevOps + ML** : Automatisation du cycle de vie complet\n2.  **Conteneurisation** : Portabilité et reproductibilité\n3.  **Tests** : Essentiels pour la fiabilité\n4.  **Monitoring** : Indispensable en production\n5.  **Documentation** : Facilite la collaboration\n6.  **Sécurité** : À considérer dès le début\n7.  **Coûts** : Toujours surveiller l'utilisation cloud\n:::\n\n## FAQ - Foire Aux Questions {#sec-faq}\n\n### Questions Techniques {#sec-faq-techniques}\n\n**Q1 : Mon API est lente, comment l'optimiser ?**\n\n*R :* Plusieurs options : - Activer le cache des prédictions - Utiliser des prédictions batch - Optimiser le modèle (quantization, pruning) - Augmenter les ressources CPU/RAM\n\n**Q2 : Comment gérer plusieurs versions de modèles ?**\n\n*R :* Utilisez MLflow Model Registry et créez des endpoints différents (v1, v2).\n\n**Q3 : Comment implémenter un rollback ?**\n\n*R :* Conservez les anciennes images Docker avec tags et utilisez :\n\n``` bash\naz containerapp update \\\n  --name $APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --image $ACR_NAME.azurecr.io/bank-churn-api:v1  # Version precedente\n```\n\n**Q4 : Mon budget Azure est presque épuisé, que faire ?**\n\n*R :* - Mettre min-replicas à 0 - Utiliser des SKU Basic - Supprimer les ressources inutilisées - Activer les budgets alerts\n\n### Questions de Compréhension {#sec-faq-comprehension}\n\n**Q5 : Quelle est la différence entre Docker et Kubernetes ?**\n\n*R :* Docker conteneurise les applications, Kubernetes les orchestre (scaling, load balancing, self-healing).\n\n**Q6 : Pourquoi utiliser FastAPI plutôt que Flask ?**\n\n*R :* FastAPI est plus rapide, avec validation automatique, documentation auto-générée, et support async natif.\n\n**Q7 : Qu'est-ce que le data drift ?**\n\n*R :* Changement dans la distribution des données d'entrée par rapport aux données d'entraînement, pouvant dégrader les performances du modèle.\n\n## Conclusion {#sec-conclusion}\n\n### Félicitations ! {#sec-conclusion-felicitations}\n\nVous avez terminé ce workshop intensif de MLOps avec Azure. Vous avez construit un système complet de déploiement de modèle de Machine Learning en production, avec toutes les bonnes pratiques de l'industrie.\n\n### Prochaines Étapes {#sec-conclusion-next-steps}\n\n1.  **Pratiquez** : Refaites le workshop avec un dataset différent\n2.  **Partagez** : Mettez votre projet sur GitHub\n3.  **Améliorez** : Implémentez les fonctionnalités avancées\n4.  **Certifiez-vous** : Préparez les certifications Azure\n\n------------------------------------------------------------------------\n\n**Bon Apprentissage et Bon Déploiement !**\n\n*Ce guide vous a accompagné dans votre premier projet MLOps.\\\nContinuez à explorer, à apprendre et à innover.*\n\n------------------------------------------------------------------------\n\n*Version 1.0 - Novembre 2025*\\\n*Workshop MLOps avec Azure* \\n\\## Test de déploiement - jeu. 20 nov. 2025 03:26:42","srcMarkdownNoYaml":"\n\n## Introduction {#sec-introduction}\n\n### Bienvenue !\n\nCe workshop vous guidera à travers le déploiement complet d'un modèle de Machine Learning en production sur Microsoft Azure. Vous allez construire une API de prédiction de défaillance client (churn) et la déployer sur le cloud avec toutes les bonnes pratiques MLOps.\n\n### Objectifs d'Apprentissage {#sec-objectifs}\n\nÀ la fin de ce workshop, vous serez capable de :\n\n-   Entraîner et sauvegarder un modèle ML avec MLflow\n-   Créer une API REST avec FastAPI\n-   Conteneuriser une application avec Docker\n-   Déployer sur Azure Container Apps\n-   Mettre en place un pipeline CI/CD avec GitHub Actions\n-   Monitorer votre application en production\n-   Détecter le data drift\n\n### Le Projet : Bank Churn Prediction {#sec-projet}\n\n**Contexte :** Une banque souhaite prédire quels clients risquent de partir pour proposer des actions de rétention.\n\n**Dataset :** 10 features (âge, score crédit, solde, etc.) + 1 target (Exited : 0/1)\n\n**Modèle :** Random Forest Classifier\n\n**Livrable :** API REST déployée sur Azure, accessible publiquement\n\n### Architecture Finale {#sec-architecture}\n\n**Flux de déploiement :**\n\n`Code GitHub` → `GitHub Actions` → `Docker Build` → `Azure Container Registry` → `Azure Container Apps` → `Internet`\n\n## Préparation de l'Environnement {#sec-preparation}\n\n### Logiciels Requis {#sec-logiciels}\n\n**Obligatoire :**\n\n-   Python 3.9+ : https://www.python.org/downloads/\n-   Visual Studio Code : https://code.visualstudio.com/\n-   Git : https://git-scm.com/downloads\n-   Docker Desktop : https://www.docker.com/products/docker-desktop\n-   Azure CLI : https://docs.microsoft.com/cli/azure/install-azure-cli\n\n**Comptes à créer :**\n\n-   Compte GitHub : https://github.com/signup\n-   Azure for Students (100\\$) : https://azure.microsoft.com/students\n\n### Vérification de l'Installation {#sec-verification}\n\nOuvrez un terminal et testez :\n\n``` bash\n# Python\npython --version\n# Doit afficher Python 3.9.x ou superieur\n\n# Git\ngit --version\n\n# Docker\ndocker --version\ndocker ps\n\n# Azure CLI\naz --version\n```\n\n### Configuration Initiale {#sec-configuration}\n\n#### Configuration Git {#sec-config-git}\n\n``` bash\ngit config --global user.name \"Votre Nom\"\ngit config --global user.email \"votre.email@example.com\"\n```\n\n#### Connexion à Azure {#sec-config-azure}\n\n``` bash\n# Se connecter a Azure\naz login\n\n# Verifier l'abonnement\naz account show\n\n# Si vous avez plusieurs abonnements, selectionner celui de Students\naz account set --subscription \"Azure for Students\"\n```\n\n## Module 1 : Entraînement du Modèle {#sec-module1}\n\n### Objectif {#sec-module1-objectif}\n\nEntraîner un modèle Random Forest pour prédire le churn et le sauvegarder avec MLflow.\n\n### Préparation du Projet {#sec-module1-preparation}\n\n``` bash\n# Creer le dossier du projet\nmkdir bank-churn-mlops\ncd bank-churn-mlops\n\n# Creer un environnement virtuel\npython -m venv venv\n\n# Activer l'environnement\n# Windows :\nvenv\\Scripts\\activate\n# Mac/Linux :\nsource venv/bin/activate\n\n# Creer la structure\nmkdir -p data model app tests\ntouch requirements.txt\n```\n\n### Fichier requirements.txt {#sec-module1-requirements}\n\nCréez le fichier `requirements.txt` avec le contenu suivant :\n\n```         \n# API Framework\nfastapi==0.104.1\nuvicorn[standard]==0.24.0\npydantic==2.5.0\n\n# Machine Learning\nscikit-learn==1.3.2\npandas==2.1.3\nnumpy==1.26.2\njoblib==1.3.2\n\n# MLflow\nmlflow==2.8.1\n\n# Testing\npytest==7.4.3\npytest-cov==4.1.0\nhttpx==0.25.2\n\n# Utilities\npython-multipart==0.0.6\nrequests==2.31.0\n```\n\nPuis installez les dépendances :\n\n``` bash\npip install -r requirements.txt\n```\n\n### Téléchargement du Dataset {#sec-module1-dataset}\n\nCréez un dataset synthétique :\n\n``` python\n# generate_data.py\nimport pandas as pd\nimport numpy as np\n\nnp.random.seed(42)\nn_samples = 10000\n\ndata = {\n    'CreditScore': np.random.randint(300, 850, n_samples),\n    'Age': np.random.randint(18, 80, n_samples),\n    'Tenure': np.random.randint(0, 11, n_samples),\n    'Balance': np.random.uniform(0, 200000, n_samples),\n    'NumOfProducts': np.random.randint(1, 5, n_samples),\n    'HasCrCard': np.random.choice([0, 1], n_samples),\n    'IsActiveMember': np.random.choice([0, 1], n_samples),\n    'EstimatedSalary': np.random.uniform(20000, 150000, n_samples),\n    'Geography_Germany': np.random.choice([0, 1], n_samples),\n    'Geography_Spain': np.random.choice([0, 1], n_samples),\n}\n\n# Target : plus de chance de partir si inactif, peu de produits, etc.\nchurn_prob = (\n    (1 - data['IsActiveMember']) * 0.3 +\n    (data['NumOfProducts'] == 1) * 0.2 +\n    (data['Age'] > 60) * 0.15 +\n    (data['Balance'] == 0) * 0.25\n)\ndata['Exited'] = (np.random.random(n_samples) < churn_prob).astype(int)\n\ndf = pd.DataFrame(data)\ndf.to_csv('data/bank_churn.csv', index=False)\nprint(f\"Dataset cree : {len(df)} lignes\")\nprint(f\"Taux de churn : {df['Exited'].mean():.2%}\")\n```\n\n### Script d'Entraînement {#sec-module1-training}\n\nCréez le fichier `train_model.py` :\n\n``` python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, \n    precision_score, \n    recall_score,\n    f1_score, \n    roc_auc_score,\n    confusion_matrix\n)\nimport joblib\nimport mlflow\nimport mlflow.sklearn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configuration MLflow\nmlflow.set_tracking_uri(\"./mlruns\")\nmlflow.set_experiment(\"bank-churn-prediction\")\n\nprint(\"Chargement des donnees...\")\ndf = pd.read_csv(\"data/bank_churn.csv\")\n\nprint(f\"Dataset : {len(df)} lignes, {len(df.columns)} colonnes\")\nprint(f\"Taux de churn : {df['Exited'].mean():.2%}\")\n\n# Separation features/target\nX = df.drop('Exited', axis=1)\ny = df['Exited']\n\n# Split train/test (80/20)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(f\"\\nTrain : {len(X_train)} lignes\")\nprint(f\"Test : {len(X_test)} lignes\")\n\n# Entrainement avec MLflow tracking\nprint(\"\\nEntrainement du modele...\")\nwith mlflow.start_run(run_name=\"random-forest-v1\"):\n    \n    # Parametres du modele\n    params = {\n        'n_estimators': 100,\n        'max_depth': 10,\n        'min_samples_split': 5,\n        'random_state': 42\n    }\n    \n    # Entrainement\n    model = RandomForestClassifier(**params)\n    model.fit(X_train, y_train)\n    \n    # Predictions\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    \n    # Calcul des metriques\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    \n    # Log des parametres et metriques dans MLflow\n    mlflow.log_params(params)\n    mlflow.log_metrics({\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1_score\": f1,\n        \"roc_auc\": auc\n    })\n    \n    # Creation et sauvegarde de la matrice de confusion\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title('Matrice de Confusion')\n    plt.ylabel('Vraie Classe')\n    plt.xlabel('Classe Predite')\n    plt.savefig('confusion_matrix.png')\n    mlflow.log_artifact('confusion_matrix.png')\n    plt.close()\n    \n    # Feature importance\n    feature_importance = pd.DataFrame({\n        'feature': X.columns,\n        'importance': model.feature_importances_\n    }).sort_values('importance', ascending=False)\n    \n    plt.figure(figsize=(10, 6))\n    plt.barh(feature_importance['feature'], feature_importance['importance'])\n    plt.xlabel('Importance')\n    plt.title('Feature Importance')\n    plt.tight_layout()\n    plt.savefig('feature_importance.png')\n    mlflow.log_artifact('feature_importance.png')\n    plt.close()\n    \n    # Enregistrement du modele dans MLflow\n    mlflow.sklearn.log_model(\n        model,\n        \"model\",\n        registered_model_name=\"bank-churn-classifier\"\n    )\n    \n    # Sauvegarde locale du modele\n    joblib.dump(model, \"model/churn_model.pkl\")\n    \n    # Tags\n    mlflow.set_tags({\n        \"environment\": \"development\",\n        \"model_type\": \"RandomForest\",\n        \"task\": \"binary_classification\"\n    })\n    \n    # Affichage des resultats\n    print(\"\\n\" + \"=\"*50)\n    print(\"RESULTATS DE L'ENTRAINEMENT\")\n    print(\"=\"*50)\n    print(f\"Accuracy  : {accuracy:.4f}\")\n    print(f\"Precision : {precision:.4f}\")\n    print(f\"Recall    : {recall:.4f}\")\n    print(f\"F1 Score  : {f1:.4f}\")\n    print(f\"ROC AUC   : {auc:.4f}\")\n    print(\"=\"*50)\n    \n    print(f\"\\nModele sauvegarde dans : model/churn_model.pkl\")\n    print(f\"MLflow UI : mlflow ui --port 5000\")\n```\n\n### Exécution {#sec-module1-execution}\n\n``` bash\n# Lancer l'entrainement\npython train_model.py\n\n# Voir les resultats dans MLflow UI\nmlflow ui --port 5000\n# Ouvrir http://localhost:5000 dans votre navigateur\n```\n\n### Checkpoint {#sec-module1-checkpoint}\n\n:::: callout-note\n## Validation Module 1\n\nAvant de passer au module suivant, vérifiez que :\n\n::: {style=\"margin-left: 20px;\"}\n-   [ ] Le modèle est entraîné avec une accuracy \\> 0.75\n-   [ ] Le fichier `model/churn_model.pkl` existe\n-   [ ] MLflow UI affiche votre expérience\n-   [ ] Vous comprenez les métriques obtenues\n:::\n::::\n\n## Module 2 : Création de l'API avec FastAPI {#sec-module2}\n\n### Objectif {#sec-module2-objectif}\n\nCréer une API REST qui expose le modèle via des endpoints HTTP.\n\n### Structure du Code API {#sec-module2-structure}\n\n```         \nbank-churn-mlops/\n|-- app/\n|   |-- __init__.py\n|   |-- main.py\n|   |-- models.py\n|   +-- utils.py\n|-- model/\n|   +-- churn_model.pkl\n|-- tests/\n|   +-- test_api.py\n|-- requirements.txt\n+-- README.md\n```\n\n### Fichier app/models.py {#sec-module2-models}\n\nDéfinition des schémas de données avec Pydantic :\n\n``` python\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass CustomerFeatures(BaseModel):\n    \"\"\"Schema pour les features d'un client\"\"\"\n    CreditScore: int = Field(..., ge=300, le=850, description=\"Score de credit\")\n    Age: int = Field(..., ge=18, le=100, description=\"Age du client\")\n    Tenure: int = Field(..., ge=0, le=10, description=\"Anciennete en annees\")\n    Balance: float = Field(..., ge=0, description=\"Solde du compte\")\n    NumOfProducts: int = Field(..., ge=1, le=4, description=\"Nombre de produits\")\n    HasCrCard: int = Field(..., ge=0, le=1, description=\"Possession carte credit\")\n    IsActiveMember: int = Field(..., ge=0, le=1, description=\"Membre actif\")\n    EstimatedSalary: float = Field(..., ge=0, description=\"Salaire estime\")\n    Geography_Germany: int = Field(..., ge=0, le=1, description=\"Client allemand\")\n    Geography_Spain: int = Field(..., ge=0, le=1, description=\"Client espagnol\")\n    \n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"CreditScore\": 650,\n                \"Age\": 35,\n                \"Tenure\": 5,\n                \"Balance\": 50000,\n                \"NumOfProducts\": 2,\n                \"HasCrCard\": 1,\n                \"IsActiveMember\": 1,\n                \"EstimatedSalary\": 75000,\n                \"Geography_Germany\": 0,\n                \"Geography_Spain\": 1\n            }\n        }\n\nclass PredictionResponse(BaseModel):\n    \"\"\"Schema pour la reponse de prediction\"\"\"\n    churn_probability: float = Field(..., description=\"Probabilite de churn (0-1)\")\n    prediction: int = Field(..., description=\"Prediction binaire (0=reste, 1=part)\")\n    risk_level: str = Field(..., description=\"Niveau de risque (Low/Medium/High)\")\n\nclass HealthResponse(BaseModel):\n    \"\"\"Schema pour le health check\"\"\"\n    status: str\n    model_loaded: bool\n```\n\n### Fichier app/main.py {#sec-module2-main}\n\nL'API principale :\n\n``` python\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nimport joblib\nimport numpy as np\nfrom typing import List\nimport logging\nimport os\n\nfrom app.models import CustomerFeatures, PredictionResponse, HealthResponse\n\n# Configuration du logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Initialisation FastAPI\napp = FastAPI(\n    title=\"Bank Churn Prediction API\",\n    description=\"API de prediction de defaillance client\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\"\n)\n\n# CORS pour permettre les requetes depuis un navigateur\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Chargement du modele au demarrage\nMODEL_PATH = os.getenv(\"MODEL_PATH\", \"model/churn_model.pkl\")\nmodel = None\n\n@app.on_event(\"startup\")\nasync def load_model():\n    \"\"\"Charge le modele au demarrage de l'API\"\"\"\n    global model\n    try:\n        model = joblib.load(MODEL_PATH)\n        logger.info(f\"Modele charge avec succes depuis {MODEL_PATH}\")\n    except Exception as e:\n        logger.error(f\"Erreur lors du chargement du modele : {e}\")\n        model = None\n\n@app.get(\"/\", tags=[\"General\"])\ndef root():\n    \"\"\"Endpoint racine\"\"\"\n    return {\n        \"message\": \"Bank Churn Prediction API\",\n        \"version\": \"1.0.0\",\n        \"status\": \"running\",\n        \"docs\": \"/docs\"\n    }\n\n@app.get(\"/health\", response_model=HealthResponse, tags=[\"General\"])\ndef health_check():\n    \"\"\"Verification de l'etat de l'API\"\"\"\n    if model is None:\n        raise HTTPException(\n            status_code=503, \n            detail=\"Modele non charge\"\n        )\n    return {\n        \"status\": \"healthy\",\n        \"model_loaded\": True\n    }\n\n@app.post(\"/predict\", response_model=PredictionResponse, tags=[\"Prediction\"])\ndef predict(features: CustomerFeatures):\n    \"\"\"\n    Predit si un client va partir (churn)\n    \n    Retourne :\n    - churn_probability : probabilite de churn (0 a 1)\n    - prediction : 0 (reste) ou 1 (part)\n    - risk_level : Low, Medium ou High\n    \"\"\"\n    if model is None:\n        raise HTTPException(\n            status_code=503, \n            detail=\"Modele non disponible\"\n        )\n    \n    try:\n        # Preparation des features\n        input_data = np.array([[\n            features.CreditScore,\n            features.Age,\n            features.Tenure,\n            features.Balance,\n            features.NumOfProducts,\n            features.HasCrCard,\n            features.IsActiveMember,\n            features.EstimatedSalary,\n            features.Geography_Germany,\n            features.Geography_Spain\n        ]])\n        \n        # Prediction\n        proba = model.predict_proba(input_data)[0, 1]\n        prediction = int(proba > 0.5)\n        \n        # Classification du risque\n        if proba < 0.3:\n            risk = \"Low\"\n        elif proba < 0.7:\n            risk = \"Medium\"\n        else:\n            risk = \"High\"\n        \n        logger.info(\n            f\"Prediction effectuee : proba={proba:.4f}, \"\n            f\"prediction={prediction}, risk={risk}\"\n        )\n        \n        return {\n            \"churn_probability\": round(float(proba), 4),\n            \"prediction\": prediction,\n            \"risk_level\": risk\n        }\n    \n    except Exception as e:\n        logger.error(f\"Erreur lors de la prediction : {e}\")\n        raise HTTPException(\n            status_code=500, \n            detail=f\"Erreur de prediction : {str(e)}\"\n        )\n\n@app.post(\"/predict/batch\", tags=[\"Prediction\"])\ndef predict_batch(features_list: List[CustomerFeatures]):\n    \"\"\"\n    Predictions en batch pour plusieurs clients\n    \"\"\"\n    if model is None:\n        raise HTTPException(status_code=503, detail=\"Modele non disponible\")\n    \n    try:\n        predictions = []\n        \n        for features in features_list:\n            input_data = np.array([[\n                features.CreditScore, features.Age, features.Tenure,\n                features.Balance, features.NumOfProducts, features.HasCrCard,\n                features.IsActiveMember, features.EstimatedSalary,\n                features.Geography_Germany, features.Geography_Spain\n            ]])\n            \n            proba = model.predict_proba(input_data)[0, 1]\n            prediction = int(proba > 0.5)\n            \n            predictions.append({\n                \"churn_probability\": round(float(proba), 4),\n                \"prediction\": prediction\n            })\n        \n        logger.info(f\"Batch prediction : {len(predictions)} clients traites\")\n        \n        return {\"predictions\": predictions, \"count\": len(predictions)}\n    \n    except Exception as e:\n        logger.error(f\"Erreur batch prediction : {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n```\n\n### Test Local de l'API {#sec-module2-test}\n\n``` bash\n# Demarrer l'API\nuvicorn app.main:app --reload --port 8000\n\n# Dans un autre terminal, tester :\n\n# 1. Health check\ncurl http://localhost:8000/health\n\n# 2. Prediction simple\ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n  }'\n```\n### Jupyter Lab \n\n```python\n#dans jupyter lab\nimport requests\nimport json\n\n# URL de ton API FastAPI\nurl = \"http://localhost:8000/predict\"\n\n# Données à envoyer\ndata = {\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n}\n\n# Envoyer la requête POST\nresponse = requests.post(url, json=data)\n\n# Afficher la réponse\nprint(f\"Status Code: {response.status_code}\")\nprint(f\"Response: {response.json()}\")\n```\n\n### Documentation Interactive {#sec-module2-docs}\n\nOuvrez votre navigateur et allez sur :\n\n-   **Swagger UI** : http://localhost:8000/docs\n-   **ReDoc** : http://localhost:8000/redoc\n\n### Checkpoint {#sec-module2-checkpoint}\n\n:::: callout-note\n## Validation Module 2\n\nAvant de passer au module suivant, vérifiez que :\n\n::: {style=\"margin-left: 20px;\"}\n-   [ ] Le modèle est entraîné avec une accuracy \\> 0.75\n-   [ ] Le fichier `model/churn_model.pkl` existe\\\n-   [ ] MLflow UI affiche votre expérience\n-   [ ] Vous comprenez les métriques obtenues\n:::\n::::\n\n## Module 3 : Conteneurisation avec Docker {#sec-module3}\n\n### Objectif {#sec-module3-objectif}\n\nEmpaqueter l'API dans un conteneur Docker pour la rendre portable et faciliter le déploiement sur Azure.\n\n### Création du Dockerfile {#sec-module3-dockerfile}\n\nCréez le fichier `Dockerfile` à la racine du projet :\n\n``` dockerfile\n# Utilise une image Python officielle\nFROM python:3.9-slim\n\n# Definir le repertoire de travail\nWORKDIR /app\n\n# Copier les fichiers de dependances\nCOPY requirements.txt .\n\n# Installer les dependances\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copier le code de l'application\nCOPY app/ ./app/\nCOPY model/ ./model/\n\n# Exposer le port\nEXPOSE 8000\n\n# Commande pour demarrer l'application\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```\n\n### Création du .dockerignore {#sec-module3-dockerignore}\n\nCréez le fichier `.dockerignore` :\n\n```         \n__pycache__\n*.pyc\n*.pyo\n*.pyd\n.Python\nenv/\nvenv/\n.venv\n*.egg-info/\n.pytest_cache/\n.git\n.gitignore\nREADME.md\n.env\nmlruns/\n*.log\n.DS_Store\n.vscode/\ntests/\n```\n\n### Build de l'Image Docker {#sec-module3-build}\n\n``` bash\n# Build de l'image (cela peut prendre quelques minutes)\ndocker build -t bank-churn-api:v1 .\n\n# Verifier que l'image est creee\ndocker images bank-churn-api:v1\n\n# Voir la taille de l'image\ndocker images --format \"table {{.Repository}}\\t{{.Tag}}\\t{{.Size}}\" | grep bank-churn\n```\n\n### Test du Conteneur en Local {#sec-module3-test}\n\n``` bash\n# Lancer le conteneur\ndocker run -d -p 8000:8000 --name churn-api bank-churn-api:v1\n\n# Verifier que le conteneur tourne\ndocker ps\n\n# Voir les logs\ndocker logs churn-api\n\n# Tester l'API\ncurl http://localhost:8000/health\n\n# Prediction de test\ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 700,\n    \"Age\": 40,\n    \"Tenure\": 7,\n    \"Balance\": 80000,\n    \"NumOfProducts\": 3,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 0,\n    \"EstimatedSalary\": 90000,\n    \"Geography_Germany\": 1,\n    \"Geography_Spain\": 0\n  }'\n\n# Arreter et supprimer le conteneur\ndocker stop churn-api\ndocker rm churn-api\n```\n\n### Commandes Docker Utiles {#sec-module3-commandes}\n\n``` bash\n# Voir tous les conteneurs (meme arretes)\ndocker ps -a\n\n# Entrer dans un conteneur en cours d'execution\ndocker exec -it churn-api /bin/bash\n\n# Voir l'utilisation des ressources\ndocker stats churn-api\n\n# Nettoyer les images inutilisees\ndocker image prune\n\n# Supprimer toutes les images\ndocker rmi $(docker images -q)\n```\n\n### Questions de Compréhension {#sec-module3-questions}\n\n1.  Pourquoi utiliser un .dockerignore ?\n2.  Quelle est la différence entre CMD et RUN dans un Dockerfile ?\n3.  Pourquoi exposer le port 8000 ?\n4.  Comment vérifier que votre conteneur fonctionne correctement ?\n\n### Checkpoint {#sec-module3-checkpoint}\n\n:::: callout-note\n## Validation Module 3\n\nAvant de passer au module suivant, vérifiez que :\n\n::: {style=\"margin-left: 20px;\"}\n-   [ ] L'image Docker est buildée avec succès\n-   [ ] Le conteneur démarre sans erreur\n-   [ ] L'API répond correctement depuis le conteneur\n-   [ ] La taille de l'image est raisonnable (\\< 1GB)\n:::\n::::\n\n## Module 4 : Déploiement sur Azure {#sec-module4}\n\n### Objectif {#sec-module4-objectif}\n\nDéployer l'API sur Azure Container Apps et la rendre accessible publiquement.\n\n### Étape 1 : Création du Groupe de Ressources {#sec-module4-etape1}\n\n``` bash\n# Variables (MODIFIEZ avec vos valeurs)\nRESOURCE_GROUP=\"rg-mlops-workshop\"\nLOCATION=\"westeurope\"\nACR_NAME=\"acrmlops$(whoami)$(date +%s)\"  # Doit etre unique globalement\nCONTAINER_APP_NAME=\"app-churn-api\"\n\n# Creation du groupe de ressources\naz group create \\\n  --name $RESOURCE_GROUP \\\n  --location $LOCATION\n\necho \"Groupe de ressources cree : $RESOURCE_GROUP\"\n```\n\n### Étape 2 : Azure Container Registry (ACR) {#sec-module4-etape2}\n\n``` bash\n# Creation du registry (SKU Basic pour economiser)\naz acr create \\\n  --resource-group $RESOURCE_GROUP \\\n  --name $ACR_NAME \\\n  --sku Basic \\\n  --admin-enabled true\n\necho \"Container Registry cree : $ACR_NAME\"\n\n# Se connecter au registry\naz acr login --name $ACR_NAME\n\n# Verifier la connexion\naz acr show --name $ACR_NAME --query loginServer --output tsv\n```\n\n### Étape 3 : Push de l'Image vers ACR {#sec-module4-etape3}\n\n``` bash\n# Recuperer l'URL du registry\nACR_LOGIN_SERVER=$(az acr show --name $ACR_NAME --query loginServer --output tsv)\n\n# Tagger l'image pour ACR\ndocker tag bank-churn-api:v1 $ACR_LOGIN_SERVER/bank-churn-api:v1\ndocker tag bank-churn-api:v1 $ACR_LOGIN_SERVER/bank-churn-api:latest\n\n# Pousser l'image vers ACR\ndocker push $ACR_LOGIN_SERVER/bank-churn-api:v1\ndocker push $ACR_LOGIN_SERVER/bank-churn-api:latest\n\n# Verifier que l'image est bien dans ACR\naz acr repository list --name $ACR_NAME --output table\naz acr repository show-tags --name $ACR_NAME --repository bank-churn-api --output table\n```\n\n### Étape 4 : Création de l'Environnement Container Apps {#sec-module4-etape4}\n\n``` bash\n# Variables\nCONTAINERAPPS_ENV=\"env-mlops-workshop\"\n\n# Creation de l'environnement\naz containerapp env create \\\n  --name $CONTAINERAPPS_ENV \\\n  --resource-group $RESOURCE_GROUP \\\n  --location $LOCATION\n\necho \"Environnement Container Apps cree : $CONTAINERAPPS_ENV\"\n```\n\n### Étape 5 : Déploiement de l'Application {#sec-module4-etape5}\n\n``` bash\n# Recuperer les credentials ACR\nACR_USERNAME=$(az acr credential show --name $ACR_NAME --query username -o tsv)\nACR_PASSWORD=$(az acr credential show --name $ACR_NAME --query passwords[0].value -o tsv)\n\n# Deployer l'application\naz containerapp create \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --environment $CONTAINERAPPS_ENV \\\n  --image $ACR_LOGIN_SERVER/bank-churn-api:v1 \\\n  --registry-server $ACR_LOGIN_SERVER \\\n  --registry-username $ACR_USERNAME \\\n  --registry-password $ACR_PASSWORD \\\n  --target-port 8000 \\\n  --ingress external \\\n  --min-replicas 1 \\\n  --max-replicas 3 \\\n  --cpu 0.5 \\\n  --memory 1Gi\n\necho \"Application deployee !\"\n```\n\n### Étape 6 : Récupérer l'URL Publique {#sec-module4-etape6}\n\n``` bash\n# Recuperer l'URL de l'application\nAPP_URL=$(az containerapp show \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --query properties.configuration.ingress.fqdn -o tsv)\n\necho \"==========================================\"\necho \"API deployee avec succes !\"\necho \"URL : https://$APP_URL\"\necho \"Health check : https://$APP_URL/health\"\necho \"Documentation : https://$APP_URL/docs\"\necho \"==========================================\"\n\n# Tester l'API deployee\ncurl https://$APP_URL/health\n```\n\n### Étape 7 : Test de l'API en Production {#sec-module4-etape7}\n\n``` bash\n# Test de prediction\ncurl -X POST \"https://$APP_URL/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"CreditScore\": 650,\n    \"Age\": 35,\n    \"Tenure\": 5,\n    \"Balance\": 50000,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 75000,\n    \"Geography_Germany\": 0,\n    \"Geography_Spain\": 1\n  }'\n```\n\n### Surveillance des Coûts {#sec-module4-couts}\n\n::: callout-warning\n## IMPORTANT - Gestion du Budget\n\nPour éviter de dépasser le budget de 100\\$ :\n\n``` bash\n# Voir les couts estimes\naz consumption usage list \\\n  --start-date 2024-11-01 \\\n  --end-date 2024-11-30 \\\n  --output table\n\n# Mettre l'application en veille (min-replicas=0)\naz containerapp update \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --min-replicas 0 \\\n  --max-replicas 3\n```\n\nCoûts estimés pour ce workshop : 8-12\\$ pour 10 heures d'utilisation.\n:::\n\n### Exercice Pratique {#sec-module4-exercice}\n\n::: callout-tip\n## EXERCICE 2\n\nPartagez votre URL d'API avec un camarade et testez son API :\n\n1.  Faites 10 prédictions sur son API\n2.  Comparez les résultats avec votre modèle\n3.  Observez les logs dans Azure Portal\n:::\n\n### Checkpoint {#sec-module4-checkpoint}\n\n:::: callout-note\n## Validation Module 4\n\nAvant de passer au module suivant, vérifiez que :\n\n::: {style=\"margin-left: 20px;\"}\n-   [ ] L'application est accessible via HTTPS\n-   [ ] Le health check fonctionne\n-   [ ] Les prédictions fonctionnent\n-   [ ] Vous avez noté l'URL publique de votre API\n:::\n::::\n\n## Module 5 : CI/CD avec GitHub Actions {#sec-module5}\n\n### Objectif {#sec-module5-objectif}\n\nAutomatiser le déploiement : chaque commit sur la branche main déclenche un build et un redéploiement.\n\n### Étape 1 : Initialisation du Repository Git {#sec-module5-etape1}\n\n``` bash\n# Initialiser git (si pas deja fait)\ngit init\n\n# Creer un .gitignore\ncat > .gitignore << EOF\n__pycache__/\n*.pyc\nvenv/\n.env\nmlruns/\n*.log\n.DS_Store\n.vscode/\nconfusion_matrix.png\nfeature_importance.png\nEOF\n\n# Premier commit\ngit add .\ngit commit -m \"Initial commit: Bank Churn API\"\n```\n\n### Étape 2 : Créer un Repository GitHub {#sec-module5-etape2}\n\n1.  Allez sur https://github.com/new\n2.  Nom du repository : `bank-churn-mlops`\n3.  Visibility : Public ou Private\n4.  Ne pas initialiser avec README (déjà fait localement)\n5.  Cliquez sur \"Create repository\"\n\n``` bash\n# Lier votre repo local a GitHub (REMPLACEZ username)\ngit remote add origin https://github.com/username/bank-churn-mlops.git\ngit branch -M main\ngit push -u origin main\n```\n\n### Étape 3 : Configuration des Secrets GitHub {#sec-module5-etape3}\n\n#### Créer un Service Principal Azure {#sec-module5-service-principal}\n\n``` bash\n# Recuperer votre Subscription ID\nSUBSCRIPTION_ID=$(az account show --query id -o tsv)\n\n# Creer un Service Principal\naz ad sp create-for-rbac \\\n  --name \"github-actions-mlops\" \\\n  --role contributor \\\n  --scopes /subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP \\\n  --sdk-auth\n```\n\nCopiez tout le JSON retourné.\n\n#### Ajouter les Secrets dans GitHub {#sec-module5-secrets}\n\n1.  Allez dans votre repository GitHub\n2.  Settings \\> Secrets and variables \\> Actions\n3.  Cliquez sur \"New repository secret\"\n4.  Ajoutez les secrets suivants :\n\n| **Nom** | **Valeur** |\n|------------------------------------|------------------------------------|\n| AZURE_CREDENTIALS | Le JSON du Service Principal |\n| ACR_USERNAME | Résultat de : `az acr credential show --name $ACR_NAME --query username -o tsv` |\n| ACR_PASSWORD | Résultat de : `az acr credential show --name $ACR_NAME --query passwords[0].value -o tsv` |\n\n### Étape 4 : Création du Workflow GitHub Actions {#sec-module5-etape4}\n\nCréez le fichier `.github/workflows/ci-cd.yml` :\n\n``` yaml\nname: CI/CD Pipeline\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n  workflow_dispatch:\n\nenv:\n  AZURE_RESOURCE_GROUP: rg-mlops-workshop\n  ACR_NAME: votre-acr-name  # MODIFIEZ ICI\n  CONTAINER_APP_NAME: app-churn-api\n  IMAGE_NAME: bank-churn-api\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n      \n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.9'\n      \n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements.txt\n          pip install pytest pytest-cov\n      \n      - name: Run tests\n        run: |\n          pytest tests/ -v --cov=app --cov-report=term\n      \n  build-and-deploy:\n    needs: test\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'\n    \n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n      \n      - name: Azure Login\n        uses: azure/login@v1\n        with:\n          creds: ${{ secrets.AZURE_CREDENTIALS }}\n      \n      - name: Login to ACR\n        uses: azure/docker-login@v1\n        with:\n          login-server: ${{ env.ACR_NAME }}.azurecr.io\n          username: ${{ secrets.ACR_USERNAME }}\n          password: ${{ secrets.ACR_PASSWORD }}\n      \n      - name: Build and push Docker image\n        run: |\n          docker build -t ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }} .\n          docker build -t ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest .\n          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}\n          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest\n      \n      - name: Deploy to Azure Container Apps\n        uses: azure/CLI@v1\n        with:\n          inlineScript: |\n            az containerapp update \\\n              --name ${{ env.CONTAINER_APP_NAME }} \\\n              --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n              --image ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}\n      \n      - name: Verify deployment\n        run: |\n          APP_URL=$(az containerapp show \\\n            --name ${{ env.CONTAINER_APP_NAME }} \\\n            --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \\\n            --query properties.configuration.ingress.fqdn -o tsv)\n          \n          echo \"Application deployed at: https://$APP_URL\"\n          \n          sleep 30\n          curl -f https://$APP_URL/health || exit 1\n          \n          echo \"Deployment successful!\"\n```\n\n### Étape 5 : Déclencher le Pipeline {#sec-module5-etape5}\n\n``` bash\n# Ajouter le workflow\ngit add .github/workflows/ci-cd.yml\ngit add tests/test_api.py\ngit commit -m \"Add CI/CD pipeline and tests\"\ngit push origin main\n\n# Le pipeline se declenche automatiquement !\n```\n\nAllez sur GitHub \\> Actions pour voir le pipeline en cours d'exécution.\n\n### Exercice Pratique {#sec-module5-exercice}\n\n::: callout-tip\n## EXERCICE 3\n\n1.  Ajoutez un nouveau test dans `test_api.py`\n2.  Faites un commit et push\n3.  Observez le pipeline s'exécuter\n4.  Vérifiez que le déploiement s'est bien fait\n:::\n\n### Checkpoint {#sec-module5-checkpoint}\n\n:::: callout-note\n## Validation Module 5\n\nAvant de passer au module suivant, vérifiez que :\n\n::: {style=\"margin-left: 20px; line-height: 1.8;\"}\n-   [ ] Le repository GitHub est créé\n-   [ ] Les secrets sont configurés\n-   [ ] Le workflow CI/CD s'exécute sans erreur\n-   [ ] L'application se redéploie\n:::\n\nautomatiquement\n::::\n\n## Module 6 : Monitoring et Maintenance {#sec-module6}\n\n### Objectif {#sec-module6-objectif}\n\nMettre en place le monitoring de l'application et détecter les problèmes en production.\n\n### Configuration Application Insights {#sec-module6-appinsights}\n\n``` bash\n# Creation d'Application Insights\naz monitor app-insights component create \\\n  --app bank-churn-insights \\\n  --location $LOCATION \\\n  --resource-group $RESOURCE_GROUP \\\n  --application-type web\n\n# Recuperer la connection string\nAPPINSIGHTS_CONN=$(az monitor app-insights component show \\\n  --app bank-churn-insights \\\n  --resource-group $RESOURCE_GROUP \\\n  --query connectionString -o tsv)\n\necho \"Connection String : $APPINSIGHTS_CONN\"\n\n# Ajouter la variable d'environnement a Container Apps\naz containerapp update \\\n  --name $CONTAINER_APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --set-env-vars \"APPLICATIONINSIGHTS_CONNECTION_STRING=$APPINSIGHTS_CONN\"\n```\n\n### Intégration du Monitoring dans le Code {#sec-module6-monitoring}\n\nAjoutez dans `requirements.txt` :\n\n```         \nopencensus-ext-azure==1.1.9\nopencensus-ext-requests==0.12.1\n```\n\nModifiez `app/main.py` pour ajouter le monitoring :\n\n``` python\nimport os\nfrom opencensus.ext.azure.log_exporter import AzureLogHandler\nimport logging\n\n# Configuration du logging avec Application Insights\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n\nAPPINSIGHTS_CONN = os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\")\nif APPINSIGHTS_CONN:\n    logger.addHandler(AzureLogHandler(connection_string=APPINSIGHTS_CONN))\n    logger.info(\"Application Insights connecte\")\n```\n\n### Détection de Data Drift {#sec-module6-drift}\n\nCréez le fichier `drift_detection.py` :\n\n``` python\nimport pandas as pd\nfrom scipy.stats import ks_2samp\nimport json\n\ndef detect_drift(reference_file, production_file, threshold=0.05):\n    \"\"\"\n    Detecte le drift entre donnees de reference et production\n    \"\"\"\n    ref_data = pd.read_csv(reference_file)\n    prod_data = pd.read_csv(production_file)\n    \n    drift_results = {}\n    \n    for column in ref_data.columns:\n        if column in prod_data.columns and column != 'Exited':\n            # Test de Kolmogorov-Smirnov\n            statistic, p_value = ks_2samp(\n                ref_data[column].dropna(),\n                prod_data[column].dropna()\n            )\n            \n            drift_detected = p_value < threshold\n            \n            drift_results[column] = {\n                'p_value': float(p_value),\n                'statistic': float(statistic),\n                'drift_detected': drift_detected\n            }\n    \n    # Rapport\n    drifted_features = [f for f, r in drift_results.items() if r['drift_detected']]\n    \n    print(\"=\"*50)\n    print(\"DATA DRIFT DETECTION REPORT\")\n    print(\"=\"*50)\n    print(f\"Threshold: {threshold}\")\n    print(f\"Features analyzed: {len(drift_results)}\")\n    print(f\"Features with drift: {len(drifted_features)}\")\n    print(\"\\nDrifted features:\")\n    for feature in drifted_features:\n        print(f\"  - {feature}: p-value = {drift_results[feature]['p_value']:.4f}\")\n    print(\"=\"*50)\n    \n    return drift_results\n\nif __name__ == \"__main__\":\n    results = detect_drift(\n        \"data/bank_churn.csv\",\n        \"data/production_data.csv\"\n    )\n    \n    # Sauvegarder les resultats\n    with open(\"drift_report.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n    \n    print(\"\\nRapport sauvegarde dans drift_report.json\")\n```\n\n### Checkpoint {#sec-module6-checkpoint}\n\n:::: callout-note\n## Validation Module 6\n\nAvant de passer au module suivant, vérifiez que :\n\n::: {style=\"margin-left: 20px; line-height: 1.8;\"}\n-   [ ] Application Insights est configuré\n-   [ ] Les logs apparaissent dans Azure Portal\n-   [ ] Vous pouvez visualiser les métriques\n-   [ ] Le script de détection de drift fonctionne\n:::\n::::\n\n## Module 7 : Optimisations et Bonnes Pratiques {#sec-module7}\n\n### Objectif {#sec-module7-objectif}\n\nAméliorer les performances, la sécurité et la maintenabilité de l'application.\n\n### Ajout d'un Cache pour les Prédictions {#sec-module7-cache}\n\nModifiez `app/main.py` :\n\n``` python\nfrom functools import lru_cache\nimport hashlib\nimport json\n\ndef hash_features(features_dict: dict) -> str:\n    \"\"\"Cree un hash unique pour les features\"\"\"\n    return hashlib.md5(\n        json.dumps(features_dict, sort_keys=True).encode()\n    ).hexdigest()\n\n# Cache pour les predictions (1000 dernieres)\n@lru_cache(maxsize=1000)\ndef predict_cached(features_hash: str, features_json: str):\n    features_dict = json.loads(features_json)\n    input_data = np.array([[\n        features_dict[\"CreditScore\"],\n        features_dict[\"Age\"],\n        # ... autres features\n    ]])\n    \n    proba = model.predict_proba(input_data)[0, 1]\n    prediction = int(proba > 0.5)\n    \n    if proba < 0.3:\n        risk = \"Low\"\n    elif proba < 0.7:\n        risk = \"Medium\"\n    else:\n        risk = \"High\"\n    \n    return {\n        \"churn_probability\": round(float(proba), 4),\n        \"prediction\": prediction,\n        \"risk_level\": risk\n    }\n\n@app.post(\"/predict\", response_model=PredictionResponse)\ndef predict(features: CustomerFeatures):\n    features_dict = features.dict()\n    features_hash = hash_features(features_dict)\n    features_json = json.dumps(features_dict)\n    \n    # Utilise le cache si disponible\n    result = predict_cached(features_hash, features_json)\n    \n    logger.info(f\"Prediction - Hash: {features_hash[:8]}\")\n    return result\n```\n\n### Checklist de Production {#sec-module7-checklist}\n\n::: callout-tip\n## Checklist Avant Production\n\n-   [ ] Tests unitaires avec coverage \\> 80%\n-   [ ] Tests d'integration\n-   [ ] Load testing effectue\n-   [ ] Monitoring configure\n-   [ ] Alertes definies\n-   [ ] Logs centralises\n-   [ ] Documentation API complete\n-   [ ] HTTPS active\n-   [ ] Health checks fonctionnels\n-   [ ] Auto-scaling teste\n-   [ ] Variables d'environnement securisees\n-   [ ] Budget Azure surveille\n:::\n\n### Checkpoint Final {#sec-module7-checkpoint}\n\n:::: callout-note\n## Validation Module 7\n\n::: {style=\"margin-left: 20px; line-height: 1.8;\"}\n-   [ ] Cache de predictions implemente\n-   [ ] Documentation complete\n-   [ ] Tous les tests passent\n-   [ ] Checklist de production verifiee\n:::\n::::\n\n## Nettoyage des Ressources Azure {#sec-nettoyage}\n\n### IMPORTANT - Suppression pour Éviter les Coûts {#sec-nettoyage-important}\n\n::: callout-warning\n## ATTENTION - À FAIRE À LA FIN DU WORKSHOP\n\nPour éviter de consommer votre budget de 100\\$, supprimez toutes les ressources :\n\n``` bash\n# Suppression du groupe de ressources (supprime tout)\naz group delete --name $RESOURCE_GROUP --yes --no-wait\n\n# Verification\naz group list --output table\n```\n\nCette commande supprime : - Azure Container Registry - Azure Container Apps - Application Insights - Tous les logs et données\n\n**Temps de suppression** : 5-10 minutes\n:::\n\n### Script de Nettoyage Automatique {#sec-nettoyage-script}\n\nCréez `cleanup.sh` :\n\n``` bash\n#!/bin/bash\n\nRESOURCE_GROUP=\"rg-mlops-workshop\"\n\necho \"==========================================\"\necho \"Nettoyage des ressources Azure\"\necho \"==========================================\"\n\nread -p \"Voulez-vous vraiment supprimer toutes les ressources ? (yes/no): \" confirm\n\nif [ \"$confirm\" != \"yes\" ]; then\n    echo \"Operation annulee.\"\n    exit 0\nfi\n\necho \"\\nRessources a supprimer:\"\naz resource list --resource-group $RESOURCE_GROUP --output table\n\necho \"\\nSuppression en cours...\"\naz group delete --name $RESOURCE_GROUP --yes --no-wait\n\necho \"\\nSuppression lancee (prend 5-10 minutes)\"\necho \"Verifiez sur : https://portal.azure.com\"\n```\n\n``` bash\n# Rendre executable et lancer\nchmod +x cleanup.sh\n./cleanup.sh\n```\n\n## Récapitulatif du Workshop {#sec-recapitulatif}\n\n### Ce que Vous Avez Accompli {#sec-recap-accompli}\n\nFélicitations ! Vous avez déployé un système MLOps complet :\n\n**Architecture Finale :**\n\n`ML Training` → `FastAPI` → `Docker` → `Azure Container Registry` → `Azure Container Apps`\n\n↑ `GitHub Actions CI/CD`\n\n↑ `Application Insights Monitoring`\n\n### Compétences Acquises {#sec-recap-competences}\n\n1.  **Machine Learning**\n    -   Entraînement d'un modèle Random Forest\n    -   Évaluation avec métriques appropriées\n    -   Tracking avec MLflow\n2.  **Développement d'API**\n    -   Création d'API REST avec FastAPI\n    -   Validation des données avec Pydantic\n    -   Documentation automatique\n3.  **Conteneurisation**\n    -   Dockerfiles optimisés\n    -   Bonnes pratiques de sécurité\n    -   Gestion des images\n4.  **Cloud Azure**\n    -   Azure Container Registry\n    -   Azure Container Apps\n    -   Application Insights\n5.  **DevOps/MLOps**\n    -   Pipelines CI/CD avec GitHub Actions\n    -   Tests automatisés\n    -   Déploiement continu\n6.  **Monitoring et Maintenance**\n    -   Logs centralisés\n    -   Métriques de performance\n    -   Détection de data drift\n\n### Points Clés à Retenir {#sec-recap-points-cles}\n\n::: callout-important\n## Lecons Importantes\n\n1.  **MLOps = DevOps + ML** : Automatisation du cycle de vie complet\n2.  **Conteneurisation** : Portabilité et reproductibilité\n3.  **Tests** : Essentiels pour la fiabilité\n4.  **Monitoring** : Indispensable en production\n5.  **Documentation** : Facilite la collaboration\n6.  **Sécurité** : À considérer dès le début\n7.  **Coûts** : Toujours surveiller l'utilisation cloud\n:::\n\n## FAQ - Foire Aux Questions {#sec-faq}\n\n### Questions Techniques {#sec-faq-techniques}\n\n**Q1 : Mon API est lente, comment l'optimiser ?**\n\n*R :* Plusieurs options : - Activer le cache des prédictions - Utiliser des prédictions batch - Optimiser le modèle (quantization, pruning) - Augmenter les ressources CPU/RAM\n\n**Q2 : Comment gérer plusieurs versions de modèles ?**\n\n*R :* Utilisez MLflow Model Registry et créez des endpoints différents (v1, v2).\n\n**Q3 : Comment implémenter un rollback ?**\n\n*R :* Conservez les anciennes images Docker avec tags et utilisez :\n\n``` bash\naz containerapp update \\\n  --name $APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --image $ACR_NAME.azurecr.io/bank-churn-api:v1  # Version precedente\n```\n\n**Q4 : Mon budget Azure est presque épuisé, que faire ?**\n\n*R :* - Mettre min-replicas à 0 - Utiliser des SKU Basic - Supprimer les ressources inutilisées - Activer les budgets alerts\n\n### Questions de Compréhension {#sec-faq-comprehension}\n\n**Q5 : Quelle est la différence entre Docker et Kubernetes ?**\n\n*R :* Docker conteneurise les applications, Kubernetes les orchestre (scaling, load balancing, self-healing).\n\n**Q6 : Pourquoi utiliser FastAPI plutôt que Flask ?**\n\n*R :* FastAPI est plus rapide, avec validation automatique, documentation auto-générée, et support async natif.\n\n**Q7 : Qu'est-ce que le data drift ?**\n\n*R :* Changement dans la distribution des données d'entrée par rapport aux données d'entraînement, pouvant dégrader les performances du modèle.\n\n## Conclusion {#sec-conclusion}\n\n### Félicitations ! {#sec-conclusion-felicitations}\n\nVous avez terminé ce workshop intensif de MLOps avec Azure. Vous avez construit un système complet de déploiement de modèle de Machine Learning en production, avec toutes les bonnes pratiques de l'industrie.\n\n### Prochaines Étapes {#sec-conclusion-next-steps}\n\n1.  **Pratiquez** : Refaites le workshop avec un dataset différent\n2.  **Partagez** : Mettez votre projet sur GitHub\n3.  **Améliorez** : Implémentez les fonctionnalités avancées\n4.  **Certifiez-vous** : Préparez les certifications Azure\n\n------------------------------------------------------------------------\n\n**Bon Apprentissage et Bon Déploiement !**\n\n*Ce guide vous a accompagné dans votre premier projet MLOps.\\\nContinuez à explorer, à apprendre et à innover.*\n\n------------------------------------------------------------------------\n\n*Version 1.0 - Novembre 2025*\\\n*Workshop MLOps avec Azure* \\n\\## Test de déploiement - jeu. 20 nov. 2025 03:26:42"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"css":["styles.css"],"toc-depth":3,"number-sections":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.25","theme":"cosmo","title":"Workshop MLOps avec Azure - Guide Pratique","editor":"visual","toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}